import { createSnippet } from './snippetCreator';
import * as vscode from 'vscode';

export const snippets717: Record<string, vscode.CompletionItem[]> = {
	'logstash-input-websocket': [
		createSnippet('mode', 'option', 'mode => "${1|client|}"$0', '**[mode](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-websocket.html#plugins-inputs-websocket-mode) option**\n\n- Value can be any of: client\n- Default value is "client"\n\nSelect the plugin’s mode of operation. Right now only client mode is supported, i.e. this plugin connects to a websocket server and receives events from the server as websocket messages.'),
		createSnippet('url', 'option', 'url => "${1:url}"', '**[url](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-websocket.html#plugins-inputs-websocket-url) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe URL to connect to.', true)
	],
	'logstash-filter-json_encode': [
		createSnippet('source', 'option', 'source => "${1:source}"', '**[source](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-json_encode.html#plugins-filters-json_encode-source) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe field to convert to JSON.', true),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-json_encode.html#plugins-filters-json_encode-target) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe field to write the JSON into. If not specified, the source field will be overwritten.')
	],
	'logstash-codec-avro': [
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-avro.html#plugins-codecs-avro-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: Avro data added at root level v1,v8: Elastic Common Schema compliant behavior ([event][original] is also added)\n- disabled: Avro data added at root level\n- v1,v8: Elastic Common Schema compliant behavior ([event][original] is also added)\n\nSupported values are:'),
		createSnippet('schema_uri', 'option', 'schema_uri => "${1:schema_uri}"', '**[schema_uri](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-avro.html#plugins-codecs-avro-schema_uri) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nschema path to fetch the schema from. This can be a http or file scheme URI example:', true),
		createSnippet('tag_on_failure', 'option', 'tag_on_failure => ${1|false,true|}', '**[tag_on_failure](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-avro.html#plugins-codecs-avro-tag_on_failure) option**\n\n- Value type is boolean\n- Default value is false\n\ntag events with _avroparsefailure when decode fails'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-avro.html#plugins-codecs-avro-target) option**\n\n- Value type is string\n- There is no default value for this setting.\n- This is only relevant when decode data into an event\n\nDefine the target field for placing the values. If this setting is not set, the Avro data will be stored at the root (top level) of the event.\n\n**_Example:_**  \n``` ruby\ninput {\n  kafka {\n    codec => avro {\n        schema_uri => "/tmp/schema.avsc"\n        target => "[document]"\n    }\n  }\n}\n```')
	],
	'logstash-output-loggly': [
		createSnippet('can_retry', 'option', 'can_retry => ${1|true,false|}', '**[can_retry](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-loggly.html#plugins-outputs-loggly-can_retry) option**\n\n- Value type is boolean\n- Default value is true\n\nCan Retry. Setting this value true helps user to send multiple retry attempts if the first request fails'),
		createSnippet('convert_timestamp', 'option', 'convert_timestamp => ${1|true,false|}', '**[convert_timestamp](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-loggly.html#plugins-outputs-loggly-convert_timestamp) option**\n\n- Value type is boolean\n- Default value is true\n\nThe plugin renames Logstash’s @timestamp field to timestamp before sending, so that Loggly recognizes it automatically.'),
		createSnippet('host', 'option', 'host => "${1:logs-01.loggly.com}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-loggly.html#plugins-outputs-loggly-host) option**\n\n- Value type is string\n- Default value is "logs-01.loggly.com"\n\nThe hostname to send logs to. This should target the loggly http input server which is usually "logs-01.loggly.com" (Gen2 account). See the Loggly HTTP endpoint documentation.'),
		createSnippet('key', 'option', 'key => "${1:key}"', '**[key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-loggly.html#plugins-outputs-loggly-key) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe loggly http customer token to use for sending. You can find yours in "Source Setup", under "Customer Tokens".', true),
		createSnippet('max_event_size', 'option', 'max_event_size => "${1:1 Mib}"', '**[max_event_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-loggly.html#plugins-outputs-loggly-max_event_size) option**\n\n- This is a required setting.\n- Value type is bytes\n- Default value is 1 Mib\n\nThe Loggly API supports event size up to 1 Mib.', true),
		createSnippet('max_payload_size', 'option', 'max_payload_size => "${1:5 Mib}"', '**[max_payload_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-loggly.html#plugins-outputs-loggly-max_payload_size) option**\n\n- This is a required setting.\n- Value type is bytes\n- Default value is 5 Mib\n\nThe Loggly API supports API call payloads up to 5 Mib.', true),
		createSnippet('proto', 'option', 'proto => "${1:http}"', '**[proto](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-loggly.html#plugins-outputs-loggly-proto) option**\n\n- Value type is string\n- Default value is "http"\n\nShould the log action be sent over https instead of plain http'),
		createSnippet('proxy_host', 'option', 'proxy_host => "${1:proxy_host}"', '**[proxy_host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-loggly.html#plugins-outputs-loggly-proxy_host) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nProxy Host'),
		createSnippet('proxy_password', 'option', 'proxy_password => "${1:proxy_password}"', '**[proxy_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-loggly.html#plugins-outputs-loggly-proxy_password) option**\n\n- Value type is password\n- Default value is ""\n\nProxy Password'),
		createSnippet('proxy_port', 'option', 'proxy_port => ${1:123}', '**[proxy_port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-loggly.html#plugins-outputs-loggly-proxy_port) option**\n\n- Value type is number\n- There is no default value for this setting.\n\nProxy Port'),
		createSnippet('proxy_user', 'option', 'proxy_user => "${1:proxy_user}"', '**[proxy_user](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-loggly.html#plugins-outputs-loggly-proxy_user) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nProxy Username'),
		createSnippet('retry_count', 'option', 'retry_count => ${1:5}', '**[retry_count](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-loggly.html#plugins-outputs-loggly-retry_count) option**\n\n- Value type is number\n- Default value is 5\n\nRetry count. It may be possible that the request may timeout due to slow Internet connection if such condition appears, retry_count helps in retrying request for multiple times It will try to submit request until retry_count and then halt'),
		createSnippet('tag', 'option', 'tag => "${1:tag}"', '**[tag](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-loggly.html#plugins-outputs-loggly-tag) option**\n\n- Value type is string\n\nLoggly Tags help you to find your logs in the Loggly dashboard easily. You can search for a tag in Loggly, using "tag:your_tag".')
	],
	'logstash-input-azure_event_hubs': [
		createSnippet('config_mode', 'option', 'config_mode => "${1|basic,advanced|}"$0', '**[config_mode](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-azure_event_hubs.html#plugins-inputs-azure_event_hubs-config_mode) option**\n\n- Value type is string\n- Valid entries are basic or advanced\n- Default value is basic\n\nSets configuration to either Basic configuration (default) or Advanced configuration.'),
		createSnippet('event_hubs', 'option', 'event_hubs => ["${1:event_hub}"]', '**[event_hubs](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-azure_event_hubs.html#plugins-inputs-azure_event_hubs-event_hubs) option**\n\n- Value type is array\n- No default value\n- Ignored for basic configuration\n- Required for advanced configuration\n\nDefines the Event Hubs to be read. An array of hashes where each entry is a hash of the Event Hub name and its configuration options.\n\n**_Example:_**  \n``` ruby\nazure_event_hubs {\n  config_mode => "advanced"\n  event_hubs => [\n      { "event_hub_name1" => {\n          event_hub_connection => "Endpoint=sb://example1..."\n      }},\n      { "event_hub_name2" => {\n          event_hub_connection => "Endpoint=sb://example2..."\n          storage_connection => "DefaultEndpointsProtocol=https;AccountName=example...."\n          storage_container => "my_container"\n     }}\n   ]\n   consumer_group => "logstash" # shared across all Event Hubs\n}\n```'),
		createSnippet('event_hub_connections', 'option', 'event_hub_connections => ["${1:event_hub_connection}"]', '**[event_hub_connections](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-azure_event_hubs.html#plugins-inputs-azure_event_hubs-event_hub_connections) option**\n\n- Value type is array\n- No default value\n- Required for basic configuration\n\nList of connection strings that identifies the Event Hubs to be read. Connection strings include the EntityPath for the Event Hub.\n\n**_Example:_**  \n``` ruby\nazure_event_hubs {\n   event_hub_connections => ["Endpoint=sb://example1...;EntityPath=event_hub_name1"  , "Endpoint=sb://example2...;EntityPath=event_hub_name2"  ]\n}\n```'),
		createSnippet('event_hub_connection', 'option', 'event_hub_connection => "${1:event_hub_connection}"', '**[event_hub_connection](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-azure_event_hubs.html#plugins-inputs-azure_event_hubs-event_hub_connection) option**\n\n- Value type is string\n- No default value\n- Valid only for advanced configuration\n\nConnection string that identifies the Event Hub to be read. Advanced configuration options can be set per Event Hub. This option modifies event_hub_name, and should be nested under it. (See sample.) This option accepts only one connection string.\n\n**_Example:_**  \n``` ruby\nazure_event_hubs {\n   config_mode => "advanced"\n   event_hubs => [\n     { "event_hub_name1" => {\n        event_hub_connection => "Endpoint=sb://example1...;EntityPath=event_hub_name1"\n     }}\n   ]\n}\n```'),
		createSnippet('checkpoint_interval', 'option', 'checkpoint_interval => ${1:5 seconds}', '**[checkpoint_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-azure_event_hubs.html#plugins-inputs-azure_event_hubs-checkpoint_interval) option**\n\n- Value type is number\n- Default value is 5 seconds\n- Set to 0 to disable.\n\nInterval in seconds to write checkpoints during batch processing. Checkpoints tell Logstash where to resume processing after a restart. Checkpoints are automatically written at the end of each batch, regardless of this setting.\n\n**_Example:_**  \n``` ruby\nazure_event_hubs {\n   event_hub_connections => ["Endpoint=sb://example1...;EntityPath=event_hub_name1"]\n   checkpoint_interval => 5\n}\n```'),
		createSnippet('consumer_group', 'option', 'consumer_group => "${1:\\$Default}"', '**[consumer_group](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-azure_event_hubs.html#plugins-inputs-azure_event_hubs-consumer_group) option**\n\n- Value type is string\n- Default value is $Default\n\nConsumer group used to read the Event Hub(s). Create a consumer group specifically for Logstash. Then ensure that all instances of Logstash use that consumer group so that they can work together properly.\n\n**_Example:_**  \n``` ruby\nazure_event_hubs {\n   event_hub_connections => ["Endpoint=sb://example1...;EntityPath=event_hub_name1"]\n   consumer_group => "logstash"\n}\n```'),
		createSnippet('decorate_events', 'option', 'decorate_events => ${1|false,true|}', '**[decorate_events](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-azure_event_hubs.html#plugins-inputs-azure_event_hubs-decorate_events) option**\n\n- Value type is boolean\n- Default value is false\n\nAdds metadata about the Event Hub, including Event Hub name, consumer_group, processor_host, partition, offset, sequence, timestamp, and event_size.\n\n**_Example:_**  \n``` ruby\nazure_event_hubs {\n   event_hub_connections => ["Endpoint=sb://example1...;EntityPath=event_hub_name1"]\n   decorate_events => true\n}\n```'),
		createSnippet('initial_position', 'option', 'initial_position => "${1|beginning,end,look_back|}"$0', '**[initial_position](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-azure_event_hubs.html#plugins-inputs-azure_event_hubs-initial_position) option**\n\n- Value type is string\n- Valid arguments are beginning, end, look_back\n- Default value is beginning\n\nWhen first reading from an Event Hub, start from this position:\n\n**_Example:_**  \n``` ruby\nazure_event_hubs {\n   event_hub_connections => ["Endpoint=sb://example1...;EntityPath=event_hub_name1"]\n   initial_position => "beginning"\n}\n```'),
		createSnippet('initial_position_look_back', 'option', 'initial_position_look_back => ${1:86400}', '**[initial_position_look_back](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-azure_event_hubs.html#plugins-inputs-azure_event_hubs-initial_position_look_back) option**\n\n- Value type is number\n- Default value is 86400\n- Used only if initial_position is set to look-back\n\nNumber of seconds to look back to find the initial position for pre-existing events. This option is used only if initial_position is set to look_back. If storage_connection is set, this configuration applies only the first time Logstash reads from the Event Hub.\n\n**_Example:_**  \n``` ruby\nazure_event_hubs {\n   event_hub_connections => ["Endpoint=sb://example1...;EntityPath=event_hub_name1"]\n   initial_position => "look_back"\n   initial_position_look_back => 86400\n}\n```'),
		createSnippet('max_batch_size', 'option', 'max_batch_size => ${1:125}', '**[max_batch_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-azure_event_hubs.html#plugins-inputs-azure_event_hubs-max_batch_size) option**\n\n- Value type is number\n- Default value is 125\n\nMaximum number of events retrieved and processed together. A checkpoint is created after each batch. Increasing this value may help with performance, but requires more memory.\n\n**_Example:_**  \n``` ruby\nazure_event_hubs {\n   event_hub_connections => ["Endpoint=sb://example1...;EntityPath=event_hub_name1"]\n   max_batch_size => 125\n}\n```'),
		createSnippet('storage_connection', 'option', 'storage_connection => "${1:storage_connection}"', '**[storage_connection](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-azure_event_hubs.html#plugins-inputs-azure_event_hubs-storage_connection) option**\n\n- Value type is string\n- No default value\n\nConnection string for blob account storage. Blob account storage persists the offsets between restarts, and ensures that multiple instances of Logstash process different partitions. When this value is set, restarts resume where processing left off. When this value is not set, the initial_position value is used on every restart.\n\n**_Example:_**  \n``` ruby\nazure_event_hubs {\n   event_hub_connections => ["Endpoint=sb://example1...;EntityPath=event_hub_name1"]\n   storage_connection => "DefaultEndpointsProtocol=https;AccountName=example...."\n}\n```'),
		createSnippet('storage_container', 'option', 'storage_container => "${1:storage_container}"', '**[storage_container](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-azure_event_hubs.html#plugins-inputs-azure_event_hubs-storage_container) option**\n\n- Value type is string\n- Defaults to the Event Hub name if not defined\n\nName of the storage container used to persist offsets and allow multiple instances of Logstash to work together.\n\n**_Example:_**  \n``` ruby\nazure_event_hubs {\n   event_hub_connections => ["Endpoint=sb://example1...;EntityPath=event_hub_name1"]\n   storage_connection => "DefaultEndpointsProtocol=https;AccountName=example...."\n   storage_container => "my_container"\n}\n```'),
		createSnippet('threads', 'option', 'threads => ${1:16}', '**[threads](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-azure_event_hubs.html#plugins-inputs-azure_event_hubs-threads) option**\n\n- Value type is number\n- Minimum value is 2\n- Default value is 16\n\nTotal number of threads used to process events. The value you set here applies to all Event Hubs. Even with advanced configuration, this value is a global setting, and can’t be set per event hub.\n\n**_Example:_**  \n``` ruby\nazure_event_hubs {\n   threads => 16\n}\n```')
	],
	'logstash-codec-jdots': [
	],
	'logstash-filter-environment': [
		createSnippet('add_metadata_from_env', 'option', 'add_metadata_from_env => {\n\t"${1:metadata_from_env}" => "${2:value}"\n}', '**[add_metadata_from_env](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-environment.html#plugins-filters-environment-add_metadata_from_env) option**\n\n- Value type is hash\n- Default value is {}\n\nSpecify a hash of field names and the environment variable name with the value you want imported into Logstash. For example:')
	],
	'logstash-output-influxdb': [
		createSnippet('allow_time_override', 'option', 'allow_time_override => ${1|false,true|}', '**[allow_time_override](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-influxdb.html#plugins-outputs-influxdb-allow_time_override) option**\n\n- Value type is boolean\n- Default value is false\n\nAllow the override of the time column in the event?'),
		createSnippet('coerce_values', 'option', 'coerce_values => {\n\t"${1:key}" => "${2:value}"\n}', '**[coerce_values](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-influxdb.html#plugins-outputs-influxdb-coerce_values) option**\n\n- Value type is hash\n- Default value is {}\n\nAllow value coercion'),
		createSnippet('data_points', 'option', 'data_points => {\n\t"${1:key}" => "${2:value}"\n}', '**[data_points](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-influxdb.html#plugins-outputs-influxdb-data_points) option**\n\n- This is a required setting.\n- Value type is hash\n- Default value is {}\n\nHash of key/value pairs representing data points to send to the named database Example: {\'column1\' => \'value1\', \'column2\' => \'value2\'}', true),
		createSnippet('db', 'option', 'db => "${1:statistics}"', '**[db](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-influxdb.html#plugins-outputs-influxdb-db) option**\n\n- Value type is string\n- Default value is "statistics"\n\nThe database to write - supports sprintf formatting'),
		createSnippet('exclude_fields', 'option', 'exclude_fields => ["${1:@timestamp}", "@version", "sequence", "message", "type"]', '**[exclude_fields](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-influxdb.html#plugins-outputs-influxdb-exclude_fields) option**\n\n- Value type is array\n- Default value is ["@timestamp", "@version", "sequence", "message", "type"]\n\nAn array containing the names of fields from the event to exclude from the data points'),
		createSnippet('flush_size', 'option', 'flush_size => ${1:100}', '**[flush_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-influxdb.html#plugins-outputs-influxdb-flush_size) option**\n\n- Value type is number\n- Default value is 100\n\nThis setting controls how many events will be buffered before sending a batch of events. Note that these are only batched for the same measurement'),
		createSnippet('host', 'option', 'host => "${1:host}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-influxdb.html#plugins-outputs-influxdb-host) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe hostname or IP address to reach your InfluxDB instance', true),
		createSnippet('idle_flush_time', 'option', 'idle_flush_time => ${1:1}', '**[idle_flush_time](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-influxdb.html#plugins-outputs-influxdb-idle_flush_time) option**\n\n- Value type is number\n- Default value is 1\n\nThe amount of time since last flush before a flush is forced.'),
		createSnippet('initial_delay', 'option', 'initial_delay => ${1:1}', '**[initial_delay](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-influxdb.html#plugins-outputs-influxdb-initial_delay) option**\n\n- Value type is number\n- Default value is 1\n\nThe amount of time in seconds to delay the initial retry on connection failure.'),
		createSnippet('max_retries', 'option', 'max_retries => ${1:3}', '**[max_retries](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-influxdb.html#plugins-outputs-influxdb-max_retries) option**\n\n- Value type is number\n- Default value is 3\n\nThe number of time to retry recoverable errors before dropping the events.'),
		createSnippet('measurement', 'option', 'measurement => "${1:logstash}"', '**[measurement](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-influxdb.html#plugins-outputs-influxdb-measurement) option**\n\n- Value type is string\n- Default value is "logstash"\n\nMeasurement name - supports sprintf formatting'),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-influxdb.html#plugins-outputs-influxdb-password) option**\n\n- Value type is password\n- Default value is nil\n\nThe password for the user who access to the named database'),
		createSnippet('port', 'option', 'port => ${1:8086}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-influxdb.html#plugins-outputs-influxdb-port) option**\n\n- Value type is number\n- Default value is 8086\n\nThe port for InfluxDB'),
		createSnippet('retention_policy', 'option', 'retention_policy => "${1:autogen}"', '**[retention_policy](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-influxdb.html#plugins-outputs-influxdb-retention_policy) option**\n\n- Value type is string\n- Default value is "autogen"\n\nThe retention policy to use'),
		createSnippet('send_as_tags', 'option', 'send_as_tags => ["${1:host}"]', '**[send_as_tags](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-influxdb.html#plugins-outputs-influxdb-send_as_tags) option**\n\n- Value type is array\n- Default value is ["host"]\n\nAn array containing the names of fields to send to Influxdb as tags instead of fields. Influxdb 0.9 convention is that values that do not change every request should be considered metadata and given as tags. Tags are only sent when present in data_points or if use_event_fields_for_data_points is true.'),
		createSnippet('ssl', 'option', 'ssl => ${1|false,true|}', '**[ssl](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-influxdb.html#plugins-outputs-influxdb-ssl) option**\n\n- Value type is boolean\n- Default value is false\n\nEnable SSL/TLS secured communication to InfluxDB'),
		createSnippet('time_precision', 'option', 'time_precision => "${1|ms,u,n,s,m,h|}"$0', '**[time_precision](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-influxdb.html#plugins-outputs-influxdb-time_precision) option**\n\n- Value can be any of: n, u, ms, s, m, h\n- Default value is "ms"\n\nSet the level of precision of time'),
		createSnippet('use_event_fields_for_data_points', 'option', 'use_event_fields_for_data_points => ${1|false,true|}', '**[use_event_fields_for_data_points](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-influxdb.html#plugins-outputs-influxdb-use_event_fields_for_data_points) option**\n\n- Value type is boolean\n- Default value is false\n\nAutomatically use fields from the event as the data points sent to Influxdb'),
		createSnippet('user', 'option', 'user => "${1:user}"', '**[user](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-influxdb.html#plugins-outputs-influxdb-user) option**\n\n- Value type is string\n- Default value is nil\n\nThe user who has access to the named database')
	],
	'logstash-codec-netflow': [
		createSnippet('cache_save_path', 'option', 'cache_save_path => "${1:/path/to/file}"', '**[cache_save_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-netflow.html#plugins-codecs-netflow-cache_save_path) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nEnables the template cache and saves it in the specified directory. This minimizes data loss after Logstash restarts because the codec doesn’t have to wait for the arrival of templates, but instead reload already received templates received during previous runs.'),
		createSnippet('cache_ttl', 'option', 'cache_ttl => ${1:4000}', '**[cache_ttl](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-netflow.html#plugins-codecs-netflow-cache_ttl) option**\n\n- Value type is number\n- Default value is 4000\n\nNetflow v9/v10 template cache TTL (seconds)'),
		createSnippet('include_flowset_id', 'option', 'include_flowset_id => ${1|false,true|}', '**[include_flowset_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-netflow.html#plugins-codecs-netflow-include_flowset_id) option**\n\n- Value type is boolean\n- Default value is false\n\nOnly makes sense for ipfix, v9 already includes this Setting to true will include the flowset_id in events Allows you to work with sequences, for instance with the aggregate filter'),
		createSnippet('ipfix_definitions', 'option', 'ipfix_definitions => "${1:/path/to/file}"', '**[ipfix_definitions](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-netflow.html#plugins-codecs-netflow-ipfix_definitions) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nOverride YAML file containing IPFIX field definitions'),
		createSnippet('netflow_definitions', 'option', 'netflow_definitions => "${1:/path/to/file}"', '**[netflow_definitions](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-netflow.html#plugins-codecs-netflow-netflow_definitions) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nOverride YAML file containing Netflow field definitions'),
		createSnippet('target', 'option', 'target => "${1:netflow}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-netflow.html#plugins-codecs-netflow-target) option**\n\n- Value type is string\n- Default value is "netflow"\n\nSpecify into what field you want the Netflow data.'),
		createSnippet('versions', 'option', 'versions => ${1:[5, 9, 10]}', '**[versions](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-netflow.html#plugins-codecs-netflow-versions) option**\n\n- Value type is array\n- Default value is [5, 9, 10]\n\nSpecify which Netflow versions you will accept.')
	],
	'logstash-codec': [
		createSnippet('avro', 'plugin', 'avro {\n\tschema_uri => "${1:schema_uri}"\n}', '**[avro](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-avro.html) codec**\n\nReads serialized Avro records as Logstash events\n\n**_Example:_**  \n``` ruby\ninput {\n  kafka {\n    codec => avro {\n        schema_uri => "/tmp/schema.avsc"\n    }\n  }\n}\nfilter {\n  ...\n}\noutput {\n  ...\n}\n```'),
		createSnippet('cef', 'plugin', 'cef {\n\t$0\n}', '**[cef](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-cef.html) codec**\n\nReads the ArcSight Common Event Format (CEF).\n\n**_Example:_**  \n``` ruby\n    input {\n      tcp {\n        # ...\n        codec => cef {\n          ecs_compatibility => v1\n        }\n      }\n    }\n```'),
		createSnippet('cloudfront', 'plugin', 'cloudfront {\n\t$0\n}', '**[cloudfront](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-cloudfront.html) codec**\n\nReads AWS CloudFront reports'),
		createSnippet('cloudtrail', 'plugin', 'cloudtrail {\n\t$0\n}', '**[cloudtrail](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-cloudtrail.html) codec**\n\nReads AWS CloudTrail log files'),
		createSnippet('collectd', 'plugin', 'collectd {\n\t$0\n}', '**[collectd](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-collectd.html) codec**\n\nReads events from the collectd binary protocol using UDP.\n\n**_Example:_**  \n``` ruby\n    input {\n      udp {\n        port => 25826\n        buffer_size => 1452\n        codec => collectd { }\n      }\n    }\n```'),
		createSnippet('csv', 'plugin', 'csv {\n\t$0\n}', '**[csv](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-csv.html) codec**\n\nTakes CSV data, parses it, and passes it along.\n\n**_Example:_**  \n``` ruby\n    filter {\n      csv {\n        convert => { "column1" => "integer", "column2" => "boolean" }\n      }\n    }\n```'),
		createSnippet('dots', 'plugin', 'dots {\n\t$0\n}', '**[dots](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-dots.html) codec**\n\nSends 1 dot per event to stdout for performance tracking'),
		createSnippet('edn', 'plugin', 'edn {\n\t$0\n}', '**[edn](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-edn.html) codec**\n\nReads EDN format data\n\n**_Example:_**  \n``` ruby\n    input {\n      tcp {\n        port => 4242\n        codec => edn {\n          target => "[document]"\n        }\n      }\n    }\n```'),
		createSnippet('edn_lines', 'plugin', 'edn_lines {\n\t$0\n}', '**[edn_lines](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-edn_lines.html) codec**\n\nReads newline-delimited EDN format data\n\n**_Example:_**  \n``` ruby\n    input {\n      tcp {\n        port => 4242\n        codec => edn_lines {\n          target => "[document]"\n        }\n      }\n    }\n```'),
		createSnippet('es_bulk', 'plugin', 'es_bulk {\n\t$0\n}', '**[es_bulk](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-es_bulk.html) codec**\n\nReads the Elasticsearch bulk format into separate events, along with metadata\n\n**_Example:_**  \n``` ruby\ninput {\n  kafka {\n    codec => es_bulk {\n        target => "[document]"\n    }\n  }\n}\n```'),
		createSnippet('fluent', 'plugin', 'fluent {\n\t$0\n}', '**[fluent](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-fluent.html) codec**\n\nReads the fluentd msgpack schema\n\n**_Example:_**  \n``` ruby\n    input {\n      tcp {\n        codec => fluent {\n          target => "[logs]"\n        }\n        port => 4000\n      }\n    }\n```'),
		createSnippet('graphite', 'plugin', 'graphite {\n\t$0\n}', '**[graphite](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-graphite.html) codec**\n\nReads graphite formatted lines'),
		createSnippet('gzip_lines', 'plugin', 'gzip_lines {\n\t$0\n}', '**[gzip_lines](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-gzip_lines.html) codec**\n\nReads gzip encoded content'),
		createSnippet('jdots', 'plugin', 'jdots {\n\t$0\n}', '**[jdots](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-jdots.html) codec**\n\nRenders each processed event as a dot'),
		createSnippet('java_line', 'plugin', 'java_line {\n\t$0\n}', '**[java_line](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-java_line.html) codec**\n\nEncodes and decodes line-oriented text data'),
		createSnippet('java_plain', 'plugin', 'java_plain {\n\t$0\n}', '**[java_plain](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-java_plain.html) codec**\n\nProcesses text data with no delimiters between events'),
		createSnippet('json', 'plugin', 'json {\n\t$0\n}', '**[json](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-json.html) codec**\n\nReads JSON formatted content, creating one event per element in a JSON array\n\n**_Example:_**  \n``` ruby\n    input {\n      http {\n        codec => json {\n          target => "[document]"\n        }\n      }\n    }\n```'),
		createSnippet('json_lines', 'plugin', 'json_lines {\n\t$0\n}', '**[json_lines](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-json_lines.html) codec**\n\nReads newline-delimited JSON\n\n**_Example:_**  \n``` ruby\n    input {\n      http {\n        codec => json_lines {\n          target => "[document]"\n        }\n      }\n    }\n```'),
		createSnippet('line', 'plugin', 'line {\n\t$0\n}', '**[line](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-line.html) codec**\n\nReads line-oriented text data'),
		createSnippet('msgpack', 'plugin', 'msgpack {\n\t$0\n}', '**[msgpack](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-msgpack.html) codec**\n\nReads MessagePack encoded content\n\n**_Example:_**  \n``` ruby\n    input {\n      tcp {\n        port => 4242\n        codec => msgpack {\n          target => "[document]"\n        }\n      }\n    }\n```'),
		createSnippet('multiline', 'plugin', 'multiline {\n\tpattern => "${1:pattern}"\n\twhat => "${2|previous,next|}"$3\n}', '**[multiline](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-multiline.html) codec**\n\nMerges multiline messages into a single event\n\n**_Example:_**  \n``` ruby\n    input {\n      stdin {\n        codec => multiline {\n          pattern => "pattern, a regexp"\n          negate => "true" or "false"\n          what => "previous" or "next"\n        }\n      }\n    }\n```'),
		createSnippet('netflow', 'plugin', 'netflow {\n\t$0\n}', '**[netflow](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-netflow.html) codec**\n\nReads Netflow v5 and Netflow v9 data'),
		createSnippet('nmap', 'plugin', 'nmap {\n\t$0\n}', '**[nmap](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-nmap.html) codec**\n\nReads Nmap data in XML format'),
		createSnippet('plain', 'plugin', 'plain {\n\t$0\n}', '**[plain](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-plain.html) codec**\n\nReads plaintext with no delimiting between events'),
		createSnippet('protobuf', 'plugin', 'protobuf {\n\tclass_name => "${1:class_name}"\n\tprotobuf_version => ${2:2}\n}', '**[protobuf](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-protobuf.html) codec**\n\nReads protobuf messages and converts to Logstash Events'),
		createSnippet('rubydebug', 'plugin', 'rubydebug {\n\t$0\n}', '**[rubydebug](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-rubydebug.html) codec**\n\nApplies the Ruby Awesome Print library to Logstash events')
	],
	'logstash-codec-cloudtrail': [
		createSnippet('charset', 'option', 'charset => "${1|UTF-8,ASCII-8BIT,US-ASCII,Big5,Big5-HKSCS,Big5-UAO,CP949,Emacs-Mule,EUC-JP,EUC-KR,EUC-TW,GB2312,GB18030,GBK,ISO-8859-1,ISO-8859-2,ISO-8859-3,ISO-8859-4,ISO-8859-5,ISO-8859-6,ISO-8859-7,ISO-8859-8,ISO-8859-9,ISO-8859-10,ISO-8859-11,ISO-8859-13,ISO-8859-14,ISO-8859-15,ISO-8859-16,KOI8-R,KOI8-U,Shift_JIS,UTF-16BE,UTF-16LE,UTF-32BE,UTF-32LE,Windows-31J,Windows-1250,Windows-1251,Windows-1252,IBM437,IBM737,IBM775,CP850,IBM852,CP852,IBM855,CP855,IBM857,IBM860,IBM861,IBM862,IBM863,IBM864,IBM865,IBM866,IBM869,Windows-1258,GB1988,macCentEuro,macCroatian,macCyrillic,macGreek,macIceland,macRoman,macRomania,macThai,macTurkish,macUkraine,CP950,CP951,IBM037,stateless-ISO-2022-JP,eucJP-ms,CP51932,EUC-JIS-2004,GB12345,ISO-2022-JP,ISO-2022-JP-2,CP50220,CP50221,Windows-1256,Windows-1253,Windows-1255,Windows-1254,TIS-620,Windows-874,Windows-1257,MacJapanese,UTF-7,UTF8-MAC,UTF-16,UTF-32,UTF8-DoCoMo,SJIS-DoCoMo,UTF8-KDDI,SJIS-KDDI,ISO-2022-JP-KDDI,stateless-ISO-2022-JP-KDDI,UTF8-SoftBank,SJIS-SoftBank,BINARY,CP437,CP737,CP775,IBM850,CP857,CP860,CP861,CP862,CP863,CP864,CP865,CP866,CP869,CP1258,Big5-HKSCS:2008,ebcdic-cp-us,eucJP,euc-jp-ms,EUC-JISX0213,eucKR,eucTW,EUC-CN,eucCN,CP936,ISO2022-JP,ISO2022-JP2,ISO8859-1,ISO8859-2,ISO8859-3,ISO8859-4,ISO8859-5,ISO8859-6,CP1256,ISO8859-7,CP1253,ISO8859-8,CP1255,ISO8859-9,CP1254,ISO8859-10,ISO8859-11,CP874,ISO8859-13,CP1257,ISO8859-14,ISO8859-15,ISO8859-16,CP878,MacJapan,ASCII,ANSI_X3.4-1968,646,CP65000,CP65001,UTF-8-MAC,UTF-8-HFS,UCS-2BE,UCS-4BE,UCS-4LE,CP932,csWindows31J,SJIS,PCK,CP1250,CP1251,CP1252,external,locale|}"$0', '**[charset](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-cloudtrail.html#plugins-codecs-cloudtrail-charset) option**\n\n- Value can be any of: ASCII-8BIT, UTF-8, US-ASCII, Big5, Big5-HKSCS, Big5-UAO, CP949, Emacs-Mule, EUC-JP, EUC-KR, EUC-TW, GB2312, GB18030, GBK, ISO-8859-1, ISO-8859-2, ISO-8859-3, ISO-8859-4, ISO-8859-5, ISO-8859-6, ISO-8859-7, ISO-8859-8, ISO-8859-9, ISO-8859-10, ISO-8859-11, ISO-8859-13, ISO-8859-14, ISO-8859-15, ISO-8859-16, KOI8-R, KOI8-U, Shift_JIS, UTF-16BE, UTF-16LE, UTF-32BE, UTF-32LE, Windows-31J, Windows-1250, Windows-1251, Windows-1252, IBM437, IBM737, IBM775, CP850, IBM852, CP852, IBM855, CP855, IBM857, IBM860, IBM861, IBM862, IBM863, IBM864, IBM865, IBM866, IBM869, Windows-1258, GB1988, macCentEuro, macCroatian, macCyrillic, macGreek, macIceland, macRoman, macRomania, macThai, macTurkish, macUkraine, CP950, CP951, IBM037, stateless-ISO-2022-JP, eucJP-ms, CP51932, EUC-JIS-2004, GB12345, ISO-2022-JP, ISO-2022-JP-2, CP50220, CP50221, Windows-1256, Windows-1253, Windows-1255, Windows-1254, TIS-620, Windows-874, Windows-1257, MacJapanese, UTF-7, UTF8-MAC, UTF-16, UTF-32, UTF8-DoCoMo, SJIS-DoCoMo, UTF8-KDDI, SJIS-KDDI, ISO-2022-JP-KDDI, stateless-ISO-2022-JP-KDDI, UTF8-SoftBank, SJIS-SoftBank, BINARY, CP437, CP737, CP775, IBM850, CP857, CP860, CP861, CP862, CP863, CP864, CP865, CP866, CP869, CP1258, Big5-HKSCS:2008, ebcdic-cp-us, eucJP, euc-jp-ms, EUC-JISX0213, eucKR, eucTW, EUC-CN, eucCN, CP936, ISO2022-JP, ISO2022-JP2, ISO8859-1, ISO8859-2, ISO8859-3, ISO8859-4, ISO8859-5, ISO8859-6, CP1256, ISO8859-7, CP1253, ISO8859-8, CP1255, ISO8859-9, CP1254, ISO8859-10, ISO8859-11, CP874, ISO8859-13, CP1257, ISO8859-14, ISO8859-15, ISO8859-16, CP878, MacJapan, ASCII, ANSI_X3.4-1968, 646, CP65000, CP65001, UTF-8-MAC, UTF-8-HFS, UCS-2BE, UCS-4BE, UCS-4LE, CP932, csWindows31J, SJIS, PCK, CP1250, CP1251, CP1252, external, locale\n- Default value is "UTF-8"')
	],
	'logstash-input-http_poller': [
		createSnippet('automatic_retries', 'option', 'automatic_retries => ${1:1}', '**[automatic_retries](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-automatic_retries) option**\n\n- Value type is number\n- Default value is 1\n\nHow many times should the client retry a failing URL. We highly recommend NOT setting this value to zero if keepalive is enabled. Some servers incorrectly end keepalives early requiring a retry! Note: if retry_non_idempotent is set only GET, HEAD, PUT, DELETE, OPTIONS, and TRACE requests will be retried.'),
		createSnippet('cacert', 'option', 'cacert => "${1:/path/to/file}"', '**[cacert](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-cacert) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you need to use a custom X.509 CA (.pem certs) specify the path to that here'),
		createSnippet('client_cert', 'option', 'client_cert => "${1:/path/to/file}"', '**[client_cert](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-client_cert) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you’d like to use a client certificate (note, most people don’t want this) set the path to the x509 cert here'),
		createSnippet('client_key', 'option', 'client_key => "${1:/path/to/file}"', '**[client_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-client_key) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you’re using a client certificate specify the path to the encryption key here'),
		createSnippet('connect_timeout', 'option', 'connect_timeout => ${1:10}', '**[connect_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-connect_timeout) option**\n\n- Value type is number\n- Default value is 10\n\nTimeout (in seconds) to wait for a connection to be established. Default is 10s'),
		createSnippet('cookies', 'option', 'cookies => ${1|true,false|}', '**[cookies](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-cookies) option**\n\n- Value type is boolean\n- Default value is true\n\nEnable cookie support. With this enabled the client will persist cookies across requests as a normal web browser would. Enabled by default'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: unstructured data added at root level v1: uses error, url and http fields that are compatible with Elastic Common Schema\n- disabled: unstructured data added at root level\n- v1: uses error, url and http fields that are compatible with Elastic Common Schema\n\nSupported values are:'),
		createSnippet('follow_redirects', 'option', 'follow_redirects => ${1|true,false|}', '**[follow_redirects](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-follow_redirects) option**\n\n- Value type is boolean\n- Default value is true\n\nShould redirects be followed? Defaults to true'),
		createSnippet('keepalive', 'option', 'keepalive => ${1|true,false|}', '**[keepalive](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-keepalive) option**\n\n- Value type is boolean\n- Default value is true\n\nTurn this on to enable HTTP keepalive support. We highly recommend setting automatic_retries to at least one with this to fix interactions with broken keepalive implementations.'),
		createSnippet('keystore', 'option', 'keystore => "${1:/path/to/file}"', '**[keystore](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-keystore) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you need to use a custom keystore (.jks) specify that here. This does not work with .pem keys!'),
		createSnippet('keystore_password', 'option', 'keystore_password => "${1:keystore_password}"', '**[keystore_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-keystore_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nSpecify the keystore password here. Note, most .jks files created with keytool require a password!'),
		createSnippet('keystore_type', 'option', 'keystore_type => "${1:JKS}"', '**[keystore_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-keystore_type) option**\n\n- Value type is string\n- Default value is "JKS"\n\nSpecify the keystore type here. One of JKS or PKCS12. Default is JKS'),
		createSnippet('metadata_target', 'option', 'metadata_target => "${1:@metadata}"', '**[metadata_target](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-metadata_target) option**\n\n- Value type is string\n- Default value is "@metadata"\n\nIf you’d like to work with the request/response metadata. Set this value to the name of the field you’d like to store a nested hash of metadata.'),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nPassword to be used in conjunction with user for HTTP authentication.'),
		createSnippet('pool_max', 'option', 'pool_max => ${1:50}', '**[pool_max](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-pool_max) option**\n\n- Value type is number\n- Default value is 50\n\nMax number of concurrent connections. Defaults to 50'),
		createSnippet('pool_max_per_route', 'option', 'pool_max_per_route => ${1:25}', '**[pool_max_per_route](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-pool_max_per_route) option**\n\n- Value type is number\n- Default value is 25\n\nMax number of concurrent connections to a single host. Defaults to 25'),
		createSnippet('proxy', 'option', 'proxy => "${1:proxy}"', '**[proxy](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-proxy) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nIf you’d like to use an HTTP proxy . This supports multiple configuration syntaxes:'),
		createSnippet('request_timeout', 'option', 'request_timeout => ${1:60}', '**[request_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-request_timeout) option**\n\n- Value type is number\n- Default value is 60\n\nTimeout (in seconds) for the entire request.'),
		createSnippet('retry_non_idempotent', 'option', 'retry_non_idempotent => ${1|false,true|}', '**[retry_non_idempotent](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-retry_non_idempotent) option**\n\n- Value type is boolean\n- Default value is false\n\nIf automatic_retries is enabled this will cause non-idempotent HTTP verbs (such as POST) to be retried.'),
		createSnippet('schedule', 'option', 'schedule => {\n\t"${1:key}" => "${2:value}"\n}', '**[schedule](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-schedule) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nSchedule of when to periodically poll from the urls Format: A hash with + key: "cron" | "every" | "in" | "at" + value: string Examples: a) { "every" ⇒ "1h" } b) { "cron" ⇒ "* * * * * UTC" } See: rufus/scheduler for details about different schedule options and value string format', true),
		createSnippet('socket_timeout', 'option', 'socket_timeout => ${1:10}', '**[socket_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-socket_timeout) option**\n\n- Value type is number\n- Default value is 10\n\nTimeout (in seconds) to wait for data on the socket. Default is 10s'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-target) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nDefine the target field for placing the received data. If this setting is omitted, the data will be stored at the root (top level) of the event.'),
		createSnippet('truststore', 'option', 'truststore => "${1:/path/to/file}"', '**[truststore](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-truststore) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you need to use a custom truststore (.jks) specify that here. This does not work with .pem certs!'),
		createSnippet('truststore_password', 'option', 'truststore_password => "${1:truststore_password}"', '**[truststore_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-truststore_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nSpecify the truststore password here. Note, most .jks files created with keytool require a password!'),
		createSnippet('truststore_type', 'option', 'truststore_type => "${1:JKS}"', '**[truststore_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-truststore_type) option**\n\n- Value type is string\n- Default value is "JKS"\n\nSpecify the truststore type here. One of JKS or PKCS12. Default is JKS'),
		createSnippet('urls', 'option', 'urls => {\n\t"${1:key}" => "${2:value}"\n}', '**[urls](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-urls) option**\n\n- This is a required setting.\n- Value type is hash\n- There is no default value for this setting.\n\nA Hash of urls in this format : "name" => "url". The name and the url will be passed in the outputted event.', true),
		createSnippet('user', 'option', 'user => "${1:user}"', '**[user](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-user) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nUsername to use with HTTP authentication for ALL requests. Note that you can also set this per-URL. If you set this you must also set the password option.'),
		createSnippet('validate_after_inactivity', 'option', 'validate_after_inactivity => ${1:200}', '**[validate_after_inactivity](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html#plugins-inputs-http_poller-validate_after_inactivity) option**\n\n- Value type is number\n- Default value is 200\n\nHow long to wait before checking for a stale connection to determine if a keepalive request is needed. Consider setting this value lower than the default, possibly to 0, if you get connection errors regularly.')
	],
	'logstash-output-file': [
		createSnippet('create_if_deleted', 'option', 'create_if_deleted => ${1|true,false|}', '**[create_if_deleted](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-file.html#plugins-outputs-file-create_if_deleted) option**\n\n- Value type is boolean\n- Default value is true\n\nIf the configured file is deleted, but an event is handled by the plugin, the plugin will recreate the file. Default ⇒ true'),
		createSnippet('dir_mode', 'option', 'dir_mode => ${1:-1}', '**[dir_mode](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-file.html#plugins-outputs-file-dir_mode) option**\n\n- Value type is number\n- Default value is -1\n\nDir access mode to use. Note that due to the bug in jruby system umask is ignored on linux: https://github.com/jruby/jruby/issues/3426 Setting it to -1 uses default OS value. Example: "dir_mode" => 0750'),
		createSnippet('file_mode', 'option', 'file_mode => ${1:-1}', '**[file_mode](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-file.html#plugins-outputs-file-file_mode) option**\n\n- Value type is number\n- Default value is -1\n\nFile access mode to use. Note that due to the bug in jruby system umask is ignored on linux: https://github.com/jruby/jruby/issues/3426 Setting it to -1 uses default OS value. Example: "file_mode" => 0640'),
		createSnippet('filename_failure', 'option', 'filename_failure => "${1:_filepath_failures}"', '**[filename_failure](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-file.html#plugins-outputs-file-filename_failure) option**\n\n- Value type is string\n- Default value is "_filepath_failures"\n\nIf the generated path is invalid, the events will be saved into this file and inside the defined path.'),
		createSnippet('flush_interval', 'option', 'flush_interval => ${1:2}', '**[flush_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-file.html#plugins-outputs-file-flush_interval) option**\n\n- Value type is number\n- Default value is 2\n\nFlush interval (in seconds) for flushing writes to log files. 0 will flush on every message.'),
		createSnippet('gzip', 'option', 'gzip => ${1|false,true|}', '**[gzip](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-file.html#plugins-outputs-file-gzip) option**\n\n- Value type is boolean\n- Default value is false\n\nGzip the output stream before writing to disk.'),
		createSnippet('path', 'option', 'path => "${1:path}"', '**[path](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-file.html#plugins-outputs-file-path) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe path to the file to write. Event fields can be used here, like /var/log/logstash/%{host}/%{application} One may also utilize the path option for date-based log rotation via the joda time format. This will use the event timestamp. E.g.: path => "./test-%{+YYYY-MM-dd}.txt" to create ./test-2013-05-29.txt', true),
		createSnippet('stale_cleanup_interval', 'option', 'stale_cleanup_interval => ${1:10}', '**[stale_cleanup_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-file.html#plugins-outputs-file-stale_cleanup_interval) option**\n\n- Value type is number\n- Default value is 10\n\nDefines the interval, in seconds, between the stale files cleanup runs. The stale files cleanup cycle closes inactive files (i.e files not written to since the last cycle).'),
		createSnippet('write_behavior', 'option', 'write_behavior => "${1:append}"', '**[write_behavior](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-file.html#plugins-outputs-file-write_behavior) option**\n\n- Value type is string\n- Default value is append\n\nIf append, the file will be opened for appending and each new event will be written at the end of the file. If overwrite, the file will be truncated before writing and only the most recent event will appear in the file.')
	],
	'logstash-filter-sleep': [
		createSnippet('every', 'option', 'every => "${1:1}"', '**[every](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-sleep.html#plugins-filters-sleep-every) option**\n\n- Value type is string\n- Default value is 1\n\nSleep on every N’th. This option is ignored in replay mode.\n\n**_Example:_**  \n``` ruby\n    filter {\n      sleep {\n        time => "1"   # Sleep 1 second\n        every => 10   # on every 10th event\n      }\n    }\n```'),
		createSnippet('replay', 'option', 'replay => ${1|false,true|}', '**[replay](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-sleep.html#plugins-filters-sleep-replay) option**\n\n- Value type is boolean\n- Default value is false\n\nEnable replay mode.\n\n**_Example:_**  \n``` ruby\n    filter {\n      sleep {\n        time => 2\n        replay => true\n      }\n    }\n```'),
		createSnippet('time', 'option', 'time => "${1:time}"', '**[time](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-sleep.html#plugins-filters-sleep-time) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe length of time to sleep, in seconds, for every event.\n\n**_Example:_**  \n``` ruby\n    filter {\n      sleep {\n        # Sleep 1 second for every event.\n        time => "1"\n      }\n    }\n```')
	],
	'logstash-filter-cidr': [
		createSnippet('address', 'option', 'address => ["${1:address}"]', '**[address](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-cidr.html#plugins-filters-cidr-address) option**\n\n- Value type is array\n- Default value is []\n\nThe IP address(es) to check with. Example:\n\n**_Example:_**  \n``` ruby\n    filter {\n      cidr {\n        add_tag => [ "testnet" ]\n        address => [ "%{src_ip}", "%{dst_ip}" ]\n        network => [ "192.0.2.0/24" ]\n      }\n    }\n```'),
		createSnippet('network', 'option', 'network => ["${1:network}"]', '**[network](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-cidr.html#plugins-filters-cidr-network) option**\n\n- Value type is array\n- Default value is []\n\nThe IP network(s) to check against. Example:\n\n**_Example:_**  \n``` ruby\n    filter {\n      cidr {\n        add_tag => [ "linklocal" ]\n        address => [ "%{clientip}" ]\n        network => [ "169.254.0.0/16", "fe80::/64" ]\n      }\n    }\n```'),
		createSnippet('network_path', 'option', 'network_path => "${1:/path/to/file}"', '**[network_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-cidr.html#plugins-filters-cidr-network_path) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nThe full path of the external file containing the networks the filter should check with. Networks are separated by a separator character defined in separator.'),
		createSnippet('refresh_interval', 'option', 'refresh_interval => ${1:600}', '**[refresh_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-cidr.html#plugins-filters-cidr-refresh_interval) option**\n\n- Value type is number\n- Default value is 600\n\nWhen using an external file, this setting will indicate how frequently (in seconds) Logstash will check the file for updates.'),
		createSnippet('separator', 'option', 'separator => "${1:\n}"', '**[separator](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-cidr.html#plugins-filters-cidr-separator) option**\n\n- Value type is string\n- Default value is \n\n\nSeparator character used for parsing networks from the external file specified by network_path. Defaults to newline \n character.')
	],
	'logstash-filter-wurfl_device_detection': [
	],
	'logstash-input-couchdb_changes': [
		createSnippet('always_reconnect', 'option', 'always_reconnect => ${1|true,false|}', '**[always_reconnect](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-couchdb_changes.html#plugins-inputs-couchdb_changes-always_reconnect) option**\n\n- Value type is boolean\n- Default value is true\n\nReconnect flag. When true, always try to reconnect after a failure'),
		createSnippet('ca_file', 'option', 'ca_file => "${1:/path/to/file}"', '**[ca_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-couchdb_changes.html#plugins-inputs-couchdb_changes-ca_file) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nPath to a CA certificate file, used to validate certificates'),
		createSnippet('db', 'option', 'db => "${1:db}"', '**[db](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-couchdb_changes.html#plugins-inputs-couchdb_changes-db) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe CouchDB db to connect to. Required parameter.', true),
		createSnippet('heartbeat', 'option', 'heartbeat => ${1:1000}', '**[heartbeat](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-couchdb_changes.html#plugins-inputs-couchdb_changes-heartbeat) option**\n\n- Value type is number\n- Default value is 1000\n\nLogstash connects to CouchDB’s _changes with feed=continuous The heartbeat is how often (in milliseconds) Logstash will ping CouchDB to ensure the connection is maintained. Changing this setting is not recommended unless you know what you are doing.'),
		createSnippet('host', 'option', 'host => "${1:localhost}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-couchdb_changes.html#plugins-inputs-couchdb_changes-host) option**\n\n- Value type is string\n- Default value is "localhost"\n\nIP or hostname of your CouchDB instance'),
		createSnippet('ignore_attachments', 'option', 'ignore_attachments => ${1|true,false|}', '**[ignore_attachments](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-couchdb_changes.html#plugins-inputs-couchdb_changes-ignore_attachments) option**\n\n- Value type is boolean\n- Default value is true\n\nFuture feature! Until implemented, changing this from the default will not do anything.'),
		createSnippet('initial_sequence', 'option', 'initial_sequence => ${1:123}', '**[initial_sequence](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-couchdb_changes.html#plugins-inputs-couchdb_changes-initial_sequence) option**\n\n- Value type is number\n- There is no default value for this setting.\n\nIf unspecified, Logstash will attempt to read the last sequence number from the sequence_path file. If that is empty or non-existent, it will begin with 0 (the beginning).'),
		createSnippet('keep_id', 'option', 'keep_id => ${1|false,true|}', '**[keep_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-couchdb_changes.html#plugins-inputs-couchdb_changes-keep_id) option**\n\n- Value type is boolean\n- Default value is false\n\nPreserve the CouchDB document id "_id" value in the output.'),
		createSnippet('keep_revision', 'option', 'keep_revision => ${1|false,true|}', '**[keep_revision](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-couchdb_changes.html#plugins-inputs-couchdb_changes-keep_revision) option**\n\n- Value type is boolean\n- Default value is false\n\nPreserve the CouchDB document revision "_rev" value in the output.'),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-couchdb_changes.html#plugins-inputs-couchdb_changes-password) option**\n\n- Value type is password\n- Default value is nil\n\nPassword, if authentication is needed to connect to CouchDB'),
		createSnippet('port', 'option', 'port => ${1:5984}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-couchdb_changes.html#plugins-inputs-couchdb_changes-port) option**\n\n- Value type is number\n- Default value is 5984\n\nPort of your CouchDB instance.'),
		createSnippet('reconnect_delay', 'option', 'reconnect_delay => ${1:10}', '**[reconnect_delay](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-couchdb_changes.html#plugins-inputs-couchdb_changes-reconnect_delay) option**\n\n- Value type is number\n- Default value is 10\n\nReconnect delay: time between reconnect attempts, in seconds.'),
		createSnippet('secure', 'option', 'secure => ${1|false,true|}', '**[secure](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-couchdb_changes.html#plugins-inputs-couchdb_changes-secure) option**\n\n- Value type is boolean\n- Default value is false\n\nConnect to CouchDB’s _changes feed securely (via https) Default: false (via http)'),
		createSnippet('sequence_path', 'option', 'sequence_path => "${1:sequence_path}"', '**[sequence_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-couchdb_changes.html#plugins-inputs-couchdb_changes-sequence_path) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nFile path where the last sequence number in the _changes stream is stored. If unset it will write to $HOME/.couchdb_seq'),
		createSnippet('timeout', 'option', 'timeout => ${1:123}', '**[timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-couchdb_changes.html#plugins-inputs-couchdb_changes-timeout) option**\n\n- Value type is number\n- There is no default value for this setting.\n\nTimeout: Number of milliseconds to wait for new data before terminating the connection. If a timeout is set it will disable the heartbeat configuration option.'),
		createSnippet('username', 'option', 'username => "${1:username}"', '**[username](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-couchdb_changes.html#plugins-inputs-couchdb_changes-username) option**\n\n- Value type is string\n- Default value is nil\n\nUsername, if authentication is needed to connect to CouchDB')
	],
	'logstash-output-pipeline': [
		createSnippet('send_to', 'option', 'send_to => ["${1:target_pipeline_address}"]', '**[send_to](https://www.elastic.co/guide/en/logstash/7.17/pipeline-to-pipeline.html) option**\n\nTarget pipeline addresses where events are sent', true)
	],
	'logstash-output-redmine': [
		createSnippet('assigned_to_id', 'option', 'assigned_to_id => ${1:123}', '**[assigned_to_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redmine.html#plugins-outputs-redmine-assigned_to_id) option**\n\n- Value type is number\n- Default value is nil\n\nredmine issue assigned_to not required for post_issue'),
		createSnippet('categorie_id', 'option', 'categorie_id => ${1:123}', '**[categorie_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redmine.html#plugins-outputs-redmine-categorie_id) option**\n\n- Value type is number\n- Default value is nil\n\nnot required for post_issue'),
		createSnippet('description', 'option', 'description => "${1:%{message\\}}"', '**[description](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redmine.html#plugins-outputs-redmine-description) option**\n\n- Value type is string\n- Default value is "%{message}"\n\nredmine issue description required'),
		createSnippet('fixed_version_id', 'option', 'fixed_version_id => ${1:123}', '**[fixed_version_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redmine.html#plugins-outputs-redmine-fixed_version_id) option**\n\n- Value type is number\n- Default value is nil\n\nredmine issue fixed_version_id'),
		createSnippet('parent_issue_id', 'option', 'parent_issue_id => ${1:123}', '**[parent_issue_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redmine.html#plugins-outputs-redmine-parent_issue_id) option**\n\n- Value type is number\n- Default value is nil\n\nredmine issue parent_issue_id not required for post_issue'),
		createSnippet('priority_id', 'option', 'priority_id => ${1:123}', '**[priority_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redmine.html#plugins-outputs-redmine-priority_id) option**\n\n- This is a required setting.\n- Value type is number\n- There is no default value for this setting.\n\nredmine issue priority_id required', true),
		createSnippet('project_id', 'option', 'project_id => ${1:123}', '**[project_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redmine.html#plugins-outputs-redmine-project_id) option**\n\n- This is a required setting.\n- Value type is number\n- There is no default value for this setting.\n\nredmine issue projet_id required', true),
		createSnippet('ssl', 'option', 'ssl => ${1|false,true|}', '**[ssl](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redmine.html#plugins-outputs-redmine-ssl) option**\n\n- Value type is boolean\n- Default value is false'),
		createSnippet('status_id', 'option', 'status_id => ${1:123}', '**[status_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redmine.html#plugins-outputs-redmine-status_id) option**\n\n- This is a required setting.\n- Value type is number\n- There is no default value for this setting.\n\nredmine issue status_id required', true),
		createSnippet('subject', 'option', 'subject => "${1:%{host\\}}"', '**[subject](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redmine.html#plugins-outputs-redmine-subject) option**\n\n- Value type is string\n- Default value is "%{host}"\n\nredmine issue subject required'),
		createSnippet('token', 'option', 'token => "${1:token}"', '**[token](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redmine.html#plugins-outputs-redmine-token) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nredmine token user used for authentication', true),
		createSnippet('tracker_id', 'option', 'tracker_id => ${1:123}', '**[tracker_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redmine.html#plugins-outputs-redmine-tracker_id) option**\n\n- This is a required setting.\n- Value type is number\n- There is no default value for this setting.\n\nredmine issue tracker_id required', true),
		createSnippet('url', 'option', 'url => "${1:url}"', '**[url](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redmine.html#plugins-outputs-redmine-url) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nhost of redmine app value format : http://urlofredmine.tld - Not add /issues at end', true)
	],
	'logstash-output-nagios_nsca': [
		createSnippet('host', 'option', 'host => "${1:localhost}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-nagios_nsca.html#plugins-outputs-nagios_nsca-host) option**\n\n- Value type is string\n- Default value is "localhost"\n\nThe nagios host or IP to send logs to. It should have a NSCA daemon running.'),
		createSnippet('message_format', 'option', 'message_format => "${1:%{@timestamp\\} %{host\\}: %{message\\}}"', '**[message_format](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-nagios_nsca.html#plugins-outputs-nagios_nsca-message_format) option**\n\n- Value type is string\n- Default value is "%{@timestamp} %{host}: %{message}"\n\nThe format to use when writing events to nagios. This value supports any string and can include %{name} and other dynamic strings.'),
		createSnippet('nagios_host', 'option', 'nagios_host => "${1:%{host\\}}"', '**[nagios_host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-nagios_nsca.html#plugins-outputs-nagios_nsca-nagios_host) option**\n\n- Value type is string\n- Default value is "%{host}"\n\nThe nagios host you want to submit a passive check result to. This parameter accepts interpolation, e.g. you can use @source_host or other logstash internal variables.'),
		createSnippet('nagios_service', 'option', 'nagios_service => "${1:LOGSTASH}"', '**[nagios_service](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-nagios_nsca.html#plugins-outputs-nagios_nsca-nagios_service) option**\n\n- Value type is string\n- Default value is "LOGSTASH"\n\nThe nagios service you want to submit a passive check result to. This parameter accepts interpolation, e.g. you can use @source_host or other logstash internal variables.'),
		createSnippet('nagios_status', 'option', 'nagios_status => "${1:nagios_status}"', '**[nagios_status](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-nagios_nsca.html#plugins-outputs-nagios_nsca-nagios_status) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe status to send to nagios. Should be 0 = OK, 1 = WARNING, 2 = CRITICAL, 3 = UNKNOWN', true),
		createSnippet('port', 'option', 'port => ${1:5667}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-nagios_nsca.html#plugins-outputs-nagios_nsca-port) option**\n\n- Value type is number\n- Default value is 5667\n\nThe port where the NSCA daemon on the nagios host listens.'),
		createSnippet('send_nsca_bin', 'option', 'send_nsca_bin => "${1:/usr/sbin/send_nsca}"', '**[send_nsca_bin](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-nagios_nsca.html#plugins-outputs-nagios_nsca-send_nsca_bin) option**\n\n- Value type is string\n- Default value is "/usr/sbin/send_nsca"\n\nThe path to the send_nsca binary on the local host.'),
		createSnippet('send_nsca_config', 'option', 'send_nsca_config => "${1:/path/to/file}"', '**[send_nsca_config](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-nagios_nsca.html#plugins-outputs-nagios_nsca-send_nsca_config) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nThe path to the send_nsca config file on the local host. Leave blank if you don’t want to provide a config file.')
	],
	'logstash-filter-dissect': [
		createSnippet('convert_datatype', 'option', 'convert_datatype => {\n\t"${1:key}" => "${2:value}"\n}', '**[convert_datatype](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-dissect.html#plugins-filters-dissect-convert_datatype) option**\n\n- Value type is hash\n- Default value is {}\n\nWith this setting int and float datatype conversions can be specified. These will be done after all mapping dissections have taken place. Feel free to use this setting on its own without a mapping section.\n\n**_Example:_**  \n``` ruby\nfilter {\n  dissect {\n    convert_datatype => {\n      "cpu" => "float"\n      "code" => "int"\n    }\n  }\n}\n```'),
		createSnippet('mapping', 'option', 'mapping => {\n\t"${1:key}" => "${2:value}"\n}', '**[mapping](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-dissect.html#plugins-filters-dissect-mapping) option**\n\n- Value type is hash\n- Default value is {}\n\nA hash of dissections of field => value\n\n**_Example:_**  \n``` ruby\nfilter {\n  dissect {\n    mapping => {\n      # using an actual line break\n      "message" => \'"%{field1}" "%{field2}"\n "%{description}"\'\n      "description" => "%{field3} %{field4} %{field5}"\n    }\n  }\n}\n```'),
		createSnippet('tag_on_failure', 'option', 'tag_on_failure => ["${1:_dissectfailure}"]', '**[tag_on_failure](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-dissect.html#plugins-filters-dissect-tag_on_failure) option**\n\n- Value type is array\n- Default value is ["_dissectfailure"]\n\nAppend values to the tags field when dissection fails')
	],
	'logstash-input-generator': [
		createSnippet('count', 'option', 'count => ${1:0}', '**[count](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-generator.html#plugins-inputs-generator-count) option**\n\n- Value type is number\n- Default value is 0\n\nSet how many messages should be generated.'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-generator.html#plugins-inputs-generator-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: uses backwards compatible field names, such as [host] v1, v8: uses fields that are compatible with ECS, such as [host][name]\n- disabled: uses backwards compatible field names, such as [host]\n- v1, v8: uses fields that are compatible with ECS, such as [host][name]\n\nSupported values are:'),
		createSnippet('lines', 'option', 'lines => ["${1:line}"]', '**[lines](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-generator.html#plugins-inputs-generator-lines) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nThe lines to emit, in order. This option cannot be used with the message setting.\n\n**_Example:_**  \n``` ruby\n    input {\n      generator {\n        lines => [\n          "line 1",\n          "line 2",\n          "line 3"\n        ]\n        # Emit all lines 3 times.\n        count => 3\n      }\n    }\n```'),
		createSnippet('message', 'option', 'message => "${1:Hello world!}"', '**[message](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-generator.html#plugins-inputs-generator-message) option**\n\n- Value type is string\n- Default value is "Hello world!"\n\nThe message string to use in the event.'),
		createSnippet('threads', 'option', 'threads => ${1:1}', '**[threads](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-generator.html#plugins-inputs-generator-threads) option**\n\n- Value type is number\n- Default value is 1')
	],
	'logstash-codec-fluent': [
		createSnippet('nanosecond_precision', 'option', 'nanosecond_precision => ${1|false,true|}', '**[nanosecond_precision](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-fluent.html#plugins-codecs-fluent-nanosecond_precision) option**\n\n- Value type is boolean\n- Default value is false\n\nEnables sub-second level precision while encoding events.'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-fluent.html#plugins-codecs-fluent-target) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nDefine the target field for placing the decoded values. If this setting is not set, data will be stored at the root (top level) of the event.\n\n**_Example:_**  \n``` ruby\n    input {\n      tcp {\n        codec => fluent {\n          target => "[logs]"\n        }\n        port => 4000\n      }\n    }\n```')
	],
	'logstash-root': [
		createSnippet('input', 'section', 'input {\n\t$0\n}', '**[input](https://www.elastic.co/guide/en/logstash/7.17/input-plugins.html) section**\n\nSection where all input plugins are declared.  \nAn input plugin enables a specific source of events to be read by Logstash.'),
		createSnippet('filter', 'section', 'filter {\n\t$0\n}', '**[filter](https://www.elastic.co/guide/en/logstash/7.17/filter-plugins.html) section**\n\nSection where all filter plugins are declared.  \nA filter plugin performs intermediary processing on an event. Filters are often applied conditionally depending on the characteristics of the event.'),
		createSnippet('output', 'section', 'output {\n\t$0\n}', '**[output](https://www.elastic.co/guide/en/logstash/7.17/output-plugins.html) section**\n\nSection where all output plugins are declared.  \nAn output plugin sends event data to a particular destination. Outputs are the final stage in the event pipeline.')
	],
	'logstash-output-elasticsearch': [
		createSnippet('action', 'option', 'action => "${1:create for data streams, and index for non-time series data}"', '**[action](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-action) option**\n\n- Value type is string\n- Default value is create for data streams, and index for non-time series data.\n\nThe Elasticsearch action to perform. Valid actions are:'),
		createSnippet('api_key', 'option', 'api_key => "${1:api_key}"', '**[api_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-api_key) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nAuthenticate using Elasticsearch API key. Note that this option also requires enabling the ssl option.'),
		createSnippet('bulk_path', 'option', 'bulk_path => "${1:bulk_path}"', '**[bulk_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-bulk_path) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nHTTP Path to perform the _bulk requests to this defaults to a concatenation of the path parameter and "_bulk"'),
		createSnippet('cacert', 'option', 'cacert => "${1:/path/to/file}"', '**[cacert](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-cacert) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nThe .cer or .pem file to validate the server’s certificate.'),
		createSnippet('cloud_auth', 'option', 'cloud_auth => "${1:cloud_auth}"', '**[cloud_auth](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-cloud_auth) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nCloud authentication string ("<username>:<password>" format) is an alternative for the user/password pair.'),
		createSnippet('cloud_id', 'option', 'cloud_id => "${1:cloud_id}"', '**[cloud_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-cloud_id) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nCloud ID, from the Elastic Cloud web console. If set hosts should not be used.'),
		createSnippet('custom_headers', 'option', 'custom_headers => {\n\t"${1:key}" => "${2:value}"\n}', '**[custom_headers](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-custom_headers) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nPass a set of key value pairs as the headers sent in each request to an elasticsearch node. The headers will be used for any kind of request (_bulk request, template installation, health checks and sniffing). These custom headers will be overidden by settings like http_compression.'),
		createSnippet('data_stream', 'option', 'data_stream => "${1|true,false,auto|}"$0', '**[data_stream](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-data_stream) option**\n\n- Value can be any of: true, false and auto\n- Default is false in Logstash 7.x and auto starting in Logstash 8.0.\n\nDefines whether data will be indexed into an Elasticsearch data stream. The other data_stream_* settings will be used only if this setting is enabled.'),
		createSnippet('data_stream_auto_routing', 'option', 'data_stream_auto_routing => ${1|true,false|}', '**[data_stream_auto_routing](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-data_stream_auto_routing) option**\n\n- Value type is boolean\n- Default value is true.\n\nAutomatically routes events by deriving the data stream name using specific event fields with the %{[data_stream][type]}-%{[data_stream][dataset]}-%{[data_stream][namespace]} format.'),
		createSnippet('data_stream_dataset', 'option', 'data_stream_dataset => "${1:generic}"', '**[data_stream_dataset](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-data_stream_dataset) option**\n\n- Value type is string\n- Default value is generic.\n\nThe data stream dataset used to construct the data stream at index time.'),
		createSnippet('data_stream_namespace', 'option', 'data_stream_namespace => "${1:default}"', '**[data_stream_namespace](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-data_stream_namespace) option**\n\n- Value type is string\n- Default value is default.\n\nThe data stream namespace used to construct the data stream at index time.'),
		createSnippet('data_stream_sync_fields', 'option', 'data_stream_sync_fields => ${1|true,false|}', '**[data_stream_sync_fields](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-data_stream_sync_fields) option**\n\n- Value type is boolean\n- Default value is true\n\nAutomatically adds and syncs the data_stream.* event fields if they are missing from the event. This ensures that fields match the name of the data stream that is receiving events.'),
		createSnippet('data_stream_type', 'option', 'data_stream_type => "${1:logs}"', '**[data_stream_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-data_stream_type) option**\n\n- Value type is string\n- Default value is logs.\n\nThe data stream type used to construct the data stream at index time. Currently, only logs, metrics, synthetics and traces are supported.'),
		createSnippet('doc_as_upsert', 'option', 'doc_as_upsert => ${1|false,true|}', '**[doc_as_upsert](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-doc_as_upsert) option**\n\n- Value type is boolean\n- Default value is false\n\nEnable doc_as_upsert for update mode. Create a new document with source if document_id doesn’t exist in Elasticsearch.'),
		createSnippet('document_id', 'option', 'document_id => "${1:document_id}"', '**[document_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-document_id) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe document ID for the index. Useful for overwriting existing entries in Elasticsearch with the same ID.'),
		createSnippet('document_type', 'option', 'document_type => "${1:document_type}"', '**[document_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-document_type) option**\n\n- Value type is string\n- There is no default value for this setting.\n- This option is deprecated\n\nThis option is deprecated due to the removal of types in Elasticsearch 6.0. It will be removed in the next major version of Logstash.'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: does not provide ECS-compatible templates v1: provides defaults that are compatible with v1 of the Elastic Common Schema\n- disabled: does not provide ECS-compatible templates\n- v1: provides defaults that are compatible with v1 of the Elastic Common Schema\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:'),
		createSnippet('failure_type_logging_whitelist', 'option', 'failure_type_logging_whitelist => ["${1:failure_type_logging_whitelist}"]', '**[failure_type_logging_whitelist](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-failure_type_logging_whitelist) option**\n\n- Value type is array\n- Default value is []\n\nSet the Elasticsearch errors in the whitelist that you don’t want to log. A useful example is when you want to skip all 409 errors which are document_already_exists_exception.'),
		createSnippet('healthcheck_path', 'option', 'healthcheck_path => "${1:healthcheck_path}"', '**[healthcheck_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-healthcheck_path) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nHTTP Path where a HEAD request is sent when a backend is marked down the request is sent in the background to see if it has come back again before it is once again eligible to service requests. If you have custom firewall rules you may need to change this'),
		createSnippet('hosts', 'option', 'hosts => ["${1:http://localhost}"]', '**[hosts](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-hosts) option**\n\n- Value type is uri\n- Default value is [//127.0.0.1]\n\nSets the host(s) of the remote instance. If given an array it will load balance requests across the hosts specified in the hosts parameter. Remember the http protocol uses the http address (eg. 9200, not 9300).'),
		createSnippet('http_compression', 'option', 'http_compression => ${1|false,true|}', '**[http_compression](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-http_compression) option**\n\n- Value type is boolean\n- Default value is false\n\nEnable gzip compression on requests.'),
		createSnippet('ilm_enabled', 'option', 'ilm_enabled => "${1|auto,false,true|}"$0', '**[ilm_enabled](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-ilm_enabled) option**\n\n- Value can be any of: true, false, auto\n- Default value is auto\n\nThe default setting of auto will automatically enable Index Lifecycle Management, if the Elasticsearch cluster is running Elasticsearch version 7.0.0 or higher with the ILM feature enabled, and disable it otherwise.'),
		createSnippet('ilm_pattern', 'option', 'ilm_pattern => "${1:{now/d\\}-000001}"', '**[ilm_pattern](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-ilm_pattern) option**\n\n- Value type is string\n- Default value is {now/d}-000001\n\nPattern used for generating indices managed by Index Lifecycle Management. The value specified in the pattern will be appended to the write alias, and incremented automatically when a new index is created by ILM.'),
		createSnippet('ilm_policy', 'option', 'ilm_policy => "${1:logstash-policy}"', '**[ilm_policy](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-ilm_policy) option**\n\n- Value type is string\n- Default value is logstash-policy\n\nModify this setting to use a custom Index Lifecycle Management policy, rather than the default. If this value is not set, the default policy will be automatically installed into Elasticsearch'),
		createSnippet('ilm_rollover_alias', 'option', 'ilm_rollover_alias => "${1:ilm_rollover_alias}"', '**[ilm_rollover_alias](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-ilm_rollover_alias) option**\n\n- Value type is string\n- Default value depends on whether ecs_compatibility is enabled: ECS Compatibility disabled: logstash ECS Compatibility enabled: ecs-logstash\n- ECS Compatibility disabled: logstash\n- ECS Compatibility enabled: ecs-logstash\n\nDefault value depends on whether ecs_compatibility is enabled:'),
		createSnippet('index', 'option', 'index => "${1:index}"', '**[index](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-index) option**\n\n- Value type is string\n- Default value depends on whether ecs_compatibility is enabled: ECS Compatibility disabled: "logstash-%{+yyyy.MM.dd}" ECS Compatibility enabled: "ecs-logstash-%{+yyyy.MM.dd}"\n- ECS Compatibility disabled: "logstash-%{+yyyy.MM.dd}"\n- ECS Compatibility enabled: "ecs-logstash-%{+yyyy.MM.dd}"\n\nDefault value depends on whether ecs_compatibility is enabled:'),
		createSnippet('keystore', 'option', 'keystore => "${1:/path/to/file}"', '**[keystore](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-keystore) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nThe keystore used to present a certificate to the server. It can be either .jks or .p12'),
		createSnippet('keystore_password', 'option', 'keystore_password => "${1:keystore_password}"', '**[keystore_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-keystore_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nSet the keystore password'),
		createSnippet('manage_template', 'option', 'manage_template => ${1|true,false|}', '**[manage_template](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-manage_template) option**\n\n- Value type is boolean\n- Default value is true\n\nFrom Logstash 1.3 onwards, a template is applied to Elasticsearch during Logstash’s startup if one with the name template_name does not already exist. By default, the contents of this template is the default template for logstash-%{+YYYY.MM.dd} which always matches indices based on the pattern logstash-*. Should you require support for other index names, or would like to change the mappings in the template in general, a custom template can be specified by setting template to the path of a template file.'),
		createSnippet('parameters', 'option', 'parameters => {\n\t"${1:key}" => "${2:value}"\n}', '**[parameters](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-parameters) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nPass a set of key value pairs as the URL query string. This query string is added to every host listed in the hosts configuration. If the hosts list contains urls that already have query strings, the one specified here will be appended.'),
		createSnippet('parent', 'option', 'parent => "${1:parent}"', '**[parent](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-parent) option**\n\n- Value type is string\n- Default value is nil\n\nFor child documents, ID of the associated parent. This can be dynamic using the %{foo} syntax.'),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nPassword to authenticate to a secure Elasticsearch cluster'),
		createSnippet('path', 'option', 'path => "${1:path}"', '**[path](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-path) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nHTTP Path at which the Elasticsearch server lives. Use this if you must run Elasticsearch behind a proxy that remaps the root path for the Elasticsearch HTTP API lives. Note that if you use paths as components of URLs in the hosts field you may not also set this field. That will raise an error at startup'),
		createSnippet('pipeline', 'option', 'pipeline => "${1:pipeline}"', '**[pipeline](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-pipeline) option**\n\n- Value type is string\n- Default value is nil\n\nSet which ingest pipeline you wish to execute for an event. You can also use event dependent configuration here like pipeline => "%{[@metadata][pipeline]}". The pipeline parameter won’t be set if the value resolves to empty string ("").'),
		createSnippet('pool_max', 'option', 'pool_max => ${1:1000}', '**[pool_max](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-pool_max) option**\n\n- Value type is number\n- Default value is 1000\n\nWhile the output tries to reuse connections efficiently we have a maximum. This sets the maximum number of open connections the output will create. Setting this too low may mean frequently closing / opening connections which is bad.'),
		createSnippet('pool_max_per_route', 'option', 'pool_max_per_route => ${1:100}', '**[pool_max_per_route](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-pool_max_per_route) option**\n\n- Value type is number\n- Default value is 100\n\nWhile the output tries to reuse connections efficiently we have a maximum per endpoint. This sets the maximum number of open connections per endpoint the output will create. Setting this too low may mean frequently closing / opening connections which is bad.'),
		createSnippet('proxy', 'option', 'proxy => ["${1:http://localhost}"]', '**[proxy](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-proxy) option**\n\n- Value type is uri\n- There is no default value for this setting.\n\nSet the address of a forward HTTP proxy. This setting accepts only URI arguments to prevent leaking credentials. An empty string is treated as if proxy was not set. This is useful when using environment variables e.g. proxy => \'${LS_PROXY:}\'.'),
		createSnippet('resurrect_delay', 'option', 'resurrect_delay => ${1:5}', '**[resurrect_delay](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-resurrect_delay) option**\n\n- Value type is number\n- Default value is 5\n\nHow frequently, in seconds, to wait between resurrection attempts. Resurrection is the process by which backend endpoints marked down are checked to see if they have come back to life'),
		createSnippet('retry_initial_interval', 'option', 'retry_initial_interval => ${1:2}', '**[retry_initial_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-retry_initial_interval) option**\n\n- Value type is number\n- Default value is 2\n\nSet initial interval in seconds between bulk retries. Doubled on each retry up to retry_max_interval'),
		createSnippet('retry_max_interval', 'option', 'retry_max_interval => ${1:64}', '**[retry_max_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-retry_max_interval) option**\n\n- Value type is number\n- Default value is 64\n\nSet max interval in seconds between bulk retries.'),
		createSnippet('retry_on_conflict', 'option', 'retry_on_conflict => ${1:1}', '**[retry_on_conflict](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-retry_on_conflict) option**\n\n- Value type is number\n- Default value is 1\n\nThe number of times Elasticsearch should internally retry an update/upserted document.'),
		createSnippet('routing', 'option', 'routing => "${1:routing}"', '**[routing](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-routing) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nA routing override to be applied to all processed events. This can be dynamic using the %{foo} syntax.'),
		createSnippet('script', 'option', 'script => "${1:script}"', '**[script](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-script) option**\n\n- Value type is string\n- Default value is ""\n\nSet script name for scripted update mode\n\n**_Example:_**  \n``` ruby\n    output {\n      elasticsearch {\n        script => "ctx._source.message = params.event.get(\'message\')"\n      }\n    }\n```'),
		createSnippet('script_lang', 'option', 'script_lang => "${1:painless}"', '**[script_lang](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-script_lang) option**\n\n- Value type is string\n- Default value is "painless"\n\nSet the language of the used script. When using indexed (stored) scripts on Elasticsearch 6.0 and higher, you must set this parameter to "" (empty string).'),
		createSnippet('script_type', 'option', 'script_type => "${1|inline,indexed,file|}"$0', '**[script_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-script_type) option**\n\n- Value can be any of: inline, indexed, file\n- Default value is ["inline"]\n\nDefine the type of script referenced by "script" variable inline : "script" contains inline script indexed : "script" contains the name of script directly indexed in elasticsearch file : "script" contains the name of script stored in elasticsearch’s config directory'),
		createSnippet('script_var_name', 'option', 'script_var_name => "${1:event}"', '**[script_var_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-script_var_name) option**\n\n- Value type is string\n- Default value is "event"\n\nSet variable name passed to script (scripted update)'),
		createSnippet('scripted_upsert', 'option', 'scripted_upsert => ${1|false,true|}', '**[scripted_upsert](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-scripted_upsert) option**\n\n- Value type is boolean\n- Default value is false\n\nif enabled, script is in charge of creating non-existent document (scripted update)'),
		createSnippet('sniffing', 'option', 'sniffing => ${1|false,true|}', '**[sniffing](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-sniffing) option**\n\n- Value type is boolean\n- Default value is false\n\nThis setting asks Elasticsearch for the list of all cluster nodes and adds them to the hosts list. For Elasticsearch 5.x and 6.x any nodes with http.enabled (on by default) will be added to the hosts list, excluding master-only nodes.'),
		createSnippet('sniffing_delay', 'option', 'sniffing_delay => ${1:5}', '**[sniffing_delay](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-sniffing_delay) option**\n\n- Value type is number\n- Default value is 5\n\nHow long to wait, in seconds, between sniffing attempts'),
		createSnippet('sniffing_path', 'option', 'sniffing_path => "${1:sniffing_path}"', '**[sniffing_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-sniffing_path) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nHTTP Path to be used for the sniffing requests the default value is computed by concatenating the path value and "_nodes/http" if sniffing_path is set it will be used as an absolute path do not use full URL here, only paths, e.g. "/sniff/_nodes/http"'),
		createSnippet('ssl', 'option', 'ssl => ${1|true,false|}', '**[ssl](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-ssl) option**\n\n- Value type is boolean\n- There is no default value for this setting.\n\nEnable SSL/TLS secured communication to Elasticsearch cluster. Leaving this unspecified will use whatever scheme is specified in the URLs listed in hosts. If no explicit protocol is specified plain HTTP will be used. If SSL is explicitly disabled here the plugin will refuse to start if an HTTPS URL is given in hosts'),
		createSnippet('ssl_certificate_verification', 'option', 'ssl_certificate_verification => ${1|true,false|}', '**[ssl_certificate_verification](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-ssl_certificate_verification) option**\n\n- Value type is boolean\n- Default value is true\n\nOption to validate the server’s certificate. Disabling this severely compromises security. For more information on disabling certificate verification please read https://www.cs.utexas.edu/~shmat/shmat_ccs12.pdf'),
		createSnippet('template', 'option', 'template => "${1:/path/to/file}"', '**[template](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-template) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nYou can set the path to your own template here, if you so desire. If not set, the included template will be used.'),
		createSnippet('template_name', 'option', 'template_name => "${1:template_name}"', '**[template_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-template_name) option**\n\n- Value type is string\n- Default value depends on whether ecs_compatibility is enabled: ECS Compatibility disabled: logstash ECS Compatibility enabled: ecs-logstash\n- ECS Compatibility disabled: logstash\n- ECS Compatibility enabled: ecs-logstash\n\nDefault value depends on whether ecs_compatibility is enabled:'),
		createSnippet('template_overwrite', 'option', 'template_overwrite => ${1|false,true|}', '**[template_overwrite](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-template_overwrite) option**\n\n- Value type is boolean\n- Default value is false\n\nThe template_overwrite option will always overwrite the indicated template in Elasticsearch with either the one indicated by template or the included one. This option is set to false by default. If you always want to stay up to date with the template provided by Logstash, this option could be very useful to you. Likewise, if you have your own template file managed by puppet, for example, and you wanted to be able to update it regularly, this option could help there as well.'),
		createSnippet('timeout', 'option', 'timeout => ${1:60}', '**[timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-timeout) option**\n\n- Value type is number\n- Default value is 60\n\nSet the timeout, in seconds, for network operations and requests sent Elasticsearch. If a timeout occurs, the request will be retried.'),
		createSnippet('truststore', 'option', 'truststore => "${1:/path/to/file}"', '**[truststore](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-truststore) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nThe truststore to validate the server’s certificate. It can be either .jks or .p12. Use either :truststore or :cacert.'),
		createSnippet('truststore_password', 'option', 'truststore_password => "${1:truststore_password}"', '**[truststore_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-truststore_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nSet the truststore password'),
		createSnippet('upsert', 'option', 'upsert => "${1:upsert}"', '**[upsert](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-upsert) option**\n\n- Value type is string\n- Default value is ""\n\nSet upsert content for update mode. Create a new document with this parameter as json string if document_id doesn’t exists'),
		createSnippet('user', 'option', 'user => "${1:user}"', '**[user](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-user) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nUsername to authenticate to a secure Elasticsearch cluster'),
		createSnippet('validate_after_inactivity', 'option', 'validate_after_inactivity => ${1:10000}', '**[validate_after_inactivity](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-validate_after_inactivity) option**\n\n- Value type is number\n- Default value is 10000\n\nHow long to wait before checking for a stale connection to determine if a keepalive request is needed. Consider setting this value lower than the default, possibly to 0, if you get connection errors regularly.'),
		createSnippet('version', 'option', 'version => "${1:version}"', '**[version](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-version) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe version to use for indexing. Use sprintf syntax like %{my_version} to use a field value here. See the versioning support blog for more information.'),
		createSnippet('version_type', 'option', 'version_type => "${1|internal,external,external_gt,external_gte,force|}"$0', '**[version_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-version_type) option**\n\n- Value can be any of: internal, external, external_gt, external_gte, force\n- There is no default value for this setting.\n\nThe version_type to use for indexing. See the versioning support blog and Version types in the Elasticsearch documentation.')
	],
	'logstash-output-pipe': [
		createSnippet('command', 'option', 'command => "${1:command}"', '**[command](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-pipe.html#plugins-outputs-pipe-command) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nCommand line to launch and pipe to', true),
		createSnippet('message_format', 'option', 'message_format => "${1:message_format}"', '**[message_format](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-pipe.html#plugins-outputs-pipe-message_format) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe format to use when writing events to the pipe. This value supports any string and can include %{name} and other dynamic strings.'),
		createSnippet('ttl', 'option', 'ttl => ${1:10}', '**[ttl](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-pipe.html#plugins-outputs-pipe-ttl) option**\n\n- Value type is number\n- Default value is 10\n\nClose pipe that hasn’t been used for TTL seconds. -1 or 0 means never close.')
	],
	'logstash-input-rss': [
		createSnippet('interval', 'option', 'interval => ${1:123}', '**[interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rss.html#plugins-inputs-rss-interval) option**\n\n- This is a required setting.\n- Value type is number\n- There is no default value for this setting.\n\nInterval to run the command. Value is in seconds.', true),
		createSnippet('url', 'option', 'url => "${1:url}"', '**[url](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rss.html#plugins-inputs-rss-url) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nRSS/Atom feed URL', true)
	],
	'logstash-codec-collectd': [
		createSnippet('authfile', 'option', 'authfile => "${1:authfile}"', '**[authfile](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-collectd.html#plugins-codecs-collectd-authfile) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nPath to the authentication file. This file should have the same format as the AuthFile in collectd. You only need to set this option if the security_level is set to Sign or Encrypt'),
		createSnippet('nan_handling', 'option', 'nan_handling => "${1|change_value,warn,drop|}"$0', '**[nan_handling](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-collectd.html#plugins-codecs-collectd-nan_handling) option**\n\n- Value can be any of: change_value, warn, drop\n- Default value is "change_value"\n\nWhat to do when a value in the event is NaN (Not a Number)'),
		createSnippet('nan_tag', 'option', 'nan_tag => "${1:_collectdNaN}"', '**[nan_tag](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-collectd.html#plugins-codecs-collectd-nan_tag) option**\n\n- Value type is string\n- Default value is "_collectdNaN"\n\nThe tag to add to the event if a NaN value was found Set this to an empty string (\'\') if you don’t want to tag'),
		createSnippet('nan_value', 'option', 'nan_value => ${1:0}', '**[nan_value](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-collectd.html#plugins-codecs-collectd-nan_value) option**\n\n- Value type is number\n- Default value is 0\n\nOnly relevant when nan_handeling is set to change_value Change NaN to this configured value'),
		createSnippet('prune_intervals', 'option', 'prune_intervals => ${1|true,false|}', '**[prune_intervals](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-collectd.html#plugins-codecs-collectd-prune_intervals) option**\n\n- Value type is boolean\n- Default value is true\n\nPrune interval records. Defaults to true.'),
		createSnippet('security_level', 'option', 'security_level => "${1|None,Sign,Encrypt|}"$0', '**[security_level](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-collectd.html#plugins-codecs-collectd-security_level) option**\n\n- Value can be any of: None, Sign, Encrypt\n- Default value is "None"\n\nSecurity Level. Default is None. This setting mirrors the setting from the collectd Network plugin'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-collectd.html#plugins-codecs-collectd-target) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nDefine the target field for placing the decoded values. If this setting is not set, data will be stored at the root (top level) of the event.\n\n**_Example:_**  \n``` ruby\n    input {\n      udp {\n        port => 12345\n        codec => collectd {\n          target => "[document]"\n        }\n      }\n    }\n```'),
		createSnippet('typesdb', 'option', 'typesdb => ["${1:typesdb}"]', '**[typesdb](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-collectd.html#plugins-codecs-collectd-typesdb) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nFile path(s) to collectd types.db to use. The last matching pattern wins if you have identical pattern names in multiple files. If no types.db is provided the included types.db will be used (currently 5.4.0).')
	],
	'logstash-input-wmi': [
		createSnippet('host', 'option', 'host => "${1:localhost}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-wmi.html#plugins-inputs-wmi-host) option**\n\n- Value type is string\n- Default value is "localhost"\n\nHost to connect to ( Defaults to localhost )'),
		createSnippet('interval', 'option', 'interval => ${1:10}', '**[interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-wmi.html#plugins-inputs-wmi-interval) option**\n\n- Value type is number\n- Default value is 10\n\nPolling interval'),
		createSnippet('namespace', 'option', 'namespace => "${1:root\\cimv2}"', '**[namespace](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-wmi.html#plugins-inputs-wmi-namespace) option**\n\n- Value type is string\n- Default value is "root\\\\cimv2"\n\nNamespace when doing remote connections'),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-wmi.html#plugins-inputs-wmi-password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nPassword when doing remote connections'),
		createSnippet('query', 'option', 'query => "${1:query}"', '**[query](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-wmi.html#plugins-inputs-wmi-query) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nWMI query', true),
		createSnippet('user', 'option', 'user => "${1:user}"', '**[user](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-wmi.html#plugins-inputs-wmi-user) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nUsername when doing remote connections')
	],
	'logstash-input-irc': [
		createSnippet('catch_all', 'option', 'catch_all => ${1|false,true|}', '**[catch_all](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-irc.html#plugins-inputs-irc-catch_all) option**\n\n- Value type is boolean\n- Default value is false\n\nCatch all IRC channel/user events not just channel messages'),
		createSnippet('channels', 'option', 'channels => ["${1:channel}"]', '**[channels](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-irc.html#plugins-inputs-irc-channels) option**\n\n- This is a required setting.\n- Value type is array\n- There is no default value for this setting.\n\nChannels to join and read messages from.', true),
		createSnippet('get_stats', 'option', 'get_stats => ${1|false,true|}', '**[get_stats](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-irc.html#plugins-inputs-irc-get_stats) option**\n\n- Value type is boolean\n- Default value is false\n\nGather and send user counts for channels - this requires catch_all and will force it'),
		createSnippet('host', 'option', 'host => "${1:host}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-irc.html#plugins-inputs-irc-host) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nHost of the IRC Server to connect to.', true),
		createSnippet('nick', 'option', 'nick => "${1:logstash}"', '**[nick](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-irc.html#plugins-inputs-irc-nick) option**\n\n- Value type is string\n- Default value is "logstash"\n\nIRC Nickname'),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-irc.html#plugins-inputs-irc-password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nIRC Server password'),
		createSnippet('port', 'option', 'port => ${1:6667}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-irc.html#plugins-inputs-irc-port) option**\n\n- Value type is number\n- Default value is 6667\n\nPort for the IRC Server'),
		createSnippet('real', 'option', 'real => "${1:logstash}"', '**[real](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-irc.html#plugins-inputs-irc-real) option**\n\n- Value type is string\n- Default value is "logstash"\n\nIRC Real name'),
		createSnippet('secure', 'option', 'secure => ${1|false,true|}', '**[secure](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-irc.html#plugins-inputs-irc-secure) option**\n\n- Value type is boolean\n- Default value is false\n\nSet this to true to enable SSL.'),
		createSnippet('stats_interval', 'option', 'stats_interval => ${1:5}', '**[stats_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-irc.html#plugins-inputs-irc-stats_interval) option**\n\n- Value type is number\n- Default value is 5\n\nHow often in minutes to get the user count stats'),
		createSnippet('user', 'option', 'user => "${1:logstash}"', '**[user](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-irc.html#plugins-inputs-irc-user) option**\n\n- Value type is string\n- Default value is "logstash"\n\nIRC Username')
	],
	'logstash-filter-fingerprint': [
		createSnippet('base64encode', 'option', 'base64encode => ${1|false,true|}', '**[base64encode](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-fingerprint.html#plugins-filters-fingerprint-base64encode) option**\n\n- Value type is boolean\n- Default value is false\n\nWhen set to true, the SHA1, SHA256, SHA384, SHA512 and MD5 fingerprint methods will produce base64 encoded rather than hex encoded strings.'),
		createSnippet('concatenate_sources', 'option', 'concatenate_sources => ${1|false,true|}', '**[concatenate_sources](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-fingerprint.html#plugins-filters-fingerprint-concatenate_sources) option**\n\n- Value type is boolean\n- Default value is false\n\nWhen set to true and method isn’t UUID or PUNCTUATION, the plugin concatenates the names and values of all fields given in the source option into one string (like the old checksum filter) before doing the fingerprint computation.'),
		createSnippet('concatenate_all_fields', 'option', 'concatenate_all_fields => ${1|false,true|}', '**[concatenate_all_fields](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-fingerprint.html#plugins-filters-fingerprint-concatenate_all_fields) option**\n\n- Value type is boolean\n- Default value is false\n\nWhen set to true and method isn’t UUID or PUNCTUATION, the plugin concatenates the names and values of all fields of the event into one string (like the old checksum filter) before doing the fingerprint computation. If false and at least one source field is given, the target field will be an array with fingerprints of the source fields given.'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-fingerprint.html#plugins-filters-fingerprint-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: unstructured data added at root level v1: uses [event][hash] fields that are compatible with Elastic Common Schema\n- disabled: unstructured data added at root level\n- v1: uses [event][hash] fields that are compatible with Elastic Common Schema\n\nSupported values are:'),
		createSnippet('key', 'option', 'key => "${1:key}"', '**[key](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-fingerprint.html#plugins-filters-fingerprint-key) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nWhen used with the IPV4_NETWORK method fill in the subnet prefix length. With other methods, optionally fill in the HMAC key.'),
		createSnippet('method', 'option', 'method => "${1|SHA1,SHA256,SHA384,SHA512,MD5,MURMUR3,IPV4_NETWORK,UUID,PUNCTUATION|}"$0', '**[method](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-fingerprint.html#plugins-filters-fingerprint-method) option**\n\n- This is a required setting.\n- Value can be any of: SHA1, SHA256, SHA384, SHA512, MD5, MURMUR3, IPV4_NETWORK, UUID, PUNCTUATION\n- Default value is "SHA1"\n\nThe fingerprint method to use.', true),
		createSnippet('source', 'option', 'source => ["${1:message}"]', '**[source](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-fingerprint.html#plugins-filters-fingerprint-source) option**\n\n- Value type is array\n- Default value is "message"\n\nThe name(s) of the source field(s) whose contents will be used to create the fingerprint. If an array is given, see the concatenate_sources option.'),
		createSnippet('target', 'option', 'target => "${1:fingerprint" when ECS is disabled}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-fingerprint.html#plugins-filters-fingerprint-target) option**\n\n- Value type is string\n- Default value is "fingerprint" when ECS is disabled\n- Default value is "[event][hash]" when ECS is enabled\n\nThe name of the field where the generated fingerprint will be stored. Any current contents of that field will be overwritten.')
	],
	'logstash-output-datadog_metrics': [
		createSnippet('api_key', 'option', 'api_key => "${1:api_key}"', '**[api_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-datadog_metrics.html#plugins-outputs-datadog_metrics-api_key) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nYour DatadogHQ API key. https://app.datadoghq.com/account/settings#api', true),
		createSnippet('dd_tags', 'option', 'dd_tags => ["${1:dd_tag}"]', '**[dd_tags](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-datadog_metrics.html#plugins-outputs-datadog_metrics-dd_tags) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nSet any custom tags for this event, default are the Logstash tags if any.'),
		createSnippet('device', 'option', 'device => "${1:%{metric_device\\}}"', '**[device](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-datadog_metrics.html#plugins-outputs-datadog_metrics-device) option**\n\n- Value type is string\n- Default value is "%{metric_device}"\n\nThe name of the device that produced the metric.'),
		createSnippet('host', 'option', 'host => "${1:%{host\\}}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-datadog_metrics.html#plugins-outputs-datadog_metrics-host) option**\n\n- Value type is string\n- Default value is "%{host}"\n\nThe name of the host that produced the metric.'),
		createSnippet('metric_name', 'option', 'metric_name => "${1:%{metric_name\\}}"', '**[metric_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-datadog_metrics.html#plugins-outputs-datadog_metrics-metric_name) option**\n\n- Value type is string\n- Default value is "%{metric_name}"\n\nThe name of the time series.'),
		createSnippet('metric_type', 'option', 'metric_type => "${1|gauge,counter,%{metric_type}|}"$0', '**[metric_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-datadog_metrics.html#plugins-outputs-datadog_metrics-metric_type) option**\n\n- Value can be any of: gauge, counter, %{metric_type}\n- Default value is "%{metric_type}"\n\nThe type of the metric.'),
		createSnippet('metric_value', 'option', 'metric_value => "${1:%{metric_value\\}}"', '**[metric_value](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-datadog_metrics.html#plugins-outputs-datadog_metrics-metric_value) option**\n\n- Value type is string\n- Default value is "%{metric_value}"\n\nThe value.'),
		createSnippet('queue_size', 'option', 'queue_size => ${1:10}', '**[queue_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-datadog_metrics.html#plugins-outputs-datadog_metrics-queue_size) option**\n\n- Value type is number\n- Default value is 10\n\nHow many events to queue before flushing to Datadog prior to schedule set in @timeframe'),
		createSnippet('timeframe', 'option', 'timeframe => ${1:10}', '**[timeframe](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-datadog_metrics.html#plugins-outputs-datadog_metrics-timeframe) option**\n\n- Value type is number\n- Default value is 10\n\nHow often (in seconds) to flush queued events to Datadog')
	],
	'logstash-filter-ruby': [
		createSnippet('code', 'option', 'code => "${1:code}"', '**[code](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-ruby.html#plugins-filters-ruby-code) option**\n\n- Value type is string\n- There is no default value for this setting.\n- This setting cannot be used together with path.\n\nThe code to execute for every event. You will have an event variable available that is the event itself. See the Event API for more information.'),
		createSnippet('init', 'option', 'init => "${1:init}"', '**[init](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-ruby.html#plugins-filters-ruby-init) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nAny code to execute at logstash startup-time'),
		createSnippet('path', 'option', 'path => "${1:path}"', '**[path](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-ruby.html#plugins-filters-ruby-path) option**\n\n- Value type is string\n- There is no default value for this setting.\n- This setting cannot be used together with code.\n\nThe path of the ruby script file that implements the filter method.'),
		createSnippet('script_params', 'option', 'script_params => {\n\t"${1:key}" => "${2:value}"\n}', '**[script_params](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-ruby.html#plugins-filters-ruby-script_params) option**\n\n- Value type is hash\n- Default value is {}\n\nA key/value hash with parameters that are passed to the register method of your ruby script file defined in path.'),
		createSnippet('tag_on_exception', 'option', 'tag_on_exception => "${1:_rubyexception}"', '**[tag_on_exception](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-ruby.html#plugins-filters-ruby-tag_on_exception) option**\n\n- Value type is string\n- Default value is _rubyexception\n\nTag to add to events in case the ruby code (either inline or file based) causes an exception.'),
		createSnippet('tag_with_exception_message', 'option', 'tag_with_exception_message => ${1|false,true|}', '**[tag_with_exception_message](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-ruby.html#plugins-filters-ruby-tag_with_exception_message) option**\n\n- Value type is boolean\n- Default value is false\n\nIf true adds a tag to the event that is the concatenation of tag_with_exception_message and the exception message.')
	],
	'logstash-filter-bytes': [
		createSnippet('source', 'option', 'source => "${1:message}"', '**[source](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-bytes.html#plugins-filters-bytes-source) option**\n\n- Value type is string\n- Default value is message\n\nName of the source field that contains the storage size'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-bytes.html#plugins-filters-bytes-target) option**\n\n- Value type is string\n\nName of the target field that will contain the storage size in bytes', true),
		createSnippet('conversion_method', 'option', 'conversion_method => "${1:binary}"', '**[conversion_method](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-bytes.html#plugins-filters-bytes-conversion_method) option**\n\n- Value type is string\n- Value can be any of: binary, metric\n- Default value is binary\n\nWhich conversion method to use when converting to bytes. binary uses 1K = 1024B. metric uses 1K = 1000B.')
	],
	'logstash-filter-date': [
		createSnippet('locale', 'option', 'locale => "${1:locale}"', '**[locale](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-date.html#plugins-filters-date-locale) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nSpecify a locale to be used for date parsing using either IETF-BCP47 or POSIX language tag. Simple examples are en,en-US for BCP47 or en_US for POSIX.'),
		createSnippet('match', 'option', 'match => ["${1:match}"]', '**[match](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-date.html#plugins-filters-date-match) option**\n\n- Value type is array\n- Default value is []\n\nAn array with field name first, and format patterns following, [ field, formats... ]\n\n**_Example:_**  \n``` ruby\n    match => [ "logdate", "MMM dd yyyy HH:mm:ss",\n              "MMM  d yyyy HH:mm:ss", "ISO8601" ]\n```'),
		createSnippet('tag_on_failure', 'option', 'tag_on_failure => ["${1:_dateparsefailure}"]', '**[tag_on_failure](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-date.html#plugins-filters-date-tag_on_failure) option**\n\n- Value type is array\n- Default value is ["_dateparsefailure"]\n\nAppend values to the tags field when there has been no successful match'),
		createSnippet('target', 'option', 'target => "${1:@timestamp}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-date.html#plugins-filters-date-target) option**\n\n- Value type is string\n- Default value is "@timestamp"\n\nStore the matching timestamp into the given target field. If not provided, default to updating the @timestamp field of the event.'),
		createSnippet('timezone', 'option', 'timezone => "${1:timezone}"', '**[timezone](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-date.html#plugins-filters-date-timezone) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nSpecify a time zone canonical ID to be used for date parsing. The valid IDs are listed on the Joda.org available time zones page. This is useful in case the time zone cannot be extracted from the value, and is not the platform default. If this is not specified the platform default will be used. Canonical ID is good as it takes care of daylight saving time for you For example, America/Los_Angeles or Europe/Paris are valid IDs. This field can be dynamic and include parts of the event using the %{field} syntax')
	],
	'logstash-output-kafka': [
		createSnippet('acks', 'option', 'acks => "${1|1,0,all|}"$0', '**[acks](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-acks) option**\n\n- Value can be any of: 0, 1, all\n- Default value is "1"\n\nThe number of acknowledgments the producer requires the leader to have received before considering a request complete.'),
		createSnippet('batch_size', 'option', 'batch_size => ${1:16384}', '**[batch_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-batch_size) option**\n\n- Value type is number\n- Default value is 16384.\n\nThe producer will attempt to batch records together into fewer requests whenever multiple records are being sent to the same partition. This helps performance on both the client and the server. This configuration controls the default batch size in bytes.'),
		createSnippet('bootstrap_servers', 'option', 'bootstrap_servers => "${1:localhost:9092}"', '**[bootstrap_servers](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-bootstrap_servers) option**\n\n- Value type is string\n- Default value is "localhost:9092"\n\nThis is for bootstrapping and the producer will only use it for getting metadata (topics, partitions and replicas). The socket connections for sending the actual data will be established based on the broker information returned in the metadata. The format is host1:port1,host2:port2, and the list can be a subset of brokers or a VIP pointing to a subset of brokers.'),
		createSnippet('buffer_memory', 'option', 'buffer_memory => ${1:33554432}', '**[buffer_memory](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-buffer_memory) option**\n\n- Value type is number\n- Default value is 33554432 (32MB).\n\nThe total bytes of memory the producer can use to buffer records waiting to be sent to the server.'),
		createSnippet('client_dns_lookup', 'option', 'client_dns_lookup => "${1:default}"', '**[client_dns_lookup](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-client_dns_lookup) option**\n\n- Value type is string\n- Valid options are use_all_dns_ips, resolve_canonical_bootstrap_servers_only, default\n- Default value is "default"\n\nControls how DNS lookups are done. If set to use_all_dns_ips, Logstash tries all IP addresses returned for a hostname before failing the connection. If set to resolve_canonical_bootstrap_servers_only, each entry will be resolved and expanded into a list of canonical names.'),
		createSnippet('client_id', 'option', 'client_id => "${1:client_id}"', '**[client_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-client_id) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe id string to pass to the server when making requests. The purpose of this is to be able to track the source of requests beyond just ip/port by allowing a logical application name to be included with the request'),
		createSnippet('compression_type', 'option', 'compression_type => "${1|none,gzip,snappy,lz4|}"$0', '**[compression_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-compression_type) option**\n\n- Value can be any of: none, gzip, snappy, lz4\n- Default value is "none"\n\nThe compression type for all data generated by the producer. The default is none (i.e. no compression). Valid values are none, gzip, snappy, or lz4.'),
		createSnippet('jaas_path', 'option', 'jaas_path => "${1:/path/to/file}"', '**[jaas_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-jaas_path) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nThe Java Authentication and Authorization Service (JAAS) API supplies user authentication and authorization services for Kafka. This setting provides the path to the JAAS file. Sample JAAS file for Kafka client:'),
		createSnippet('kerberos_config', 'option', 'kerberos_config => "${1:/path/to/file}"', '**[kerberos_config](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-kerberos_config) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nOptional path to kerberos config file. This is krb5.conf style as detailed in https://web.mit.edu/kerberos/krb5-1.12/doc/admin/conf_files/krb5_conf.html'),
		createSnippet('key_serializer', 'option', 'key_serializer => "${1:org.apache.kafka.common.serialization.StringSerializer}"', '**[key_serializer](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-key_serializer) option**\n\n- Value type is string\n- Default value is "org.apache.kafka.common.serialization.StringSerializer"\n\nSerializer class for the key of the message'),
		createSnippet('linger_ms', 'option', 'linger_ms => ${1:0}', '**[linger_ms](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-linger_ms) option**\n\n- Value type is number\n- Default value is 0\n\nThe producer groups together any records that arrive in between request transmissions into a single batched request. Normally this occurs only under load when records arrive faster than they can be sent out. However in some circumstances the client may want to reduce the number of requests even under moderate load. This setting accomplishes this by adding a small amount of artificial delay—that is, rather than immediately sending out a record the producer will wait for up to the given delay to allow other records to be sent so that the sends can be batched together.'),
		createSnippet('max_request_size', 'option', 'max_request_size => ${1:1048576}', '**[max_request_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-max_request_size) option**\n\n- Value type is number\n- Default value is 1048576 (1MB).\n\nThe maximum size of a request'),
		createSnippet('message_key', 'option', 'message_key => "${1:message_key}"', '**[message_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-message_key) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe key for the message.'),
		createSnippet('metadata_fetch_timeout_ms', 'option', 'metadata_fetch_timeout_ms => ${1:60000 milliseconds}', '**[metadata_fetch_timeout_ms](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-metadata_fetch_timeout_ms) option**\n\n- Value type is number\n- Default value is 60000 milliseconds (60 seconds).\n\nThe timeout setting for initial metadata request to fetch topic metadata.'),
		createSnippet('metadata_max_age_ms', 'option', 'metadata_max_age_ms => ${1:300000 milliseconds}', '**[metadata_max_age_ms](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-metadata_max_age_ms) option**\n\n- Value type is number\n- Default value is 300000 milliseconds (5 minutes).\n\nThe max time in milliseconds before a metadata refresh is forced.'),
		createSnippet('partitioner', 'option', 'partitioner => "${1:partitioner}"', '**[partitioner](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-partitioner) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe default behavior is to hash the message_key of an event to get the partition. When no message key is present, the plugin picks a partition in a round-robin fashion.'),
		createSnippet('receive_buffer_bytes', 'option', 'receive_buffer_bytes => ${1:32768}', '**[receive_buffer_bytes](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-receive_buffer_bytes) option**\n\n- Value type is number\n- Default value is 32768 (32KB).\n\nThe size of the TCP receive buffer to use when reading data'),
		createSnippet('reconnect_backoff_ms', 'option', 'reconnect_backoff_ms => ${1:50}', '**[reconnect_backoff_ms](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-reconnect_backoff_ms) option**\n\n- Value type is number\n- Default value is 50.\n\nThe amount of time to wait before attempting to reconnect to a given host when a connection fails.'),
		createSnippet('request_timeout_ms', 'option', 'request_timeout_ms => ${1:40000 milliseconds}', '**[request_timeout_ms](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-request_timeout_ms) option**\n\n- Value type is number\n- Default value is 40000 milliseconds (40 seconds).\n\nThe configuration controls the maximum amount of time the client will wait for the response of a request. If the response is not received before the timeout elapses the client will resend the request if necessary or fail the request if retries are exhausted.'),
		createSnippet('retries', 'option', 'retries => ${1:123}', '**[retries](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-retries) option**\n\n- Value type is number\n- There is no default value for this setting.\n\nThe default retry behavior is to retry until successful. To prevent data loss, the use of this setting is discouraged.'),
		createSnippet('retry_backoff_ms', 'option', 'retry_backoff_ms => ${1:100 milliseconds}', '**[retry_backoff_ms](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-retry_backoff_ms) option**\n\n- Value type is number\n- Default value is 100 milliseconds.\n\nThe amount of time to wait before attempting to retry a failed produce request to a given topic partition.'),
		createSnippet('sasl_jaas_config', 'option', 'sasl_jaas_config => "${1:sasl_jaas_config}"', '**[sasl_jaas_config](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-sasl_jaas_config) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nJAAS configuration setting local to this plugin instance, as opposed to settings using config file configured using jaas_path, which are shared across the JVM. This allows each plugin instance to have its own configuration.\n\n**_Example:_**  \n``` ruby\n    output {\n      kafka {\n        sasl_jaas_config => "org.apache.kafka.common.security.plain.PlainLoginModule required username=\'auser\'  password=\'apassword\';"\n      }\n    }\n```'),
		createSnippet('sasl_kerberos_service_name', 'option', 'sasl_kerberos_service_name => "${1:sasl_kerberos_service_name}"', '**[sasl_kerberos_service_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-sasl_kerberos_service_name) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe Kerberos principal name that Kafka broker runs as. This can be defined either in Kafka’s JAAS config or in Kafka’s config.'),
		createSnippet('sasl_mechanism', 'option', 'sasl_mechanism => "${1:GSSAPI}"', '**[sasl_mechanism](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-sasl_mechanism) option**\n\n- Value type is string\n- Default value is "GSSAPI"\n\nSASL mechanism used for client connections. This may be any mechanism for which a security provider is available. GSSAPI is the default mechanism.'),
		createSnippet('security_protocol', 'option', 'security_protocol => "${1|PLAINTEXT,SSL,SASL_PLAINTEXT,SASL_SSL|}"$0', '**[security_protocol](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-security_protocol) option**\n\n- Value can be any of: PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL\n- Default value is "PLAINTEXT"\n\nSecurity protocol to use, which can be either of PLAINTEXT,SSL,SASL_PLAINTEXT,SASL_SSL'),
		createSnippet('send_buffer_bytes', 'option', 'send_buffer_bytes => ${1:131072}', '**[send_buffer_bytes](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-send_buffer_bytes) option**\n\n- Value type is number\n- Default value is 131072 (128KB).\n\nThe size of the TCP send buffer to use when sending data.'),
		createSnippet('ssl_endpoint_identification_algorithm', 'option', 'ssl_endpoint_identification_algorithm => "${1:https}"', '**[ssl_endpoint_identification_algorithm](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-ssl_endpoint_identification_algorithm) option**\n\n- Value type is string\n- Default value is "https"\n\nThe endpoint identification algorithm, defaults to "https". Set to empty string "" to disable'),
		createSnippet('ssl_key_password', 'option', 'ssl_key_password => "${1:ssl_key_password}"', '**[ssl_key_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-ssl_key_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nThe password of the private key in the key store file.'),
		createSnippet('ssl_keystore_location', 'option', 'ssl_keystore_location => "${1:/path/to/file}"', '**[ssl_keystore_location](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-ssl_keystore_location) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf client authentication is required, this setting stores the keystore path.'),
		createSnippet('ssl_keystore_password', 'option', 'ssl_keystore_password => "${1:ssl_keystore_password}"', '**[ssl_keystore_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-ssl_keystore_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nIf client authentication is required, this setting stores the keystore password'),
		createSnippet('ssl_keystore_type', 'option', 'ssl_keystore_type => "${1:ssl_keystore_type}"', '**[ssl_keystore_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-ssl_keystore_type) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe keystore type.'),
		createSnippet('ssl_truststore_location', 'option', 'ssl_truststore_location => "${1:/path/to/file}"', '**[ssl_truststore_location](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-ssl_truststore_location) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nThe JKS truststore path to validate the Kafka broker’s certificate.'),
		createSnippet('ssl_truststore_password', 'option', 'ssl_truststore_password => "${1:ssl_truststore_password}"', '**[ssl_truststore_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-ssl_truststore_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nThe truststore password'),
		createSnippet('ssl_truststore_type', 'option', 'ssl_truststore_type => "${1:ssl_truststore_type}"', '**[ssl_truststore_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-ssl_truststore_type) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe truststore type.'),
		createSnippet('topic_id', 'option', 'topic_id => "${1:topic_id}"', '**[topic_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-topic_id) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe topic to produce messages to', true),
		createSnippet('value_serializer', 'option', 'value_serializer => "${1:org.apache.kafka.common.serialization.StringSerializer}"', '**[value_serializer](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html#plugins-outputs-kafka-value_serializer) option**\n\n- Value type is string\n- Default value is "org.apache.kafka.common.serialization.StringSerializer"\n\nSerializer class for the value of the message')
	],
	'logstash-output-java_stdout': [
	],
	'logstash-filter-kv': [
		createSnippet('allow_duplicate_values', 'option', 'allow_duplicate_values => ${1|true,false|}', '**[allow_duplicate_values](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-allow_duplicate_values) option**\n\n- Value type is boolean\n- Default value is true\n\nA bool option for removing duplicate key/value pairs. When set to false, only one unique key/value pair will be preserved.\n\n**_Example:_**  \n``` ruby\n    filter {\n      kv {\n        allow_duplicate_values => false\n      }\n    }\n```'),
		createSnippet('default_keys', 'option', 'default_keys => {\n\t"${1:key}" => "${2:value}"\n}', '**[default_keys](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-default_keys) option**\n\n- Value type is hash\n- Default value is {}\n\nA hash specifying the default keys and their values which should be added to the event in case these keys do not exist in the source field being parsed.\n\n**_Example:_**  \n``` ruby\n    filter {\n      kv {\n        default_keys => [ "from", "logstash@example.com",\n                         "to", "default@dev.null" ]\n      }\n    }\n```'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: does not use ECS-compatible field names v1: Elastic Common Schema compliant behavior (warns when target isn’t set)\n- disabled: does not use ECS-compatible field names\n- v1: Elastic Common Schema compliant behavior (warns when target isn’t set)\n\nSupported values are:'),
		createSnippet('exclude_keys', 'option', 'exclude_keys => ["${1:exclude_key}"]', '**[exclude_keys](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-exclude_keys) option**\n\n- Value type is array\n- Default value is []\n\nAn array specifying the parsed keys which should not be added to the event. By default no keys will be excluded.\n\n**_Example:_**  \n``` ruby\n    filter {\n      kv {\n        exclude_keys => [ "from", "to" ]\n      }\n    }\n```'),
		createSnippet('field_split', 'option', 'field_split => "${1:field_split}"', '**[field_split](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-field_split) option**\n\n- Value type is string\n- Default value is " "\n\nA string of characters to use as single-character field delimiters for parsing out key-value pairs.\n\n**_Example:_**  \n``` ruby\n    filter {\n      kv {\n        field_split => "&?"\n      }\n    }\n```'),
		createSnippet('field_split_pattern', 'option', 'field_split_pattern => "${1:field_split_pattern}"', '**[field_split_pattern](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-field_split_pattern) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nA regex expression to use as field delimiter for parsing out key-value pairs. Useful to define multi-character field delimiters. Setting the field_split_pattern options will take precedence over the field_split option.\n\n**_Example:_**  \n``` ruby\n    filter { kv { field_split_pattern => ":+" } }\n```'),
		createSnippet('include_brackets', 'option', 'include_brackets => ${1|true,false|}', '**[include_brackets](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-include_brackets) option**\n\n- Value type is boolean\n- Default value is true\n\nA boolean specifying whether to treat square brackets, angle brackets, and parentheses as value "wrappers" that should be removed from the value.\n\n**_Example:_**  \n``` ruby\n    filter {\n      kv {\n        include_brackets => true\n      }\n    }\n```'),
		createSnippet('include_keys', 'option', 'include_keys => ["${1:include_key}"]', '**[include_keys](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-include_keys) option**\n\n- Value type is array\n- Default value is []\n\nAn array specifying the parsed keys which should be added to the event. By default all keys will be added.\n\n**_Example:_**  \n``` ruby\n    filter {\n      kv {\n        include_keys => [ "from", "to" ]\n      }\n    }\n```'),
		createSnippet('prefix', 'option', 'prefix => "${1:prefix}"', '**[prefix](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-prefix) option**\n\n- Value type is string\n- Default value is ""\n\nA string to prepend to all of the extracted keys.\n\n**_Example:_**  \n``` ruby\n    filter { kv { prefix => "arg_" } }\n```'),
		createSnippet('recursive', 'option', 'recursive => ${1|false,true|}', '**[recursive](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-recursive) option**\n\n- Value type is boolean\n- Default value is false\n\nA boolean specifying whether to drill down into values and recursively get more key-value pairs from it. The extra key-value pairs will be stored as subkeys of the root key.\n\n**_Example:_**  \n``` ruby\n    filter {\n      kv {\n        recursive => "true"\n      }\n    }\n```'),
		createSnippet('remove_char_key', 'option', 'remove_char_key => "${1:remove_char_key}"', '**[remove_char_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-remove_char_key) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nA string of characters to remove from the key.\n\n**_Example:_**  \n``` ruby\n    filter {\n      kv {\n        remove_char_key => "<>\\\\[\\\\],"\n      }\n    }\n```'),
		createSnippet('remove_char_value', 'option', 'remove_char_value => "${1:remove_char_value}"', '**[remove_char_value](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-remove_char_value) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nA string of characters to remove from the value.\n\n**_Example:_**  \n``` ruby\n    filter {\n      kv {\n        remove_char_value => "<>\\\\[\\\\],"\n      }\n    }\n```'),
		createSnippet('source', 'option', 'source => "${1:message}"', '**[source](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-source) option**\n\n- Value type is string\n- Default value is "message"\n\nThe field to perform key=value searching on\n\n**_Example:_**  \n``` ruby\n    filter { kv { source => "not_the_message" } }\n```'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-target) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe name of the container to put all of the key-value pairs into.\n\n**_Example:_**  \n``` ruby\n    filter { kv { target => "kv" } }\n```'),
		createSnippet('tag_on_failure', 'option', 'tag_on_failure => "${1:_kv_filter_error}"', '**[tag_on_failure](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-tag_on_failure) option**\n\n- Value type is string\n- The default value for this setting is _kv_filter_error.\n\nWhen a kv operation causes a runtime exception to be thrown within the plugin, the operation is safely aborted without crashing the plugin, and the event is tagged with the provided value.'),
		createSnippet('tag_on_timeout', 'option', 'tag_on_timeout => "${1:_kv_filter_timeout}"', '**[tag_on_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-tag_on_timeout) option**\n\n- Value type is string\n- The default value for this setting is _kv_filter_timeout.\n\nWhen timeouts are enabled and a kv operation is aborted, the event is tagged with the provided value (see: timeout_millis).'),
		createSnippet('timeout_millis', 'option', 'timeout_millis => ${1:30000}', '**[timeout_millis](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-timeout_millis) option**\n\n- Value type is number\n- The default value for this setting is 30000 (30 seconds).\n- Set to zero (0) to disable timeouts\n\nTimeouts provide a safeguard against inputs that are pathological against the regular expressions that are used to extract key/value pairs. When parsing an event exceeds this threshold the operation is aborted and the event is tagged in order to prevent the operation from blocking the pipeline (see: tag_on_timeout).'),
		createSnippet('transform_key', 'option', 'transform_key => "${1|lowercase,uppercase,capitalize|}"$0', '**[transform_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-transform_key) option**\n\n- Value can be any of: lowercase, uppercase, capitalize\n- There is no default value for this setting.\n\nTransform keys to lower case, upper case or capitals.\n\n**_Example:_**  \n``` ruby\n    filter {\n      kv {\n        transform_key => "lowercase"\n      }\n    }\n```'),
		createSnippet('transform_value', 'option', 'transform_value => "${1|lowercase,uppercase,capitalize|}"$0', '**[transform_value](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-transform_value) option**\n\n- Value can be any of: lowercase, uppercase, capitalize\n- There is no default value for this setting.\n\nTransform values to lower case, upper case or capitals.\n\n**_Example:_**  \n``` ruby\n    filter {\n      kv {\n        transform_value => "capitalize"\n      }\n    }\n```'),
		createSnippet('trim_key', 'option', 'trim_key => "${1:trim_key}"', '**[trim_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-trim_key) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nA string of characters to trim from the key. This is useful if your keys are wrapped in brackets or start with space.\n\n**_Example:_**  \n``` ruby\n    filter {\n      kv {\n        trim_key => "<>\\\\[\\\\],"\n      }\n    }\n```'),
		createSnippet('trim_value', 'option', 'trim_value => "${1:trim_value}"', '**[trim_value](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-trim_value) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nConstants used for transform check A string of characters to trim from the value. This is useful if your values are wrapped in brackets or are terminated with commas (like postfix logs).\n\n**_Example:_**  \n``` ruby\n    filter {\n      kv {\n        trim_value => "<>\\\\[\\\\],"\n      }\n    }\n```'),
		createSnippet('value_split', 'option', 'value_split => "${1:=}"', '**[value_split](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-value_split) option**\n\n- Value type is string\n- Default value is "="\n\nA non-empty string of characters to use as single-character value delimiters for parsing out key-value pairs.\n\n**_Example:_**  \n``` ruby\n    filter { kv { value_split => ":" } }\n```'),
		createSnippet('value_split_pattern', 'option', 'value_split_pattern => "${1:value_split_pattern}"', '**[value_split_pattern](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-value_split_pattern) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nA regex expression to use as value delimiter for parsing out key-value pairs. Useful to define multi-character value delimiters. Setting the value_split_pattern options will take precedence over the value_split option.'),
		createSnippet('whitespace', 'option', 'whitespace => "${1|lenient,strict|}"$0', '**[whitespace](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html#plugins-filters-kv-whitespace) option**\n\n- Value can be any of: lenient, strict\n- Default value is lenient\n\nAn option specifying whether to be lenient or strict with the acceptance of unnecessary whitespace surrounding the configured value-split sequence.')
	],
	'logstash-filter-geoip': [
		createSnippet('cache_size', 'option', 'cache_size => ${1:1000}', '**[cache_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-geoip.html#plugins-filters-geoip-cache_size) option**\n\n- Value type is number\n- Default value is 1000\n\nGeoIP lookup is surprisingly expensive. This filter uses an cache to take advantage of the fact that IPs agents are often found adjacent to one another in log files and rarely have a random distribution. The higher you set this the more likely an item is to be in the cache and the faster this filter will run. However, if you set this too high you can use more memory than desired. Since the Geoip API upgraded to v2, there is not any eviction policy so far, if cache is full, no more record can be added. Experiment with different values for this option to find the best performance for your dataset.'),
		createSnippet('database', 'option', 'database => "${1:/path/to/file}"', '**[database](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-geoip.html#plugins-filters-geoip-database) option**\n\n- Value type is path\n- If not specified, the database defaults to the GeoLite2 City database that ships with Logstash.\n\nThe path to MaxMind’s database file that Logstash should use. The default database is GeoLite2-City. This plugin supports several free databases (GeoLite2-City, GeoLite2-Country, GeoLite2-ASN) and a selection of commercially-licensed databases (GeoIP2-City, GeoIP2-ISP, GeoIP2-Country).'),
		createSnippet('default_database_type', 'option', 'default_database_type => "${1|City,ASN|}"$0', '**[default_database_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-geoip.html#plugins-filters-geoip-default_database_type) option**\n\n- Value type is string\n- The default value is City\n- The only acceptable values are City and ASN\n\nThis plugin now includes both the GeoLite2-City and GeoLite2-ASN databases. If database and default_database_type are unset, the GeoLite2-City database will be selected. To use the included GeoLite2-ASN database, set default_database_type to ASN.'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-geoip.html#plugins-filters-geoip-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: unstructured geo data added at root level v1, v8: use fields that are compatible with Elastic Common Schema. Example: [client][geo][country_name]. See field mapping for more info.\n- disabled: unstructured geo data added at root level\n- v1, v8: use fields that are compatible with Elastic Common Schema. Example: [client][geo][country_name]. See field mapping for more info.\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:'),
		createSnippet('fields', 'option', 'fields => ["${1:field}"]', '**[fields](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-geoip.html#plugins-filters-geoip-fields) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nAn array of geoip fields to be included in the event.'),
		createSnippet('source', 'option', 'source => "${1:source}"', '**[source](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-geoip.html#plugins-filters-geoip-source) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe field containing the IP address or hostname to map via geoip. If this field is an array, only the first value will be used.', true),
		createSnippet('tag_on_failure', 'option', 'tag_on_failure => ["${1:_geoip_lookup_failure}"]', '**[tag_on_failure](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-geoip.html#plugins-filters-geoip-tag_on_failure) option**\n\n- Value type is array\n- Default value is ["_geoip_lookup_failure"]\n\nTags the event on failure to look up geo information. This can be used in later analysis.'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-geoip.html#plugins-filters-geoip-target) option**\n\n- This is an optional setting with condition.\n- Value type is string\n- Default value depends on whether ecs_compatibility is enabled: ECS Compatibility disabled: geoip ECS Compatibility enabled: If source is an ip sub-field, eg. [client][ip], target will automatically set to the parent field, in this example client, otherwise, target is a required setting geo field is nested in [client][geo] ECS compatible values are client, destination, host, observer, server, source\n- ECS Compatibility disabled: geoip\n- ECS Compatibility enabled: If source is an ip sub-field, eg. [client][ip], target will automatically set to the parent field, in this example client, otherwise, target is a required setting geo field is nested in [client][geo] ECS compatible values are client, destination, host, observer, server, source\n- geo field is nested in [client][geo]\n- ECS compatible values are client, destination, host, observer, server, source\n\nDefault value depends on whether ecs_compatibility is enabled:')
	],
	'logstash-output-xmpp': [
		createSnippet('host', 'option', 'host => "${1:host}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-xmpp.html#plugins-outputs-xmpp-host) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe xmpp server to connect to. This is optional. If you omit this setting, the host on the user/identity is used. (foo.com for user@foo.com)'),
		createSnippet('message', 'option', 'message => "${1:message}"', '**[message](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-xmpp.html#plugins-outputs-xmpp-message) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe message to send. This supports dynamic strings like %{host}', true),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-xmpp.html#plugins-outputs-xmpp-password) option**\n\n- This is a required setting.\n- Value type is password\n- There is no default value for this setting.\n\nThe xmpp password for the user/identity.', true),
		createSnippet('rooms', 'option', 'rooms => ["${1:room}"]', '**[rooms](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-xmpp.html#plugins-outputs-xmpp-rooms) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nif muc/multi-user-chat required, give the name of the room that you want to join: room@conference.domain/nick'),
		createSnippet('user', 'option', 'user => "${1:user}"', '**[user](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-xmpp.html#plugins-outputs-xmpp-user) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe user or resource ID, like foo@example.com.', true),
		createSnippet('users', 'option', 'users => ["${1:user}"]', '**[users](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-xmpp.html#plugins-outputs-xmpp-users) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nThe users to send messages to')
	],
	'logstash-input-kinesis': [
		createSnippet('application_name', 'option', 'application_name => "${1:logstash}"', '**[application_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kinesis.html#plugins-inputs-kinesis-application_name) option**\n\n- Value type is string\n- Default value is "logstash"\n\nThe application name used for the dynamodb coordination table. Must be unique for this kinesis stream.'),
		createSnippet('checkpoint_interval_seconds', 'option', 'checkpoint_interval_seconds => ${1:60}', '**[checkpoint_interval_seconds](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kinesis.html#plugins-inputs-kinesis-checkpoint_interval_seconds) option**\n\n- Value type is number\n- Default value is 60\n\nHow many seconds between worker checkpoints to dynamodb.'),
		createSnippet('http_proxy', 'option', 'http_proxy => "${1:http_proxy}"', '**[http_proxy](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kinesis.html#plugins-inputs-kinesis-http_proxy) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nProxy support for Kinesis, DynamoDB, and CloudWatch (if enabled).'),
		createSnippet('initial_position_in_stream', 'option', 'initial_position_in_stream => "${1:TRIM_HORIZON}"', '**[initial_position_in_stream](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kinesis.html#plugins-inputs-kinesis-initial_position_in_stream) option**\n\n- Value type is string\n- Default value is "TRIM_HORIZON"\n\nThe value for initialPositionInStream. Accepts "TRIM_HORIZON" or "LATEST".'),
		createSnippet('kinesis_stream_name', 'option', 'kinesis_stream_name => "${1:kinesis_stream_name}"', '**[kinesis_stream_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kinesis.html#plugins-inputs-kinesis-kinesis_stream_name) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe kinesis stream name.', true),
		createSnippet('metrics', 'option', 'metrics => "${1|null,cloudwatch|}"$0', '**[metrics](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kinesis.html#plugins-inputs-kinesis-metrics) option**\n\n- Value can be any of: ``, cloudwatch\n- Default value is nil\n\nWorker metric tracking. By default this is disabled, set it to "cloudwatch" to enable the cloudwatch integration in the Kinesis Client Library.'),
		createSnippet('non_proxy_hosts', 'option', 'non_proxy_hosts => "${1:non_proxy_hosts}"', '**[non_proxy_hosts](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kinesis.html#plugins-inputs-kinesis-non_proxy_hosts) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nHosts that should be excluded from proxying, separated by the "|" (pipe) character.'),
		createSnippet('profile', 'option', 'profile => "${1:profile}"', '**[profile](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kinesis.html#plugins-inputs-kinesis-profile) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS profile name for authentication. This ensures that the ~/.aws/credentials AWS auth provider is used. By default this is empty and the default chain will be used.'),
		createSnippet('region', 'option', 'region => "${1:us-east-1}"', '**[region](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kinesis.html#plugins-inputs-kinesis-region) option**\n\n- Value type is string\n- Default value is "us-east-1"\n\nThe AWS region for Kinesis, DynamoDB, and CloudWatch (if enabled)'),
		createSnippet('role_arn', 'option', 'role_arn => "${1:role_arn}"', '**[role_arn](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kinesis.html#plugins-inputs-kinesis-role_arn) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS role to assume. This can be used, for example, to access a Kinesis stream in a different AWS account. This role will be assumed after the default credentials or profile credentials are created. By default this is empty and a role will not be assumed.'),
		createSnippet('role_session_name', 'option', 'role_session_name => "${1:logstash}"', '**[role_session_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kinesis.html#plugins-inputs-kinesis-role_session_name) option**\n\n- Value type is string\n- Default value is logstash\n\nSession name to use when assuming an IAM role. This is recorded in CloudTrail logs for example.'),
		createSnippet('additional_settings', 'option', 'additional_settings => "${1:additional_settings}"', '**[additional_settings](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kinesis.html#plugins-inputs-kinesis-additional_settings) option**\n\n- Value type is string\n- There is no default value for this setting\n\nThe KCL provides several configuration options which can be set in KinesisClientLibConfiguration. These options are configured via various function calls that all begin with with. Some of these functions take complex types, which are not supported. However, you may invoke any one of the withX() functions that take a primitive by providing key-value pairs in snake_case.\n\n**_Example:_**  \n``` ruby\nadditional_settings => {"initial_lease_table_read_capacity" => 25 "initial_lease_table_write_capacity" => 100}\n```')
	],
	'logstash-filter-metrics': [
		createSnippet('clear_interval', 'option', 'clear_interval => ${1:-1}', '**[clear_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-metrics.html#plugins-filters-metrics-clear_interval) option**\n\n- Value type is number\n- Default value is -1\n\nThe clear interval, when all counters are reset.'),
		createSnippet('flush_interval', 'option', 'flush_interval => ${1:5}', '**[flush_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-metrics.html#plugins-filters-metrics-flush_interval) option**\n\n- Value type is number\n- Default value is 5\n\nThe flush interval, when the metrics event is created. Must be a multiple of 5s.'),
		createSnippet('ignore_older_than', 'option', 'ignore_older_than => ${1:0}', '**[ignore_older_than](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-metrics.html#plugins-filters-metrics-ignore_older_than) option**\n\n- Value type is number\n- Default value is 0\n\nDon’t track events that have @timestamp older than some number of seconds.'),
		createSnippet('meter', 'option', 'meter => ["${1:meter}"]', '**[meter](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-metrics.html#plugins-filters-metrics-meter) option**\n\n- Value type is array\n- Default value is []\n\nsyntax: meter => [ "name of metric", "name of metric" ]'),
		createSnippet('percentiles', 'option', 'percentiles => ${1:[1, 5, 10, 90, 95, 99, 100]}', '**[percentiles](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-metrics.html#plugins-filters-metrics-percentiles) option**\n\n- Value type is array\n- Default value is [1, 5, 10, 90, 95, 99, 100]\n\nThe percentiles that should be measured and emitted for timer values.'),
		createSnippet('rates', 'option', 'rates => ${1:[1, 5, 15]}', '**[rates](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-metrics.html#plugins-filters-metrics-rates) option**\n\n- Value type is array\n- Default value is [1, 5, 15]\n\nThe rates that should be measured, in minutes. Possible values are 1, 5, and 15.'),
		createSnippet('timer', 'option', 'timer => {\n\t"${1:key}" => "${2:value}"\n}', '**[timer](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-metrics.html#plugins-filters-metrics-timer) option**\n\n- Value type is hash\n- Default value is {}\n\nsyntax: timer => [ "name of metric", "%{time_value}" ]')
	],
	'logstash-filter': [
		createSnippet('grok', 'plugin', 'grok {\n\tmatch => {\n\t\t"${1:field}" => "${2:pattern}"\n\t}\n}', '**[grok](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-grok.html) filter**\n\nParses unstructured event data into fields\n\n**_Example:_**  \n``` ruby\n    input {\n      file {\n        path => "/var/log/http.log"\n      }\n    }\n    filter {\n      grok {\n        match => { "message" => "%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}" }\n      }\n    }\n```'),
		createSnippet('if', 'keyword', 'if ${1|[field],"value",123,true|} ${2|==,!=,<,>,<=,>=,=~,!~,in,not in|} ${3|[field],"value",123,true,["value1"\\, "value2"],/regex/|} {\n\t$0\n}', '**[if](https://www.elastic.co/guide/en/logstash/7.17/event-dependent-configuration.html#conditionals) keyword**\n\nConditionnal block'),
		createSnippet('age', 'plugin', 'age {\n\t$0\n}', '**[age](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-age.html) filter**\n\nCalculates the age of an event by subtracting the event timestamp from the current timestamp\n\n**_Example:_**  \n``` ruby\nfilter {\n  age {}\n  if [@metadata][age] > 86400 {\n    drop {}\n  }\n}\n```'),
		createSnippet('aggregate', 'plugin', 'aggregate {\n\tcode => "${1:code}"\n\ttask_id => "${2:task_id}"\n}', '**[aggregate](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-aggregate.html) filter**\n\nAggregates information from several events originating with a single task\n\n**_Example:_**  \n``` ruby\n filter {\n   grok {\n     match => [ "message", "%{LOGLEVEL:loglevel} - %{NOTSPACE:taskid} - %{NOTSPACE:logger} - %{WORD:label}( - %{INT:duration:int})?" ]\n   }\n\n   if [logger] == "TASK_START" {\n     aggregate {\n       task_id => "%{taskid}"\n       code => "map[\'sql_duration\'] = 0"\n       map_action => "create"\n     }\n   }\n\n   if [logger] == "SQL" {\n     aggregate {\n       task_id => "%{taskid}"\n       code => "map[\'sql_duration\'] += event.get(\'duration\')"\n       map_action => "update"\n     }\n   }\n\n   if [logger] == "TASK_END" {\n     aggregate {\n       task_id => "%{taskid}"\n       code => "event.set(\'sql_duration\', map[\'sql_duration\'])"\n       map_action => "update"\n       end_of_task => true\n       timeout => 120\n     }\n   }\n }\n```'),
		createSnippet('alter', 'plugin', 'alter {\n\t$0\n}', '**[alter](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-alter.html) filter**\n\nPerforms general alterations to fields that the mutate filter does not handle\n\n**_Example:_**  \n``` ruby\n    filter {\n      alter {\n        coalesce => [\n             "field_name", "value1", "value2", "value3", ...\n        ]\n      }\n    }\n```'),
		createSnippet('bytes', 'plugin', 'bytes {\n\ttarget => "${1:target}"\n}', '**[bytes](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-bytes.html) filter**\n\nParses string representations of computer storage sizes, such as "123 MB" or "5.6gb", into their numeric value in bytes\n\n**_Example:_**  \n``` ruby\n    filter {\n      bytes {\n        source => "my_bytes_string_field"\n        target => "my_bytes_numeric_field"\n      }\n    }\n```'),
		createSnippet('cidr', 'plugin', 'cidr {\n\t$0\n}', '**[cidr](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-cidr.html) filter**\n\nChecks IP addresses against a list of network blocks\n\n**_Example:_**  \n``` ruby\n    filter {\n      cidr {\n        add_tag => [ "testnet" ]\n        address => [ "%{src_ip}", "%{dst_ip}" ]\n        network => [ "192.0.2.0/24" ]\n      }\n    }\n```'),
		createSnippet('cipher', 'plugin', 'cipher {\n\talgorithm => "${1:algorithm}"\n\tmode => "${2:mode}"\n}', '**[cipher](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-cipher.html) filter**\n\nApplies or removes a cipher to an event\n\n**_Example:_**  \n``` ruby\n    filter { cipher { cipher_padding => 0 }}\n```'),
		createSnippet('clone', 'plugin', 'clone {\n\tclones => ["${1:clone}"]\n}', '**[clone](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-clone.html) filter**\n\nDuplicates events\n\n**_Example:_**  \n``` ruby\n    filter {\n      clone {\n        clones => ["sun", "moon"]\n      }\n    }\n```'),
		createSnippet('csv', 'plugin', 'csv {\n\t$0\n}', '**[csv](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-csv.html) filter**\n\nParses comma-separated value data into individual fields\n\n**_Example:_**  \n``` ruby\n    filter {\n      csv {\n        convert => {\n          "column1" => "integer"\n          "column2" => "boolean"\n        }\n      }\n    }\n```'),
		createSnippet('date', 'plugin', 'date {\n\t$0\n}', '**[date](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-date.html) filter**\n\nParses dates from fields to use as the Logstash timestamp for an event\n\n**_Example:_**  \n``` ruby\n    filter {\n      date {\n        match => [ "logdate", "MMM dd yyyy HH:mm:ss" ]\n      }\n    }\n```'),
		createSnippet('de_dot', 'plugin', 'de_dot {\n\t$0\n}', '**[de_dot](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-de_dot.html) filter**\n\nComputationally expensive filter that removes dots from a field name\n\n**_Example:_**  \n``` ruby\n    filter {\n      de_dot {\n        add_field => { "foo_%{somefield}" => "Hello world, from %{host}" }\n      }\n    }\n```'),
		createSnippet('dissect', 'plugin', 'dissect {\n\t$0\n}', '**[dissect](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-dissect.html) filter**\n\nExtracts unstructured event data into fields using delimiters\n\n**_Example:_**  \n``` ruby\n  filter {\n    dissect {\n      mapping => {\n        "message" => "%{ts} %{+ts} %{+ts} %{src} %{} %{prog}[%{pid}]: %{msg}"\n      }\n    }\n  }\n```'),
		createSnippet('dns', 'plugin', 'dns {\n\t$0\n}', '**[dns](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-dns.html) filter**\n\nPerforms a standard or reverse DNS lookup\n\n**_Example:_**  \n``` ruby\n    filter {\n      dns {\n        reverse => [ "source_host", "field_with_address" ]\n        resolve => [ "field_with_fqdn" ]\n        action => "replace"\n      }\n    }\n```'),
		createSnippet('drop', 'plugin', 'drop {\n\t$0\n}', '**[drop](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-drop.html) filter**\n\nDrops all events\n\n**_Example:_**  \n``` ruby\n    filter {\n      if [loglevel] == "debug" {\n        drop { }\n      }\n    }\n```'),
		createSnippet('elapsed', 'plugin', 'elapsed {\n\tend_tag => "${1:end_tag}"\n\tstart_tag => "${2:start_tag}"\n\tunique_id_field => "${3:unique_id_field}"\n}', '**[elapsed](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elapsed.html) filter**\n\nCalculates the elapsed time between a pair of events\n\n**_Example:_**  \n``` ruby\n    filter {\n      elapsed {\n        start_tag => "start event tag"\n        end_tag => "end event tag"\n        unique_id_field => "id field name"\n        timeout => seconds\n        new_event_on_match => true/false\n      }\n    }\n```'),
		createSnippet('elasticsearch', 'plugin', 'elasticsearch {\n\t$0\n}', '**[elasticsearch](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elasticsearch.html) filter**\n\nCopies fields from previous log events in Elasticsearch to current events\n\n**_Example:_**  \n``` ruby\nif [type] == "end" {\n   elasticsearch {\n      hosts => ["es-server"]\n      query => "type:start AND operation:%{[opid]}"\n      fields => { "@timestamp" => "started" }\n   }\n\n   date {\n      match => ["[started]", "ISO8601"]\n      target => "[started]"\n   }\n\n   ruby {\n      code => "event.set(\'duration_hrs\', (event.get(\'@timestamp\') - event.get(\'started\')) / 3600)"\n   }\n}\n```'),
		createSnippet('environment', 'plugin', 'environment {\n\t$0\n}', '**[environment](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-environment.html) filter**\n\nStores environment variables as metadata sub-fields\n\n**_Example:_**  \n``` ruby\n    filter {\n      environment {\n        add_field => { "foo_%{somefield}" => "Hello world, from %{host}" }\n      }\n    }\n```'),
		createSnippet('extractnumbers', 'plugin', 'extractnumbers {\n\t$0\n}', '**[extractnumbers](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-extractnumbers.html) filter**\n\nExtracts numbers from a string\n\n**_Example:_**  \n``` ruby\n    filter {\n      extractnumbers {\n        add_field => { "foo_%{somefield}" => "Hello world, from %{host}" }\n      }\n    }\n```'),
		createSnippet('fingerprint', 'plugin', 'fingerprint {\n\tmethod => "${1|SHA1,SHA256,SHA384,SHA512,MD5,MURMUR3,IPV4_NETWORK,UUID,PUNCTUATION|}"$2\n}', '**[fingerprint](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-fingerprint.html) filter**\n\nFingerprints fields by replacing values with a consistent hash\n\n**_Example:_**  \n``` ruby\nfingerprint {\n  source => ["user_id", "siblings", "birthday"]\n}\n```'),
		createSnippet('geoip', 'plugin', 'geoip {\n\tsource => "${1:source}"\n}', '**[geoip](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-geoip.html) filter**\n\nAdds geographical information about an IP address\n\n**_Example:_**  \n``` ruby\n    filter {\n      geoip {\n        add_field => { "foo_%{somefield}" => "Hello world, from %{host}" }\n      }\n    }\n```'),
		createSnippet('http', 'plugin', 'http {\n\turl => "${1:url}"\n}', '**[http](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html) filter**\n\nProvides integration with external web services/REST APIs\n\n**_Example:_**  \n``` ruby\n    filter {\n      http {\n        add_field => { "foo_%{somefield}" => "Hello world, from %{host}" }\n      }\n    }\n```'),
		createSnippet('i18n', 'plugin', 'i18n {\n\t$0\n}', '**[i18n](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-i18n.html) filter**\n\nRemoves special characters from a field\n\n**_Example:_**  \n``` ruby\n    filter {\n      i18n {\n         transliterate => ["field1", "field2"]\n      }\n    }\n```'),
		createSnippet('java_uuid', 'plugin', 'java_uuid {\n\ttarget => "${1:target}"\n}', '**[java_uuid](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-java_uuid.html) filter**\n\nGenerates a UUID and adds it to each processed event\n\n**_Example:_**  \n``` ruby\n   filter {\n      java_uuid {\n        target    => "uuid"\n        overwrite => true\n      }\n   }\n```'),
		createSnippet('jdbc_static', 'plugin', 'jdbc_static {\n\tjdbc_connection_string => "${1:jdbc_connection_string}"\n\tjdbc_driver_class => "${2:jdbc_driver_class}"\n}', '**[jdbc_static](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_static.html) filter**\n\nEnriches events with data pre-loaded from a remote database\n\n**_Example:_**  \n``` ruby\nfilter {\n  jdbc_static {\n    loaders => [ \n      {\n        id => "remote-servers"\n        query => "select ip, descr from ref.local_ips order by ip"\n        local_table => "servers"\n      },\n      {\n        id => "remote-users"\n        query => "select firstname, lastname, userid from ref.local_users order by userid"\n        local_table => "users"\n      }\n    ]\n    local_db_objects => [ \n      {\n        name => "servers"\n        index_columns => ["ip"]\n        columns => [\n          ["ip", "varchar(15)"],\n          ["descr", "varchar(255)"]\n        ]\n      },\n      {\n        name => "users"\n        index_columns => ["userid"]\n        columns => [\n          ["firstname", "varchar(255)"],\n          ["lastname", "varchar(255)"],\n          ["userid", "int"]\n        ]\n      }\n    ]\n    local_lookups => [ \n      {\n        id => "local-servers"\n        query => "SELECT descr as description FROM servers WHERE ip = :ip"\n        parameters => {ip => "[from_ip]"}\n        target => "server"\n      },\n      {\n        id => "local-users"\n        query => "SELECT firstname, lastname FROM users WHERE userid = ? AND country = ?"\n        prepared_parameters => ["[loggedin_userid]", "[user_nation]"] \n        target => "user" \n      }\n    ]\n    # using add_field here to add & rename values to the event root\n    add_field => { server_name => "%{[server][0][description]}" } \n    add_field => { user_firstname => "%{[user][0][firstname]}" }\n    add_field => { user_lastname => "%{[user][0][lastname]}" }\n    remove_field => ["server", "user"]\n    staging_directory => "/tmp/logstash/jdbc_static/import_data"\n    loader_schedule => "* */2 * * *" # run loaders every 2 hours\n    jdbc_user => "logstash"\n    jdbc_password => "example"\n    jdbc_driver_class => "org.postgresql.Driver"\n    jdbc_driver_library => "/tmp/logstash/vendor/postgresql-42.1.4.jar"\n    jdbc_connection_string => "jdbc:postgresql://remotedb:5432/ls_test_2"\n  }\n}\n```'),
		createSnippet('jdbc_streaming', 'plugin', 'jdbc_streaming {\n\tjdbc_connection_string => "${1:jdbc_connection_string}"\n\tjdbc_driver_class => "${2:jdbc_driver_class}"\n\tstatement => "${3:statement}"\n\ttarget => "${4:target}"\n}', '**[jdbc_streaming](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html) filter**\n\nEnrich events with your database data\n\n**_Example:_**  \n``` ruby\nfilter {\n  jdbc_streaming {\n    jdbc_driver_library => "/path/to/mysql-connector-java-5.1.34-bin.jar"\n    jdbc_driver_class => "com.mysql.jdbc.Driver"\n    jdbc_connection_string => "jdbc:mysql://localhost:3306/mydatabase"\n    jdbc_user => "me"\n    jdbc_password => "secret"\n    statement => "select * from WORLD.COUNTRY WHERE Code = :code"\n    parameters => { "code" => "country_code"}\n    target => "country_details"\n  }\n}\n```'),
		createSnippet('json', 'plugin', 'json {\n\tsource => "${1:source}"\n}', '**[json](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-json.html) filter**\n\nParses JSON events\n\n**_Example:_**  \n``` ruby\n    filter {\n      json {\n        source => "message"\n      }\n    }\n```'),
		createSnippet('json_encode', 'plugin', 'json_encode {\n\tsource => "${1:source}"\n}', '**[json_encode](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-json_encode.html) filter**\n\nSerializes a field to JSON\n\n**_Example:_**  \n``` ruby\n    filter {\n      json_encode {\n        source => "foo"\n        target => "bar"\n      }\n    }\n```'),
		createSnippet('kv', 'plugin', 'kv {\n\t$0\n}', '**[kv](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-kv.html) filter**\n\nParses key-value pairs\n\n**_Example:_**  \n``` ruby\n    filter {\n      kv { }\n    }\n```'),
		createSnippet('memcached', 'plugin', 'memcached {\n\t$0\n}', '**[memcached](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-memcached.html) filter**\n\nProvides integration with external data in Memcached\n\n**_Example:_**  \n``` ruby\nmemcached {\n    hosts => ["localhost"]\n    namespace => "convert_mm"\n    get => {\n      "%{millimeters}" => "[inches]"\n    }\n    add_tag => ["from_cache"]\n    id => "memcached-get"\n  }\n```'),
		createSnippet('metricize', 'plugin', 'metricize {\n\tmetrics => ["${1:metric}"]\n}', '**[metricize](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-metricize.html) filter**\n\nTakes complex events containing a number of metrics and splits these up into multiple events, each holding a single metric\n\n**_Example:_**  \n``` ruby\n    filter {\n      metricize {\n        add_field => { "foo_%{somefield}" => "Hello world, from %{host}" }\n      }\n    }\n```'),
		createSnippet('metrics', 'plugin', 'metrics {\n\t$0\n}', '**[metrics](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-metrics.html) filter**\n\nAggregates metrics\n\n**_Example:_**  \n``` ruby\n    filter {\n      metrics {\n        meter => [ "http_%{response}" ]\n        add_tag => "metric"\n      }\n    }\n```'),
		createSnippet('mutate', 'plugin', 'mutate {\n\t$0\n}', '**[mutate](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-mutate.html) filter**\n\nPerforms mutations on fields\n\n**_Example:_**  \n``` ruby\nfilter {\n    mutate {\n        split => { "hostname" => "." }\n        add_field => { "shortHostname" => "%{[hostname][0]}" }\n    }\n\n    mutate {\n        rename => {"shortHostname" => "hostname"}\n    }\n}\n```'),
		createSnippet('prune', 'plugin', 'prune {\n\t$0\n}', '**[prune](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-prune.html) filter**\n\nPrunes event data based on a list of fields to blacklist or whitelist\n\n**_Example:_**  \n``` ruby\n    filter {\n      prune {\n        whitelist_names => [ "msg" ]\n      }\n    }\nAllows both `"msg"` and `"msg_short"` through.\n```'),
		createSnippet('range', 'plugin', 'range {\n\t$0\n}', '**[range](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-range.html) filter**\n\nChecks that specified fields stay within given size or length limits\n\n**_Example:_**  \n``` ruby\n    filter {\n      range {\n        ranges => [ "message", 0, 10, "tag:short",\n                    "message", 11, 100, "tag:medium",\n                    "message", 101, 1000, "tag:long",\n                    "message", 1001, 1e1000, "drop",\n                    "duration", 0, 100, "field:latency:fast",\n                    "duration", 101, 200, "field:latency:normal",\n                    "duration", 201, 1000, "field:latency:slow",\n                    "duration", 1001, 1e1000, "field:latency:outlier",\n                    "requests", 0, 10, "tag:too_few_%{host}_requests" ]\n      }\n    }\n```'),
		createSnippet('ruby', 'plugin', 'ruby {\n\t$0\n}', '**[ruby](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-ruby.html) filter**\n\nExecutes arbitrary Ruby code\n\n**_Example:_**  \n``` ruby\n    filter {\n      ruby {\n        # Cancel 90% of events\n        code => "event.cancel if rand <= 0.90"\n      }\n    }\n```'),
		createSnippet('sleep', 'plugin', 'sleep {\n\t$0\n}', '**[sleep](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-sleep.html) filter**\n\nSleeps for a specified time span\n\n**_Example:_**  \n``` ruby\n    filter {\n      sleep {\n        time => "1"   # Sleep 1 second\n        every => 10   # on every 10th event\n      }\n    }\n```'),
		createSnippet('split', 'plugin', 'split {\n\t$0\n}', '**[split](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-split.html) filter**\n\nSplits multi-line messages, strings, or arrays into distinct events\n\n**_Example:_**  \n``` ruby\nfilter {\n split {\n   field => "results"\n }\n}\n```'),
		createSnippet('syslog_pri', 'plugin', 'syslog_pri {\n\t$0\n}', '**[syslog_pri](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-syslog_pri.html) filter**\n\nParses the PRI (priority) field of a syslog message\n\n**_Example:_**  \n``` ruby\n    filter {\n      syslog_pri {\n        add_field => { "foo_%{somefield}" => "Hello world, from %{host}" }\n      }\n    }\n```'),
		createSnippet('threats_classifier', 'plugin', 'threats_classifier {\n\t$0\n}', '**[threats_classifier](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-threats_classifier.html) filter**\n\nEnriches security logs with information about the attacker’s intent'),
		createSnippet('throttle', 'plugin', 'throttle {\n\tkey => "${1:key}"\n}', '**[throttle](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-throttle.html) filter**\n\nThrottles the number of events\n\n**_Example:_**  \n``` ruby\n    filter {\n      throttle {\n        before_count => 3\n        after_count => 5\n        period => 3600\n        max_age => 7200\n        key => "%{host}%{message}"\n        add_tag => "throttled"\n      }\n      if "throttled" in [tags] {\n        drop { }\n      }\n    }\n```'),
		createSnippet('tld', 'plugin', 'tld {\n\t$0\n}', '**[tld](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-tld.html) filter**\n\nReplaces the contents of the default message field with whatever you specify in the configuration\n\n**_Example:_**  \n``` ruby\n    filter {\n      tld {\n        add_field => { "foo_%{somefield}" => "Hello world, from %{host}" }\n      }\n    }\n```'),
		createSnippet('translate', 'plugin', 'translate {\n\tsource => "${1:source}"\n}', '**[translate](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-translate.html) filter**\n\nReplaces field contents based on a hash or YAML file\n\n**_Example:_**  \n``` ruby\n    filter {\n      translate {\n        source => "[http][response][status_code]"\n        target => "[http_status_description]"\n        dictionary => {\n          "100" => "Continue"\n          "101" => "Switching Protocols"\n          "200" => "OK"\n          "500" => "Server Error"\n        }\n        fallback => "I\'m a teapot"\n      }\n    }\n```'),
		createSnippet('truncate', 'plugin', 'truncate {\n\tlength_bytes => ${1:123}\n}', '**[truncate](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-truncate.html) filter**\n\nTruncates fields longer than a given length\n\n**_Example:_**  \n``` ruby\n    filter {\n      truncate {\n        add_field => { "foo_%{somefield}" => "Hello world, from %{host}" }\n      }\n    }\n```'),
		createSnippet('urldecode', 'plugin', 'urldecode {\n\t$0\n}', '**[urldecode](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-urldecode.html) filter**\n\nDecodes URL-encoded fields\n\n**_Example:_**  \n``` ruby\n    filter {\n      urldecode {\n        add_field => { "foo_%{somefield}" => "Hello world, from %{host}" }\n      }\n    }\n```'),
		createSnippet('useragent', 'plugin', 'useragent {\n\tsource => "${1:source}"\n}', '**[useragent](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-useragent.html) filter**\n\nParses user agent strings into fields\n\n**_Example:_**  \n``` ruby\n    filter {\n      useragent {\n        source => \'message\'\n      }\n    }\n```'),
		createSnippet('uuid', 'plugin', 'uuid {\n\ttarget => "${1:target}"\n}', '**[uuid](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-uuid.html) filter**\n\nAdds a UUID to events\n\n**_Example:_**  \n``` ruby\n   filter {\n      uuid {\n        target    => "uuid"\n        overwrite => true\n      }\n   }\n```'),
		createSnippet('wurfl_device_detection', 'plugin', 'wurfl_device_detection {\n\t$0\n}', '**[wurfl_device_detection](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-wurfl_device_detection.html) filter**\n\nEnriches logs with device information such as brand, model, OS'),
		createSnippet('xml', 'plugin', 'xml {\n\tsource => "${1:source}"\n}', '**[xml](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-xml.html) filter**\n\nParses XML into fields\n\n**_Example:_**  \n``` ruby\nfilter {\n  xml {\n    namespaces => {\n      "xsl" => "http://www.w3.org/1999/XSL/Transform"\n      "xhtml" => "http://www.w3.org/1999/xhtml"\n    }\n  }\n}\n```')
	],
	'logstash-filter-uuid': [
		createSnippet('overwrite', 'option', 'overwrite => ${1|false,true|}', '**[overwrite](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-uuid.html#plugins-filters-uuid-overwrite) option**\n\n- Value type is boolean\n- Default value is false\n\nIf the value in the field currently (if any) should be overridden by the generated UUID. Defaults to false (i.e. if the field is present, with ANY value, it won’t be overridden)\n\n**_Example:_**  \n``` ruby\n   filter {\n      uuid {\n        target    => "uuid"\n        overwrite => true\n      }\n   }\n```'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-uuid.html#plugins-filters-uuid-target) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nSelect the name of the field where the generated UUID should be stored.\n\n**_Example:_**  \n``` ruby\n    filter {\n      uuid {\n        target => "uuid"\n      }\n    }\n```', true)
	],
	'logstash-input-common_options': [
		createSnippet('add_field', 'common_option', 'add_field => {\n\t"${1:field}" => "${2:value}"\n}', '**[add_field](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-azure_event_hubs.html#plugins-inputs-azure_event_hubs-add_field) option**\n\n- Value type is hash\n- Default value is {}\n\nAdd a field to an event'),
		createSnippet('codec', 'common_option', 'codec => ', '**[codec](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-azure_event_hubs.html#plugins-inputs-azure_event_hubs-codec) option**\n\n- Value type is codec\n- Default value is "plain"\n\nThe codec used for input data. Input codecs are a convenient method for decoding your data before it enters the input, without needing a separate filter in your Logstash pipeline.'),
		createSnippet('enable_metric', 'common_option', 'enable_metric => ${1|true,false|}', '**[enable_metric](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-azure_event_hubs.html#plugins-inputs-azure_event_hubs-enable_metric) option**\n\n- Value type is boolean\n- Default value is true\n\nDisable or enable metric logging for this specific plugin instance by default we record all the metrics we can, but you can disable metrics collection for a specific plugin.'),
		createSnippet('id', 'common_option', 'id => "${1:id}"', '**[id](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-azure_event_hubs.html#plugins-inputs-azure_event_hubs-id) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nAdd a unique ID to the plugin configuration. If no ID is specified, Logstash will generate one. It is strongly recommended to set this ID in your configuration. This is particularly useful when you have two or more plugins of the same type, for example, if you have 2 azure_event_hubs inputs. Adding a named ID in this case will help in monitoring Logstash when using the monitoring APIs.\n\n**_Example:_**  \n``` ruby\ninput {\n  azure_event_hubs {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('tags', 'common_option', 'tags => ["${1:tag}"]', '**[tags](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-azure_event_hubs.html#plugins-inputs-azure_event_hubs-tags) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nAdd any number of arbitrary tags to your event.'),
		createSnippet('type', 'common_option', 'type => "${1:type}"', '**[type](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-azure_event_hubs.html#plugins-inputs-azure_event_hubs-type) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nAdd a type field to all events handled by this input.')
	],
	'logstash-codec-edn': [
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-edn.html#plugins-codecs-edn-target) option**\n\n- Value type is string\n- There is no default value for this setting.\n- The option is only relevant while decoding.\n\nDefine the target field for placing the decoded fields. If this setting is not set, data will be stored at the root (top level) of the event.\n\n**_Example:_**  \n``` ruby\n    input {\n      tcp {\n        port => 4242\n        codec => edn {\n          target => "[document]"\n        }\n      }\n    }\n```')
	],
	'logstash-output-zabbix': [
		createSnippet('multi_value', 'option', 'multi_value => ["${1:multi_value}"]', '**[multi_value](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-zabbix.html#plugins-outputs-zabbix-multi_value) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nUse the multi_value directive to send multiple key/value pairs. This can be thought of as an array, like:'),
		createSnippet('timeout', 'option', 'timeout => ${1:1}', '**[timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-zabbix.html#plugins-outputs-zabbix-timeout) option**\n\n- Value type is number\n- Default value is 1\n\nThe number of seconds to wait before giving up on a connection to the Zabbix server. This number should be very small, otherwise delays in delivery of other outputs could result.'),
		createSnippet('zabbix_host', 'option', 'zabbix_host => "${1:zabbix_host}"', '**[zabbix_host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-zabbix.html#plugins-outputs-zabbix-zabbix_host) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe field name which holds the Zabbix host name. This can be a sub-field of the @metadata field.', true),
		createSnippet('zabbix_key', 'option', 'zabbix_key => "${1:zabbix_key}"', '**[zabbix_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-zabbix.html#plugins-outputs-zabbix-zabbix_key) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nA single field name which holds the value you intend to use as the Zabbix item key. This can be a sub-field of the @metadata field. This directive will be ignored if using multi_value'),
		createSnippet('zabbix_server_host', 'option', 'zabbix_server_host => "${1:localhost}"', '**[zabbix_server_host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-zabbix.html#plugins-outputs-zabbix-zabbix_server_host) option**\n\n- Value type is string\n- Default value is "localhost"\n\nThe IP or resolvable hostname where the Zabbix server is running'),
		createSnippet('zabbix_server_port', 'option', 'zabbix_server_port => ${1:10051}', '**[zabbix_server_port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-zabbix.html#plugins-outputs-zabbix-zabbix_server_port) option**\n\n- Value type is number\n- Default value is 10051\n\nThe port on which the Zabbix server is running'),
		createSnippet('zabbix_value', 'option', 'zabbix_value => "${1:message}"', '**[zabbix_value](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-zabbix.html#plugins-outputs-zabbix-zabbix_value) option**\n\n- Value type is string\n- Default value is "message"\n\nThe field name which holds the value you want to send. This directive will be ignored if using multi_value')
	],
	'logstash-output-gelf': [
		createSnippet('chunksize', 'option', 'chunksize => ${1:1420}', '**[chunksize](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-gelf.html#plugins-outputs-gelf-chunksize) option**\n\n- Value type is number\n- Default value is 1420\n\nThe chunksize. You usually don’t need to change this.'),
		createSnippet('custom_fields', 'option', 'custom_fields => {\n\t"${1:key}" => "${2:value}"\n}', '**[custom_fields](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-gelf.html#plugins-outputs-gelf-custom_fields) option**\n\n- Value type is hash\n- Default value is {}\n\nThe GELF custom field mappings. GELF supports arbitrary attributes as custom fields. This exposes that. Exclude the _ portion of the field name e.g. custom_fields => [\'foo_field\', \'some_value\'] sets _foo_field = some_value.'),
		createSnippet('full_message', 'option', 'full_message => "${1:%{message\\}}"', '**[full_message](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-gelf.html#plugins-outputs-gelf-full_message) option**\n\n- Value type is string\n- Default value is "%{message}"\n\nThe GELF full message. Dynamic values like %{foo} are permitted here.'),
		createSnippet('host', 'option', 'host => "${1:host}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-gelf.html#plugins-outputs-gelf-host) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nGraylog2 server IP address or hostname.', true),
		createSnippet('ignore_metadata', 'option', 'ignore_metadata => ["${1:@timestamp}", "@version", "severity", "host", "source_host", "source_path", "short_message"]', '**[ignore_metadata](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-gelf.html#plugins-outputs-gelf-ignore_metadata) option**\n\n- Value type is array\n- Default value is ["@timestamp", "@version", "severity", "host", "source_host", "source_path", "short_message"]\n\nIgnore these fields when ship_metadata is set. Typically this lists the fields used in dynamic values for GELF fields.'),
		createSnippet('level', 'option', 'level => ["${1:%{severity\\}}", "INFO"]', '**[level](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-gelf.html#plugins-outputs-gelf-level) option**\n\n- Value type is array\n- Default value is ["%{severity}", "INFO"]\n\nThe GELF message level. Dynamic values like %{level} are permitted here; useful if you want to parse the log level from an event and use that as the GELF level/severity.'),
		createSnippet('port', 'option', 'port => ${1:12201}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-gelf.html#plugins-outputs-gelf-port) option**\n\n- Value type is number\n- Default value is 12201\n\nGraylog2 server port number.'),
		createSnippet('protocol', 'option', 'protocol => "${1:UDP}"', '**[protocol](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-gelf.html#plugins-outputs-gelf-protocol) option**\n\n- Value type is string\n- Default value is "UDP"\n\nBy default, this plugin outputs via the UDP transfer protocol, but can be configured to use TCP instead.'),
		createSnippet('sender', 'option', 'sender => "${1:%{host\\}}"', '**[sender](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-gelf.html#plugins-outputs-gelf-sender) option**\n\n- Value type is string\n- Default value is "%{host}"\n\nAllow overriding of the GELF sender field. This is useful if you want to use something other than the event’s source host as the "sender" of an event. A common case for this is using the application name instead of the hostname.'),
		createSnippet('ship_metadata', 'option', 'ship_metadata => ${1|true,false|}', '**[ship_metadata](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-gelf.html#plugins-outputs-gelf-ship_metadata) option**\n\n- Value type is boolean\n- Default value is true\n\nShould Logstash ship metadata within event object? This will cause Logstash to ship any fields in the event (such as those created by grok) in the GELF messages. These will be sent as underscored "additional fields".'),
		createSnippet('ship_tags', 'option', 'ship_tags => ${1|true,false|}', '**[ship_tags](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-gelf.html#plugins-outputs-gelf-ship_tags) option**\n\n- Value type is boolean\n- Default value is true\n\nShip tags within events. This will cause Logstash to ship the tags of an event as the field \\\\_tags.'),
		createSnippet('short_message', 'option', 'short_message => "${1:short_message}"', '**[short_message](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-gelf.html#plugins-outputs-gelf-short_message) option**\n\n- Value type is string\n- Default value is "short_message"\n\nThe GELF short message field name. If the field does not exist or is empty, the event message is taken instead.')
	],
	'logstash-output-ganglia': [
		createSnippet('group', 'option', 'group => "${1:group}"', '**[group](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-ganglia.html#plugins-outputs-ganglia-group) option**\n\n- Value type is string\n- Default value is ""\n\nMetric group'),
		createSnippet('host', 'option', 'host => "${1:localhost}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-ganglia.html#plugins-outputs-ganglia-host) option**\n\n- Value type is string\n- Default value is "localhost"\n\nThe address of the ganglia server.'),
		createSnippet('lifetime', 'option', 'lifetime => ${1:300}', '**[lifetime](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-ganglia.html#plugins-outputs-ganglia-lifetime) option**\n\n- Value type is number\n- Default value is 300\n\nLifetime in seconds of this metric'),
		createSnippet('max_interval', 'option', 'max_interval => ${1:60}', '**[max_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-ganglia.html#plugins-outputs-ganglia-max_interval) option**\n\n- Value type is number\n- Default value is 60\n\nMaximum time in seconds between gmetric calls for this metric.'),
		createSnippet('metric', 'option', 'metric => "${1:metric}"', '**[metric](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-ganglia.html#plugins-outputs-ganglia-metric) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe metric to use. This supports dynamic strings like %{host}', true),
		createSnippet('metric_type', 'option', 'metric_type => "${1|uint8,int8,string,int16,uint16,int32,uint32,float,double|}"$0', '**[metric_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-ganglia.html#plugins-outputs-ganglia-metric_type) option**\n\n- Value can be any of: string, int8, uint8, int16, uint16, int32, uint32, float, double\n- Default value is "uint8"\n\nThe type of value for this metric.'),
		createSnippet('port', 'option', 'port => ${1:8649}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-ganglia.html#plugins-outputs-ganglia-port) option**\n\n- Value type is number\n- Default value is 8649\n\nThe port to connect on your ganglia server.'),
		createSnippet('slope', 'option', 'slope => "${1|both,positive,negative,zero,unspecified|}"$0', '**[slope](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-ganglia.html#plugins-outputs-ganglia-slope) option**\n\n- Value can be any of: zero, positive, negative, both, unspecified\n- Default value is "both"\n\nMetric slope, represents metric behavior'),
		createSnippet('units', 'option', 'units => "${1:units}"', '**[units](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-ganglia.html#plugins-outputs-ganglia-units) option**\n\n- Value type is string\n- Default value is ""\n\nGmetric units for metric, such as "kb/sec" or "ms" or whatever unit this metric uses.'),
		createSnippet('value', 'option', 'value => "${1:value}"', '**[value](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-ganglia.html#plugins-outputs-ganglia-value) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe value to use. This supports dynamic strings like %{bytes} It will be coerced to a floating point value. Values which cannot be coerced will zero (0)', true)
	],
	'logstash-output-lumberjack': [
		createSnippet('flush_size', 'option', 'flush_size => ${1:1024}', '**[flush_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-lumberjack.html#plugins-outputs-lumberjack-flush_size) option**\n\n- Value type is number\n- Default value is 1024\n\nTo make efficient calls to the lumberjack output we are buffering events locally. if the number of events exceed the number the declared flush_size we will send them to the logstash server.'),
		createSnippet('hosts', 'option', 'hosts => ["${1:host}"]', '**[hosts](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-lumberjack.html#plugins-outputs-lumberjack-hosts) option**\n\n- This is a required setting.\n- Value type is array\n- There is no default value for this setting.\n\nList of addresses lumberjack can send to. When the plugin needs to connect to the remote peer, it randomly selects one of the hosts.', true),
		createSnippet('idle_flush_time', 'option', 'idle_flush_time => ${1:1}', '**[idle_flush_time](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-lumberjack.html#plugins-outputs-lumberjack-idle_flush_time) option**\n\n- Value type is number\n- Default value is 1\n\nThe amount of time since last flush before a flush is forced.'),
		createSnippet('port', 'option', 'port => ${1:123}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-lumberjack.html#plugins-outputs-lumberjack-port) option**\n\n- This is a required setting.\n- Value type is number\n- There is no default value for this setting.\n\nthe port to connect to', true),
		createSnippet('ssl_certificate', 'option', 'ssl_certificate => "${1:/path/to/file}"', '**[ssl_certificate](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-lumberjack.html#plugins-outputs-lumberjack-ssl_certificate) option**\n\n- This is a required setting.\n- Value type is path\n- There is no default value for this setting.\n\nssl certificate to use', true)
	],
	'logstash-codec-protobuf': [
		createSnippet('class_name', 'option', 'class_name => "${1:class_name}"', '**[class_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-protobuf.html#plugins-codecs-protobuf-class_name) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nFully qualified name of the class to decode. Please note that the module delimiter is different depending on the protobuf version. For protobuf v2, use double colons:\n\n**_Example:_**  \n``` ruby\nclass_name => "Animals::Mammals::Unicorn"\n```', true),
		createSnippet('class_file', 'option', 'class_file => "${1:class_file}"', '**[class_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-protobuf.html#plugins-codecs-protobuf-class_file) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nAbsolute path to the directory that contains all compiled protobuf files. If the protobuf definitions are spread across multiple folders, this needs to point to the folder containing all those folders.'),
		createSnippet('protobuf_root_directory', 'option', 'protobuf_root_directory => "${1:protobuf_root_directory}"', '**[protobuf_root_directory](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-protobuf.html#plugins-codecs-protobuf-protobuf_root_directory) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nAbsolute path to the root directory that contains all referenced/used dependencies of the main class (class_name) or any of its dependencies. Must be used in combination with the class_file setting, and can not be used in combination with the legacy loading mechanism include_path.'),
		createSnippet('include_path', 'option', 'include_path => ["${1:include_path}"]', '**[include_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-protobuf.html#plugins-codecs-protobuf-include_path) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nLegacy protobuf definition loading mechanism for backwards compatibility: List of absolute pathes to files with protobuf definitions. When using more than one file, make sure to arrange the files in reverse order of dependency so that each class is loaded before it is refered to by another.\n\n**_Example:_**  \n``` ruby\ninclude_path => [\'/path/to/pb_definitions/wings.pb.rb\',\'/path/to/pb_definitions/unicorn.pb.rb\']\n```'),
		createSnippet('protobuf_version', 'option', 'protobuf_version => ${1:2}', '**[protobuf_version](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-protobuf.html#plugins-codecs-protobuf-protobuf_version) option**\n\n- Value type is number\n- Default value is 2\n\nProtocol buffers version. Valid settings are 2, 3.', true),
		createSnippet('stop_on_error', 'option', 'stop_on_error => ${1|false,true|}', '**[stop_on_error](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-protobuf.html#plugins-codecs-protobuf-stop_on_error) option**\n\n- Value type is boolean\n- Default value is false\n\nStop entire pipeline when encountering a non decodable message.'),
		createSnippet('pb3_encoder_autoconvert_types', 'option', 'pb3_encoder_autoconvert_types => ${1|true,false|}', '**[pb3_encoder_autoconvert_types](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-protobuf.html#plugins-codecs-protobuf-pb3_encoder_autoconvert_types) option**\n\n- Value type is boolean\n- Default value is true\n\nConvert data types to match the protobuf definition (if possible). The protobuf encoder library is very strict with regards to data types. Example: an event has an integer field but the protobuf definition expects a float. This would lead to an exception and the event would be lost.')
	],
	'logstash-filter-throttle': [
		createSnippet('after_count', 'option', 'after_count => ${1:-1}', '**[after_count](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-throttle.html#plugins-filters-throttle-after_count) option**\n\n- Value type is number\n- Default value is -1\n\nEvents greater than this count will be throttled. Setting this value to -1, the default, will cause no events to be throttled based on the upper bound.'),
		createSnippet('before_count', 'option', 'before_count => ${1:-1}', '**[before_count](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-throttle.html#plugins-filters-throttle-before_count) option**\n\n- Value type is number\n- Default value is -1\n\nEvents less than this count will be throttled. Setting this value to -1, the default, will cause no events to be throttled based on the lower bound.'),
		createSnippet('key', 'option', 'key => "${1:key}"', '**[key](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-throttle.html#plugins-filters-throttle-key) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe key used to identify events. Events with the same key are grouped together. Field substitutions are allowed, so you can combine multiple fields.', true),
		createSnippet('max_age', 'option', 'max_age => ${1:3600}', '**[max_age](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-throttle.html#plugins-filters-throttle-max_age) option**\n\n- Value type is number\n- Default value is 3600\n\nThe maximum age of a timeslot. Higher values allow better tracking of an asynchronous flow of events, but require more memory. As a rule of thumb you should set this value to at least twice the period. Or set this value to period + maximum time offset between unordered events with the same key. Values below the specified period give unexpected results if unordered events are processed simultaneously.'),
		createSnippet('max_counters', 'option', 'max_counters => ${1:100000}', '**[max_counters](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-throttle.html#plugins-filters-throttle-max_counters) option**\n\n- Value type is number\n- Default value is 100000\n\nThe maximum number of counters to store before decreasing the maximum age of a timeslot. Setting this value to -1 will prevent an upper bound with no constraint on the number of counters. This configuration value should only be used as a memory control mechanism and can cause early counter expiration if the value is reached. It is recommended to leave the default value and ensure that your key is selected such that it limits the number of counters required (i.e. don’t use UUID as the key).'),
		createSnippet('period', 'option', 'period => "${1:60}"', '**[period](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-throttle.html#plugins-filters-throttle-period) option**\n\n- Value type is string\n- Default value is "60"\n\nThe period in seconds after the first occurrence of an event until a new timeslot is created. This period is tracked per unique key and per timeslot. Field substitutions are allowed in this value. This allows you to specify that certain kinds of events throttle for a specific period of time.')
	],
	'logstash-codec-csv': [
		createSnippet('autodetect_column_names', 'option', 'autodetect_column_names => ${1|false,true|}', '**[autodetect_column_names](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-csv.html#plugins-codecs-csv-autodetect_column_names) option**\n\n- Value type is boolean\n- Default value is false\n\nDefine whether column names should be auto-detected from the header column or not. Defaults to false.'),
		createSnippet('autogenerate_column_names', 'option', 'autogenerate_column_names => ${1|true,false|}', '**[autogenerate_column_names](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-csv.html#plugins-codecs-csv-autogenerate_column_names) option**\n\n- Value type is boolean\n- Default value is true\n\nDefine whether column names should be autogenerated or not. Defaults to true. If set to false, columns not having a header specified will not be parsed.'),
		createSnippet('charset', 'option', 'charset => "${1|UTF-8,ASCII-8BIT,US-ASCII,Big5,Big5-HKSCS,Big5-UAO,CP949,Emacs-Mule,EUC-JP,EUC-KR,EUC-TW,GB2312,GB18030,GBK,ISO-8859-1,ISO-8859-2,ISO-8859-3,ISO-8859-4,ISO-8859-5,ISO-8859-6,ISO-8859-7,ISO-8859-8,ISO-8859-9,ISO-8859-10,ISO-8859-11,ISO-8859-13,ISO-8859-14,ISO-8859-15,ISO-8859-16,KOI8-R,KOI8-U,Shift_JIS,UTF-16BE,UTF-16LE,UTF-32BE,UTF-32LE,Windows-31J,Windows-1250,Windows-1251,Windows-1252,IBM437,IBM737,IBM775,CP850,IBM852,CP852,IBM855,CP855,IBM857,IBM860,IBM861,IBM862,IBM863,IBM864,IBM865,IBM866,IBM869,Windows-1258,GB1988,macCentEuro,macCroatian,macCyrillic,macGreek,macIceland,macRoman,macRomania,macThai,macTurkish,macUkraine,CP950,CP951,IBM037,stateless-ISO-2022-JP,eucJP-ms,CP51932,EUC-JIS-2004,GB12345,ISO-2022-JP,ISO-2022-JP-2,CP50220,CP50221,Windows-1256,Windows-1253,Windows-1255,Windows-1254,TIS-620,Windows-874,Windows-1257,MacJapanese,UTF-7,UTF8-MAC,UTF-16,UTF-32,UTF8-DoCoMo,SJIS-DoCoMo,UTF8-KDDI,SJIS-KDDI,ISO-2022-JP-KDDI,stateless-ISO-2022-JP-KDDI,UTF8-SoftBank,SJIS-SoftBank,BINARY,CP437,CP737,CP775,IBM850,CP857,CP860,CP861,CP862,CP863,CP864,CP865,CP866,CP869,CP1258,Big5-HKSCS:2008,ebcdic-cp-us,eucJP,euc-jp-ms,EUC-JISX0213,eucKR,eucTW,EUC-CN,eucCN,CP936,ISO2022-JP,ISO2022-JP2,ISO8859-1,ISO8859-2,ISO8859-3,ISO8859-4,ISO8859-5,ISO8859-6,CP1256,ISO8859-7,CP1253,ISO8859-8,CP1255,ISO8859-9,CP1254,ISO8859-10,ISO8859-11,CP874,ISO8859-13,CP1257,ISO8859-14,ISO8859-15,ISO8859-16,CP878,MacJapan,ASCII,ANSI_X3.4-1968,646,CP65000,CP65001,UTF-8-MAC,UTF-8-HFS,UCS-2BE,UCS-4BE,UCS-4LE,CP932,csWindows31J,SJIS,PCK,CP1250,CP1251,CP1252,external,locale|}"$0', '**[charset](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-csv.html#plugins-codecs-csv-charset) option**\n\n- Value can be any of: ASCII-8BIT, UTF-8, US-ASCII, Big5, Big5-HKSCS, Big5-UAO, CP949, Emacs-Mule, EUC-JP, EUC-KR, EUC-TW, GB2312, GB18030, GBK, ISO-8859-1, ISO-8859-2, ISO-8859-3, ISO-8859-4, ISO-8859-5, ISO-8859-6, ISO-8859-7, ISO-8859-8, ISO-8859-9, ISO-8859-10, ISO-8859-11, ISO-8859-13, ISO-8859-14, ISO-8859-15, ISO-8859-16, KOI8-R, KOI8-U, Shift_JIS, UTF-16BE, UTF-16LE, UTF-32BE, UTF-32LE, Windows-31J, Windows-1250, Windows-1251, Windows-1252, IBM437, IBM737, IBM775, CP850, IBM852, CP852, IBM855, CP855, IBM857, IBM860, IBM861, IBM862, IBM863, IBM864, IBM865, IBM866, IBM869, Windows-1258, GB1988, macCentEuro, macCroatian, macCyrillic, macGreek, macIceland, macRoman, macRomania, macThai, macTurkish, macUkraine, CP950, CP951, IBM037, stateless-ISO-2022-JP, eucJP-ms, CP51932, EUC-JIS-2004, GB12345, ISO-2022-JP, ISO-2022-JP-2, CP50220, CP50221, Windows-1256, Windows-1253, Windows-1255, Windows-1254, TIS-620, Windows-874, Windows-1257, MacJapanese, UTF-7, UTF8-MAC, UTF-16, UTF-32, UTF8-DoCoMo, SJIS-DoCoMo, UTF8-KDDI, SJIS-KDDI, ISO-2022-JP-KDDI, stateless-ISO-2022-JP-KDDI, UTF8-SoftBank, SJIS-SoftBank, BINARY, CP437, CP737, CP775, IBM850, CP857, CP860, CP861, CP862, CP863, CP864, CP865, CP866, CP869, CP1258, Big5-HKSCS:2008, ebcdic-cp-us, eucJP, euc-jp-ms, EUC-JISX0213, eucKR, eucTW, EUC-CN, eucCN, CP936, ISO2022-JP, ISO2022-JP2, ISO8859-1, ISO8859-2, ISO8859-3, ISO8859-4, ISO8859-5, ISO8859-6, CP1256, ISO8859-7, CP1253, ISO8859-8, CP1255, ISO8859-9, CP1254, ISO8859-10, ISO8859-11, CP874, ISO8859-13, CP1257, ISO8859-14, ISO8859-15, ISO8859-16, CP878, MacJapan, ASCII, ANSI_X3.4-1968, 646, CP65000, CP65001, UTF-8-MAC, UTF-8-HFS, UCS-2BE, UCS-4BE, UCS-4LE, CP932, csWindows31J, SJIS, PCK, CP1250, CP1251, CP1252, external, locale\n- Default value is "UTF-8"\n\nList of valid conversion types used for the convert option The character encoding used in this codec. Examples include "UTF-8" and "CP1252".'),
		createSnippet('columns', 'option', 'columns => ["${1:column}"]', '**[columns](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-csv.html#plugins-codecs-csv-columns) option**\n\n- Value type is array\n- Default value is []\n\nWhen decoding: Define a list of column names (in the order they appear in the CSV, as if it were a header line). If columns is not configured, or there are not enough columns specified, the default column names are "column1", "column2", etc.'),
		createSnippet('convert', 'option', 'convert => {\n\t"${1:key}" => "${2:value}"\n}', '**[convert](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-csv.html#plugins-codecs-csv-convert) option**\n\n- Value type is hash\n- Default value is {}\n\nDefine a set of datatype conversions to be applied to columns. Possible conversions are: integer, float, date, date_time, boolean\n\n**_Example:_**  \n``` ruby\n    filter {\n      csv {\n        convert => { "column1" => "integer", "column2" => "boolean" }\n      }\n    }\n```'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-csv.html#plugins-codecs-csv-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: CSV data added at root level v1,v8: Elastic Common Schema compliant behavior ([event][original] is also added)\n- disabled: CSV data added at root level\n- v1,v8: Elastic Common Schema compliant behavior ([event][original] is also added)\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled\n\nSupported values are:'),
		createSnippet('include_headers', 'option', 'include_headers => ${1|false,true|}', '**[include_headers](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-csv.html#plugins-codecs-csv-include_headers) option**\n\n- Value type is boolean\n- Default value is false\n\nWhen encoding in an output plugin, include headers in the encoded CSV once per codec lifecyle (not for every event). Default ⇒ false'),
		createSnippet('quote_char', 'option', 'quote_char => "${1:\\"}"', '**[quote_char](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-csv.html#plugins-codecs-csv-quote_char) option**\n\n- Value type is string\n- Default value is "\\\\""\n\nDefine the character used to quote CSV fields. If this is not specified the default is a double quote ". Optional.'),
		createSnippet('separator', 'option', 'separator => "${1:,}"', '**[separator](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-csv.html#plugins-codecs-csv-separator) option**\n\n- Value type is string\n- Default value is ","\n\nDefine the column separator value. If this is not specified, the default is a comma ,. Optional.'),
		createSnippet('skip_empty_columns', 'option', 'skip_empty_columns => ${1|false,true|}', '**[skip_empty_columns](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-csv.html#plugins-codecs-csv-skip_empty_columns) option**\n\n- Value type is boolean\n- Default value is false\n\nDefine whether empty columns should be skipped. Defaults to false. If set to true, columns containing no value will not be included.'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-csv.html#plugins-codecs-csv-target) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nDefine the target field for placing the row values. If this setting is not set, the CSV data will be stored at the root (top level) of the event.\n\n**_Example:_**  \n``` ruby\n    input {\n      file {\n        codec => csv {\n          autodetect_column_names => true\n          target => "[document]"\n        }\n      }\n    }\n```')
	],
	'logstash-input-rabbitmq': [
		createSnippet('ack', 'option', 'ack => ${1|true,false|}', '**[ack](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-ack) option**\n\n- Value type is boolean\n- Default value is true\n\nEnable message acknowledgements. With acknowledgements messages fetched by Logstash but not yet sent into the Logstash pipeline will be requeued by the server if Logstash shuts down. Acknowledgements will however hurt the message throughput.'),
		createSnippet('arguments', 'option', 'arguments => {$1}', '**[arguments](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-arguments) option**\n\n- Value type is array\n- Default value is {}\n\nOptional queue arguments as an array.'),
		createSnippet('auto_delete', 'option', 'auto_delete => ${1|false,true|}', '**[auto_delete](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-auto_delete) option**\n\n- Value type is boolean\n- Default value is false\n\nShould the queue be deleted on the broker when the last consumer disconnects? Set this option to false if you want the queue to remain on the broker, queueing up messages until a consumer comes along to consume them.'),
		createSnippet('automatic_recovery', 'option', 'automatic_recovery => ${1|true,false|}', '**[automatic_recovery](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-automatic_recovery) option**\n\n- Value type is boolean\n- Default value is true\n\nSet this to automatically recover from a broken connection. You almost certainly don’t want to override this!'),
		createSnippet('connect_retry_interval', 'option', 'connect_retry_interval => ${1:1}', '**[connect_retry_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-connect_retry_interval) option**\n\n- Value type is number\n- Default value is 1\n\nTime in seconds to wait before retrying a connection'),
		createSnippet('connection_timeout', 'option', 'connection_timeout => ${1:123}', '**[connection_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-connection_timeout) option**\n\n- Value type is number\n- There is no default value for this setting.\n\nThe default connection timeout in milliseconds. If not specified the timeout is infinite.'),
		createSnippet('durable', 'option', 'durable => ${1|false,true|}', '**[durable](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-durable) option**\n\n- Value type is boolean\n- Default value is false\n\nIs this queue durable? (aka; Should it survive a broker restart?) If consuming directly from a queue you must set this value to match the existing queue setting, otherwise the connection will fail due to an inequivalent arg error.'),
		createSnippet('exchange', 'option', 'exchange => "${1:exchange}"', '**[exchange](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-exchange) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe name of the exchange to bind the queue to. Specify exchange_type as well to declare the exchange if it does not exist'),
		createSnippet('exchange_type', 'option', 'exchange_type => "${1:exchange_type}"', '**[exchange_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-exchange_type) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe type of the exchange to bind to. Specifying this will cause this plugin to declare the exchange if it does not exist.'),
		createSnippet('exclusive', 'option', 'exclusive => ${1|false,true|}', '**[exclusive](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-exclusive) option**\n\n- Value type is boolean\n- Default value is false\n\nIs the queue exclusive? Exclusive queues can only be used by the connection that declared them and will be deleted when it is closed (e.g. due to a Logstash restart).'),
		createSnippet('heartbeat', 'option', 'heartbeat => ${1:123}', '**[heartbeat](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-heartbeat) option**\n\n- Value type is number\n- There is no default value for this setting.\n\nHeartbeat timeout in seconds. If unspecified then heartbeat timeout of 60 seconds will be used.'),
		createSnippet('host', 'option', 'host => "${1:host}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-host) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nCommon functionality for the rabbitmq input/output RabbitMQ server address(es) host can either be a single host, or a list of hosts i.e. host ⇒ "localhost" or host ⇒ ["host01", "host02]', true),
		createSnippet('key', 'option', 'key => "${1:logstash}"', '**[key](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-key) option**\n\n- Value type is string\n- Default value is "logstash"\n\nThe routing key to use when binding a queue to the exchange. This is only relevant for direct or topic exchanges.'),
		createSnippet('metadata_enabled', 'option', 'metadata_enabled => ${1|true,false|}', '**[metadata_enabled](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-metadata_enabled) option**\n\n- Value type is string\n- Accepted values are: none: no metadata is added basic: headers and properties are added extended: headers, properties, and raw payload are added false: deprecated alias for none true: deprecated alias for basic\n- none: no metadata is added\n- basic: headers and properties are added\n- extended: headers, properties, and raw payload are added\n- false: deprecated alias for none\n- true: deprecated alias for basic\n- Default value is none\n\nAccepted values are:'),
		createSnippet('passive', 'option', 'passive => ${1|false,true|}', '**[passive](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-passive) option**\n\n- Value type is boolean\n- Default value is false\n\nIf true the queue will be passively declared, meaning it must already exist on the server. To have Logstash create the queue if necessary leave this option as false. If actively declaring a queue that already exists, the queue options for this plugin (durable etc) must match those of the existing queue.'),
		createSnippet('password', 'option', 'password => "${1:guest}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-password) option**\n\n- Value type is password\n- Default value is "guest"\n\nRabbitMQ password'),
		createSnippet('port', 'option', 'port => ${1:5672}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-port) option**\n\n- Value type is number\n- Default value is 5672\n\nRabbitMQ port to connect on'),
		createSnippet('prefetch_count', 'option', 'prefetch_count => ${1:256}', '**[prefetch_count](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-prefetch_count) option**\n\n- Value type is number\n- Default value is 256\n\nPrefetch count. If acknowledgements are enabled with the ack option, specifies the number of outstanding unacknowledged messages allowed.'),
		createSnippet('queue', 'option', 'queue => "${1:queue}"', '**[queue](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-queue) option**\n\n- Value type is string\n- Default value is ""\n\nThe properties to extract from each message and store in a @metadata field.'),
		createSnippet('ssl', 'option', 'ssl => ${1|true,false|}', '**[ssl](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-ssl) option**\n\n- Value type is boolean\n- There is no default value for this setting.\n\nEnable or disable SSL. Note that by default remote certificate verification is off. Specify ssl_certificate_path and ssl_certificate_password if you need certificate verification'),
		createSnippet('ssl_certificate_password', 'option', 'ssl_certificate_password => "${1:ssl_certificate_password}"', '**[ssl_certificate_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-ssl_certificate_password) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nPassword for the encrypted PKCS12 (.p12) certificate file specified in ssl_certificate_path'),
		createSnippet('ssl_certificate_path', 'option', 'ssl_certificate_path => "${1:/path/to/file}"', '**[ssl_certificate_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-ssl_certificate_path) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nPath to an SSL certificate in PKCS12 (.p12) format used for verifying the remote host'),
		createSnippet('ssl_version', 'option', 'ssl_version => "${1:TLSv1.2}"', '**[ssl_version](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-ssl_version) option**\n\n- Value type is string\n- Default value is "TLSv1.2"\n\nVersion of the SSL protocol to use.'),
		createSnippet('subscription_retry_interval_seconds', 'option', 'subscription_retry_interval_seconds => ${1:5}', '**[subscription_retry_interval_seconds](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-subscription_retry_interval_seconds) option**\n\n- This is a required setting.\n- Value type is number\n- Default value is 5\n\nAmount of time in seconds to wait after a failed subscription request before retrying. Subscribes can fail if the server goes away and then comes back.', true),
		createSnippet('threads', 'option', 'threads => ${1:1}', '**[threads](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-threads) option**\n\n- Value type is number\n- Default value is 1'),
		createSnippet('user', 'option', 'user => "${1:guest}"', '**[user](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-user) option**\n\n- Value type is string\n- Default value is "guest"\n\nRabbitMQ username'),
		createSnippet('vhost', 'option', 'vhost => "${1:/}"', '**[vhost](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html#plugins-inputs-rabbitmq-vhost) option**\n\n- Value type is string\n- Default value is "/"\n\nThe vhost (virtual host) to use. If you don’t know what this is, leave the default. With the exception of the default vhost ("/"), names of vhosts should not begin with a forward slash.')
	],
	'logstash-output-irc': [
		createSnippet('channels', 'option', 'channels => ["${1:channel}"]', '**[channels](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-irc.html#plugins-outputs-irc-channels) option**\n\n- This is a required setting.\n- Value type is array\n- There is no default value for this setting.\n\nChannels to broadcast to.', true),
		createSnippet('format', 'option', 'format => "${1:%{message\\}}"', '**[format](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-irc.html#plugins-outputs-irc-format) option**\n\n- Value type is string\n- Default value is "%{message}"\n\nMessage format to send, event tokens are usable here'),
		createSnippet('host', 'option', 'host => "${1:host}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-irc.html#plugins-outputs-irc-host) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nAddress of the host to connect to', true),
		createSnippet('messages_per_second', 'option', 'messages_per_second => ${1:0.5}', '**[messages_per_second](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-irc.html#plugins-outputs-irc-messages_per_second) option**\n\n- Value type is number\n- Default value is 0.5\n\nLimit the rate of messages sent to IRC in messages per second.'),
		createSnippet('nick', 'option', 'nick => "${1:logstash}"', '**[nick](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-irc.html#plugins-outputs-irc-nick) option**\n\n- Value type is string\n- Default value is "logstash"\n\nIRC Nickname'),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-irc.html#plugins-outputs-irc-password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nIRC server password'),
		createSnippet('port', 'option', 'port => ${1:6667}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-irc.html#plugins-outputs-irc-port) option**\n\n- Value type is number\n- Default value is 6667\n\nPort on host to connect to.'),
		createSnippet('post_string', 'option', 'post_string => "${1:post_string}"', '**[post_string](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-irc.html#plugins-outputs-irc-post_string) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nStatic string after event'),
		createSnippet('pre_string', 'option', 'pre_string => "${1:pre_string}"', '**[pre_string](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-irc.html#plugins-outputs-irc-pre_string) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nStatic string before event'),
		createSnippet('real', 'option', 'real => "${1:logstash}"', '**[real](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-irc.html#plugins-outputs-irc-real) option**\n\n- Value type is string\n- Default value is "logstash"\n\nIRC Real name'),
		createSnippet('secure', 'option', 'secure => ${1|false,true|}', '**[secure](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-irc.html#plugins-outputs-irc-secure) option**\n\n- Value type is boolean\n- Default value is false\n\nSet this to true to enable SSL.'),
		createSnippet('user', 'option', 'user => "${1:logstash}"', '**[user](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-irc.html#plugins-outputs-irc-user) option**\n\n- Value type is string\n- Default value is "logstash"\n\nIRC Username')
	],
	'logstash-codec-graphite': [
		createSnippet('exclude_metrics', 'option', 'exclude_metrics => ["${1:%{[^\\}]+\\}}"]', '**[exclude_metrics](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-graphite.html#plugins-codecs-graphite-exclude_metrics) option**\n\n- Value type is array\n- Default value is ["%{[^}]+}"]\n\nExclude regex matched metric names, by default exclude unresolved %{field} strings'),
		createSnippet('fields_are_metrics', 'option', 'fields_are_metrics => ${1|false,true|}', '**[fields_are_metrics](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-graphite.html#plugins-codecs-graphite-fields_are_metrics) option**\n\n- Value type is boolean\n- Default value is false\n\nIndicate that the event @fields should be treated as metrics and will be sent as is to graphite'),
		createSnippet('include_metrics', 'option', 'include_metrics => ["${1:.*}"]', '**[include_metrics](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-graphite.html#plugins-codecs-graphite-include_metrics) option**\n\n- Value type is array\n- Default value is [".*"]\n\nInclude only regex matched metric names'),
		createSnippet('metrics', 'option', 'metrics => {\n\t"${1:key}" => "${2:value}"\n}', '**[metrics](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-graphite.html#plugins-codecs-graphite-metrics) option**\n\n- Value type is hash\n- Default value is {}\n\nThe metric(s) to use. This supports dynamic strings like %{host} for metric names and also for values. This is a hash field with key of the metric name, value of the metric value. Example:'),
		createSnippet('metrics_format', 'option', 'metrics_format => "${1:*}"', '**[metrics_format](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-graphite.html#plugins-codecs-graphite-metrics_format) option**\n\n- Value type is string\n- Default value is "*"\n\nDefines format of the metric string. The placeholder * will be replaced with the name of the actual metric. This supports dynamic strings like %{host}.\n\n**_Example:_**  \n``` ruby\n    metrics_format => "%{host}.foo.bar.*.sum"\n```')
	],
	'logstash-output-stdout': [
	],
	'logstash-input-cloudwatch': [
		createSnippet('access_key_id', 'option', 'access_key_id => "${1:access_key_id}"', '**[access_key_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-cloudwatch.html#plugins-inputs-cloudwatch-access_key_id) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThis plugin uses the AWS SDK and supports several ways to get credentials, which will be tried in this order:'),
		createSnippet('aws_credentials_file', 'option', 'aws_credentials_file => "${1:aws_credentials_file}"', '**[aws_credentials_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-cloudwatch.html#plugins-inputs-cloudwatch-aws_credentials_file) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nPath to YAML file containing a hash of AWS credentials. This file will only be loaded if access_key_id and secret_access_key aren’t set. The contents of the file should look like this:'),
		createSnippet('combined', 'option', 'combined => ${1|false,true|}', '**[combined](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-cloudwatch.html#plugins-inputs-cloudwatch-combined) option**\n\n- Value type is boolean\n- Default value is false\n\nUse this for namespaces that need to combine the dimensions like S3 and SNS.'),
		createSnippet('endpoint', 'option', 'endpoint => "${1:endpoint}"', '**[endpoint](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-cloudwatch.html#plugins-inputs-cloudwatch-endpoint) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe endpoint to connect to. By default it is constructed using the value of region. This is useful when connecting to S3 compatible services, but beware that these aren’t guaranteed to work correctly with the AWS SDK.'),
		createSnippet('filters', 'option', 'filters => ["${1:filter}"]', '**[filters](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-cloudwatch.html#plugins-inputs-cloudwatch-filters) option**\n\n- This setting can be required or optional. See note below.\n- Value type is array\n- There is no default value for this setting.\n\nThis setting is optional when the namespace is AWS/EC2. Otherwise this is a required field.'),
		createSnippet('interval', 'option', 'interval => ${1:900}', '**[interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-cloudwatch.html#plugins-inputs-cloudwatch-interval) option**\n\n- Value type is number\n- Default value is 900\n\nSet how frequently CloudWatch should be queried'),
		createSnippet('metrics', 'option', 'metrics => ["${1:CPUUtilization}", "DiskReadOps", "DiskWriteOps", "NetworkIn", "NetworkOut"]', '**[metrics](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-cloudwatch.html#plugins-inputs-cloudwatch-metrics) option**\n\n- Value type is array\n- Default value is ["CPUUtilization", "DiskReadOps", "DiskWriteOps", "NetworkIn", "NetworkOut"]\n\nSpecify the metrics to fetch for the namespace. The defaults are AWS/EC2 specific. See http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/aws-namespaces.html for the available metrics for other namespaces.'),
		createSnippet('namespace', 'option', 'namespace => "${1:AWS/EC2}"', '**[namespace](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-cloudwatch.html#plugins-inputs-cloudwatch-namespace) option**\n\n- Value type is string\n- Default value is "AWS/EC2"\n\nIf undefined, LogStash will complain, even if codec is unused. The service namespace of the metrics to fetch.'),
		createSnippet('period', 'option', 'period => ${1:300}', '**[period](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-cloudwatch.html#plugins-inputs-cloudwatch-period) option**\n\n- Value type is number\n- Default value is 300\n\nSet the granularity of the returned datapoints.'),
		createSnippet('proxy_uri', 'option', 'proxy_uri => "${1:proxy_uri}"', '**[proxy_uri](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-cloudwatch.html#plugins-inputs-cloudwatch-proxy_uri) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nURI to proxy server if required'),
		createSnippet('region', 'option', 'region => "${1:us-east-1}"', '**[region](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-cloudwatch.html#plugins-inputs-cloudwatch-region) option**\n\n- Value type is string\n- Default value is "us-east-1"\n\nThe AWS Region'),
		createSnippet('role_arn', 'option', 'role_arn => "${1:role_arn}"', '**[role_arn](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-cloudwatch.html#plugins-inputs-cloudwatch-role_arn) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS IAM Role to assume, if any. This is used to generate temporary credentials, typically for cross-account access. See the AssumeRole API documentation for more information.'),
		createSnippet('role_session_name', 'option', 'role_session_name => "${1:logstash}"', '**[role_session_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-cloudwatch.html#plugins-inputs-cloudwatch-role_session_name) option**\n\n- Value type is string\n- Default value is "logstash"\n\nSession name to use when assuming an IAM role.'),
		createSnippet('secret_access_key', 'option', 'secret_access_key => "${1:secret_access_key}"', '**[secret_access_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-cloudwatch.html#plugins-inputs-cloudwatch-secret_access_key) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS Secret Access Key'),
		createSnippet('session_token', 'option', 'session_token => "${1:session_token}"', '**[session_token](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-cloudwatch.html#plugins-inputs-cloudwatch-session_token) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS Session token for temporary credential'),
		createSnippet('statistics', 'option', 'statistics => ["${1:SampleCount}", "Average", "Minimum", "Maximum", "Sum"]', '**[statistics](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-cloudwatch.html#plugins-inputs-cloudwatch-statistics) option**\n\n- Value type is array\n- Default value is ["SampleCount", "Average", "Minimum", "Maximum", "Sum"]\n\nSpecify the statistics to fetch for each namespace'),
		createSnippet('use_ssl', 'option', 'use_ssl => ${1|true,false|}', '**[use_ssl](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-cloudwatch.html#plugins-inputs-cloudwatch-use_ssl) option**\n\n- Value type is boolean\n- Default value is true\n\nMake sure we require the V1 classes when including this module. require aws-sdk will load v2 classes. Should we require (true) or disable (false) using SSL for communicating with the AWS API The AWS SDK for Ruby defaults to SSL so we preserve that')
	],
	'logstash-input-snmptrap': [
		createSnippet('community', 'option', 'community => ["${1:public}"]', '**[community](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-snmptrap.html#plugins-inputs-snmptrap-community) option**\n\n- Value type is array\n- Default value is "public"\n\nSNMP Community String to listen for.'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-snmptrap.html#plugins-inputs-snmptrap-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: does not use ECS-compatible field names (fields might be set at the root of the event) v1, v8: avoids field names that might conflict with Elastic Common Schema (for example, the host field)\n- disabled: does not use ECS-compatible field names (fields might be set at the root of the event)\n- v1, v8: avoids field names that might conflict with Elastic Common Schema (for example, the host field)\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:'),
		createSnippet('host', 'option', 'host => "${1:0.0.0.0}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-snmptrap.html#plugins-inputs-snmptrap-host) option**\n\n- Value type is string\n- Default value is "0.0.0.0"\n\nThe address to listen on'),
		createSnippet('port', 'option', 'port => ${1:1062}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-snmptrap.html#plugins-inputs-snmptrap-port) option**\n\n- Value type is number\n- Default value is 1062\n\nThe port to listen on. Remember that ports less than 1024 (privileged ports) may require root to use. hence the default of 1062.'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-snmptrap.html#plugins-inputs-snmptrap-target) option**\n\n- Value type is string\n- There is no default value for this setting\n\nThe name of the field under which SNMP payloads are assigned. If not specified data will be stored in the root of the event.'),
		createSnippet('yamlmibdir', 'option', 'yamlmibdir => "${1:yamlmibdir}"', '**[yamlmibdir](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-snmptrap.html#plugins-inputs-snmptrap-yamlmibdir) option**\n\n- Value type is string\n- There is no default value for this setting.\n\ndirectory of YAML MIB maps (same format ruby-snmp uses)')
	],
	'logstash-input-tcp': [
		createSnippet('dns_reverse_lookup_enabled', 'option', 'dns_reverse_lookup_enabled => ${1|true,false|}', '**[dns_reverse_lookup_enabled](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-tcp.html#plugins-inputs-tcp-dns_reverse_lookup_enabled) option**\n\n- Value type is boolean\n- Default value is true\n\nIt is possible to avoid DNS reverse-lookups by disabling this setting. If disabled, the address metadata that is added to events will contain the source address as-specified at the TCP layer and IPs will not be resolved to hostnames.'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-tcp.html#plugins-inputs-tcp-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: unstructured connection metadata added at root level v1,v8: structured connection metadata added under [@metadata][input][tcp]\n- disabled: unstructured connection metadata added at root level\n- v1,v8: structured connection metadata added under [@metadata][input][tcp]\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:'),
		createSnippet('host', 'option', 'host => "${1:0.0.0.0}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-tcp.html#plugins-inputs-tcp-host) option**\n\n- Value type is string\n- Default value is "0.0.0.0"\n\nWhen mode is server, the address to listen on. When mode is client, the address to connect to.'),
		createSnippet('mode', 'option', 'mode => "${1|server,client|}"$0', '**[mode](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-tcp.html#plugins-inputs-tcp-mode) option**\n\n- Value can be any of: server, client\n- Default value is "server"\n\nMode to operate in. server listens for client connections, client connects to a server.'),
		createSnippet('port', 'option', 'port => ${1:123}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-tcp.html#plugins-inputs-tcp-port) option**\n\n- This is a required setting.\n- Value type is number\n- There is no default value for this setting.\n\nWhen mode is server, the port to listen on. When mode is client, the port to connect to.', true),
		createSnippet('proxy_protocol', 'option', 'proxy_protocol => ${1|false,true|}', '**[proxy_protocol](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-tcp.html#plugins-inputs-tcp-proxy_protocol) option**\n\n- Value type is boolean\n- Default value is false\n\nProxy protocol support, only v1 is supported at this time http://www.haproxy.org/download/1.5/doc/proxy-protocol.txt'),
		createSnippet('ssl_cert', 'option', 'ssl_cert => "${1:/path/to/file}"', '**[ssl_cert](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-tcp.html#plugins-inputs-tcp-ssl_cert) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nPath to certificate in PEM format. This certificate will be presented to the connecting clients.'),
		createSnippet('ssl_certificate_authorities', 'option', 'ssl_certificate_authorities => ["${1:ssl_certificate_authoritie}"]', '**[ssl_certificate_authorities](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-tcp.html#plugins-inputs-tcp-ssl_certificate_authorities) option**\n\n- Value type is array\n- Default value is []\n\nValidate client certificate or certificate chain against these authorities. You can define multiple files or paths. All the certificates will be read and added to the trust store.'),
		createSnippet('ssl_enable', 'option', 'ssl_enable => ${1|false,true|}', '**[ssl_enable](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-tcp.html#plugins-inputs-tcp-ssl_enable) option**\n\n- Value type is boolean\n- Default value is false\n\nEnable SSL (must be set for other ssl_ options to take effect).'),
		createSnippet('ssl_extra_chain_certs', 'option', 'ssl_extra_chain_certs => ["${1:ssl_extra_chain_cert}"]', '**[ssl_extra_chain_certs](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-tcp.html#plugins-inputs-tcp-ssl_extra_chain_certs) option**\n\n- Value type is array\n- Default value is []\n\nAn Array of paths to extra X509 certificates. These are used together with the certificate to construct the certificate chain presented to the client.'),
		createSnippet('ssl_key', 'option', 'ssl_key => "${1:/path/to/file}"', '**[ssl_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-tcp.html#plugins-inputs-tcp-ssl_key) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nThe path to the private key corresponding to the specified certificate (PEM format).'),
		createSnippet('ssl_key_passphrase', 'option', 'ssl_key_passphrase => "${1:ssl_key_passphrase}"', '**[ssl_key_passphrase](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-tcp.html#plugins-inputs-tcp-ssl_key_passphrase) option**\n\n- Value type is password\n- Default value is nil\n\nSSL key passphrase for the private key.'),
		createSnippet('ssl_verify', 'option', 'ssl_verify => ${1|true,false|}', '**[ssl_verify](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-tcp.html#plugins-inputs-tcp-ssl_verify) option**\n\n- Value type is boolean\n- Default value is true\n\nVerify the identity of the other end of the SSL connection against the CA. For input, sets the field sslsubject to that of the client certificate.'),
		createSnippet('tcp_keep_alive', 'option', 'tcp_keep_alive => ${1|false,true|}', '**[tcp_keep_alive](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-tcp.html#plugins-inputs-tcp-tcp_keep_alive) option**\n\n- Value type is boolean\n- Default value is false\n\nInstruct the socket to use TCP keep alive. If it’s true then the underlying socket will use the OS defaults settings for keep alive. If it’s false it doesn’t configure any keep alive setting for the underlying socket.')
	],
	'logstash-filter-mutate': [
		createSnippet('convert', 'option', 'convert => {\n\t"${1:key}" => "${2:value}"\n}', '**[convert](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-mutate.html#plugins-filters-mutate-convert) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nConvert a field’s value to a different type, like turning a string to an integer. If the field value is an array, all members will be converted. If the field is a hash no action will be taken.\n\n**_Example:_**  \n``` ruby\n    filter {\n      mutate {\n        convert => {\n          "fieldname" => "integer"\n          "booleanfield" => "boolean"\n        }\n      }\n    }\n```'),
		createSnippet('copy', 'option', 'copy => {\n\t"${1:key}" => "${2:value}"\n}', '**[copy](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-mutate.html#plugins-filters-mutate-copy) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nCopy an existing field to another field. Existing target field will be overriden.\n\n**_Example:_**  \n``` ruby\n    filter {\n      mutate {\n         copy => { "source_field" => "dest_field" }\n      }\n    }\n```'),
		createSnippet('gsub', 'option', 'gsub => ["${1:gsub}"]', '**[gsub](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-mutate.html#plugins-filters-mutate-gsub) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nMatch a regular expression against a field value and replace all matches with a replacement string. Only fields that are strings or arrays of strings are supported. For other kinds of fields no action will be taken.\n\n**_Example:_**  \n``` ruby\n    filter {\n      mutate {\n        gsub => [\n          # replace all forward slashes with underscore\n          "fieldname", "/", "_",\n          # replace backslashes, question marks, hashes, and minuses\n          # with a dot "."\n          "fieldname2", "[\\\\?#-]", "."\n        ]\n      }\n    }\n```'),
		createSnippet('join', 'option', 'join => {\n\t"${1:key}" => "${2:value}"\n}', '**[join](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-mutate.html#plugins-filters-mutate-join) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nJoin an array with a separator character. Does nothing on non-array fields.\n\n**_Example:_**  \n``` ruby\n   filter {\n     mutate {\n       join => { "fieldname" => "," }\n     }\n   }\n```'),
		createSnippet('lowercase', 'option', 'lowercase => ["${1:lowercase}"]', '**[lowercase](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-mutate.html#plugins-filters-mutate-lowercase) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nConvert a string to its lowercase equivalent.\n\n**_Example:_**  \n``` ruby\n    filter {\n      mutate {\n        lowercase => [ "fieldname" ]\n      }\n    }\n```'),
		createSnippet('merge', 'option', 'merge => {\n\t"${1:key}" => "${2:value}"\n}', '**[merge](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-mutate.html#plugins-filters-mutate-merge) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nMerge two fields of arrays or hashes. String fields will be automatically be converted into an array, so:\n\n**_Example:_**  \n``` ruby\n    filter {\n      mutate {\n         merge => { "dest_field" => "added_field" }\n      }\n    }\n```'),
		createSnippet('coerce', 'option', 'coerce => {\n\t"${1:key}" => "${2:value}"\n}', '**[coerce](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-mutate.html#plugins-filters-mutate-coerce) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nSet the default value of a field that exists but is null\n\n**_Example:_**  \n``` ruby\n    filter {\n      mutate {\n        # Sets the default value of the \'field1\' field to \'default_value\'\n        coerce => { "field1" => "default_value" }\n      }\n    }\n```'),
		createSnippet('rename', 'option', 'rename => {\n\t"${1:key}" => "${2:value}"\n}', '**[rename](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-mutate.html#plugins-filters-mutate-rename) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nRename one or more fields.\n\n**_Example:_**  \n``` ruby\n    filter {\n      mutate {\n        # Renames the \'HOSTORIP\' field to \'client_ip\'\n        rename => { "HOSTORIP" => "client_ip" }\n      }\n    }\n```'),
		createSnippet('replace', 'option', 'replace => {\n\t"${1:key}" => "${2:value}"\n}', '**[replace](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-mutate.html#plugins-filters-mutate-replace) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nReplace the value of a field with a new value, or add the field if it doesn’t already exist. The new value can include %{foo} strings to help you build a new value from other parts of the event.\n\n**_Example:_**  \n``` ruby\n    filter {\n      mutate {\n        replace => { "message" => "%{source_host}: My new message" }\n      }\n    }\n```'),
		createSnippet('split', 'option', 'split => {\n\t"${1:key}" => "${2:value}"\n}', '**[split](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-mutate.html#plugins-filters-mutate-split) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nSplit a field to an array using a separator character. Only works on string fields.\n\n**_Example:_**  \n``` ruby\n    filter {\n      mutate {\n         split => { "fieldname" => "," }\n      }\n    }\n```'),
		createSnippet('strip', 'option', 'strip => ["${1:strip}"]', '**[strip](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-mutate.html#plugins-filters-mutate-strip) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nStrip whitespace from field. NOTE: this only works on leading and trailing whitespace.\n\n**_Example:_**  \n``` ruby\n    filter {\n      mutate {\n         strip => ["field1", "field2"]\n      }\n    }\n```'),
		createSnippet('update', 'option', 'update => {\n\t"${1:key}" => "${2:value}"\n}', '**[update](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-mutate.html#plugins-filters-mutate-update) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nUpdate an existing field with a new value. If the field does not exist, then no action will be taken.\n\n**_Example:_**  \n``` ruby\n    filter {\n      mutate {\n        update => { "sample" => "My new message" }\n      }\n    }\n```'),
		createSnippet('uppercase', 'option', 'uppercase => ["${1:uppercase}"]', '**[uppercase](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-mutate.html#plugins-filters-mutate-uppercase) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nConvert a string to its uppercase equivalent.\n\n**_Example:_**  \n``` ruby\n    filter {\n      mutate {\n        uppercase => [ "fieldname" ]\n      }\n    }\n```'),
		createSnippet('capitalize', 'option', 'capitalize => ["${1:capitalize}"]', '**[capitalize](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-mutate.html#plugins-filters-mutate-capitalize) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nConvert a string to its capitalized equivalent.\n\n**_Example:_**  \n``` ruby\n    filter {\n      mutate {\n        capitalize => [ "fieldname" ]\n      }\n    }\n```'),
		createSnippet('tag_on_failure', 'option', 'tag_on_failure => "${1:_mutate_error}"', '**[tag_on_failure](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-mutate.html#plugins-filters-mutate-tag_on_failure) option**\n\n- Value type is string\n- The default value for this setting is _mutate_error\n\nIf a failure occurs during the application of this mutate filter, the rest of the operations are aborted and the provided tag is added to the event.')
	],
	'logstash-output-dynatrace': [
	],
	'logstash-filter-json': [
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-json.html#plugins-filters-json-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: does not use ECS-compatible field names v1: Elastic Common Schema compliant behavior (warns when target isn’t set)\n- disabled: does not use ECS-compatible field names\n- v1: Elastic Common Schema compliant behavior (warns when target isn’t set)\n\nSupported values are:'),
		createSnippet('skip_on_invalid_json', 'option', 'skip_on_invalid_json => ${1|false,true|}', '**[skip_on_invalid_json](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-json.html#plugins-filters-json-skip_on_invalid_json) option**\n\n- Value type is boolean\n- Default value is false\n\nAllows for skipping the filter on invalid JSON (this allows you to handle JSON and non-JSON data without warnings)'),
		createSnippet('source', 'option', 'source => "${1:source}"', '**[source](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-json.html#plugins-filters-json-source) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe configuration for the JSON filter:\n\n**_Example:_**  \n``` ruby\n    source => source_field\n```', true),
		createSnippet('tag_on_failure', 'option', 'tag_on_failure => ["${1:_jsonparsefailure}"]', '**[tag_on_failure](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-json.html#plugins-filters-json-tag_on_failure) option**\n\n- Value type is array\n- Default value is ["_jsonparsefailure"]\n\nAppend values to the tags field when there has been no successful match'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-json.html#plugins-filters-json-target) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nDefine the target field for placing the parsed data. If this setting is omitted, the JSON data will be stored at the root (top level) of the event.\n\n**_Example:_**  \n``` ruby\n    filter {\n      json {\n        target => "doc"\n      }\n    }\n```')
	],
	'logstash-output-datadog': [
		createSnippet('alert_type', 'option', 'alert_type => "${1|info,error,warning,success|}"$0', '**[alert_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-datadog.html#plugins-outputs-datadog-alert_type) option**\n\n- Value can be any of: info, error, warning, success\n- There is no default value for this setting.\n\nAlert type'),
		createSnippet('api_key', 'option', 'api_key => "${1:api_key}"', '**[api_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-datadog.html#plugins-outputs-datadog-api_key) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nYour DatadogHQ API key', true),
		createSnippet('date_happened', 'option', 'date_happened => "${1:date_happened}"', '**[date_happened](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-datadog.html#plugins-outputs-datadog-date_happened) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nDate Happened'),
		createSnippet('dd_tags', 'option', 'dd_tags => ["${1:dd_tag}"]', '**[dd_tags](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-datadog.html#plugins-outputs-datadog-dd_tags) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nTags Set any custom tags for this event Default are the Logstash tags if any'),
		createSnippet('priority', 'option', 'priority => "${1|normal,low|}"$0', '**[priority](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-datadog.html#plugins-outputs-datadog-priority) option**\n\n- Value can be any of: normal, low\n- There is no default value for this setting.\n\nPriority'),
		createSnippet('source_type_name', 'option', 'source_type_name => "${1|my apps,hudson,jenkins,user,nagios,feed,chef,puppet,git,bitbucket,fabric,capistrano|}"$0', '**[source_type_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-datadog.html#plugins-outputs-datadog-source_type_name) option**\n\n- Value can be any of: nagios, hudson, jenkins, user, my apps, feed, chef, puppet, git, bitbucket, fabric, capistrano\n- Default value is "my apps"\n\nSource type name'),
		createSnippet('text', 'option', 'text => "${1:%{message\\}}"', '**[text](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-datadog.html#plugins-outputs-datadog-text) option**\n\n- Value type is string\n- Default value is "%{message}"\n\nText'),
		createSnippet('title', 'option', 'title => "${1:Logstash event for %{host\\}}"', '**[title](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-datadog.html#plugins-outputs-datadog-title) option**\n\n- Value type is string\n- Default value is "Logstash event for %{host}"\n\nTitle')
	],
	'logstash-input-file': [
		createSnippet('check_archive_validity', 'option', 'check_archive_validity => ${1|true,false|}', '**[check_archive_validity](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-check_archive_validity) option**\n\n- Value type is boolean\n- The default is false.\n\nWhen set to true, this setting verifies that a compressed file is valid before processing it. There are two passes through the file—one pass to verify that the file is valid, and another pass to process the file.'),
		createSnippet('close_older', 'option', 'close_older => "${1:1 hour}"', '**[close_older](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-close_older) option**\n\n- Value type is number or string_duration\n- Default value is "1 hour"\n\nThe file input closes any files that were last read the specified duration (seconds if a number is specified) ago. This has different implications depending on if a file is being tailed or read. If tailing, and there is a large time gap in incoming data the file can be closed (allowing other files to be opened) but will be queued for reopening when new data is detected. If reading, the file will be closed after closed_older seconds from when the last bytes were read. This setting is retained for backward compatibility if you upgrade the plugin to 4.1.0+, are reading not tailing and do not switch to using Read mode.'),
		createSnippet('delimiter', 'option', 'delimiter => "${1:\n}"', '**[delimiter](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-delimiter) option**\n\n- Value type is string\n- Default value is "\n"\n\nset the new line delimiter, defaults to "\n". Note that when reading compressed files this setting is not used, instead the standard Windows or Unix line endings are used.'),
		createSnippet('discover_interval', 'option', 'discover_interval => ${1:15}', '**[discover_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-discover_interval) option**\n\n- Value type is number\n- Default value is 15\n\nHow often we expand the filename patterns in the path option to discover new files to watch. This value is a multiple to stat_interval, e.g. if stat_interval is "500 ms" then new files files could be discovered every 15 X 500 milliseconds - 7.5 seconds. In practice, this will be the best case because the time taken to read new content needs to be factored in.'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: sets non-ECS metadata on event (such as top-level host, path) v1,v8: sets ECS-compatible metadata on event (such as [host][name], [log][file][path])\n- disabled: sets non-ECS metadata on event (such as top-level host, path)\n- v1,v8: sets ECS-compatible metadata on event (such as [host][name], [log][file][path])\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:'),
		createSnippet('exclude', 'option', 'exclude => ["${1:exclude}"]', '**[exclude](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-exclude) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nExclusions (matched against the filename, not full path). Filename patterns are valid here, too. For example, if you have\n\n**_Example:_**  \n``` ruby\n    exclude => "*.gz"\n```'),
		createSnippet('exit_after_read', 'option', 'exit_after_read => ${1|false,true|}', '**[exit_after_read](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-exit_after_read) option**\n\n- Value type is boolean\n- Default value is false\n\nThis option can be used in read mode to enforce closing all watchers when file gets read. Can be used in situation when content of the file is static and won’t change during execution. When set to true it also disables active discovery of the files - only files that were in the directories when process was started will be read. It supports sincedb entries. When file was processed once, then modified - next run will only read newly added entries.'),
		createSnippet('file_chunk_count', 'option', 'file_chunk_count => ${1:4611686018427387903}', '**[file_chunk_count](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-file_chunk_count) option**\n\n- Value type is number\n- Default value is 4611686018427387903\n\nWhen combined with the file_chunk_size, this option sets how many chunks (bands or stripes) are read from each file before moving to the next active file. For example, a file_chunk_count of 32 and a file_chunk_size 32KB will process the next 1MB from each active file. As the default is very large, the file is effectively read to EOF before moving to the next active file.'),
		createSnippet('file_chunk_size', 'option', 'file_chunk_size => ${1:32768}', '**[file_chunk_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-file_chunk_size) option**\n\n- Value type is number\n- Default value is 32768 (32KB)\n\nFile content is read off disk in blocks or chunks and lines are extracted from the chunk. See file_chunk_count to see why and when to change this setting from the default.'),
		createSnippet('file_completed_action', 'option', 'file_completed_action => "${1|delete,log,log_and_delete|}"$0', '**[file_completed_action](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-file_completed_action) option**\n\n- Value can be any of: delete, log, log_and_delete\n- The default is delete.\n\nWhen in read mode, what action should be carried out when a file is done with. If delete is specified then the file will be deleted. If log is specified then the full path of the file is logged to the file specified in the file_completed_log_path setting. If log_and_delete is specified then both above actions take place.'),
		createSnippet('file_completed_log_path', 'option', 'file_completed_log_path => "${1:file_completed_log_path}"', '**[file_completed_log_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-file_completed_log_path) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nWhich file should the completely read file paths be appended to. Only specify this path to a file when file_completed_action is log or log_and_delete. IMPORTANT: this file is appended to only - it could become very large. You are responsible for file rotation.'),
		createSnippet('file_sort_by', 'option', 'file_sort_by => "${1|last_modified,path|}"$0', '**[file_sort_by](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-file_sort_by) option**\n\n- Value can be any of: last_modified, path\n- The default is last_modified.\n\nWhich attribute of a "watched" file should be used to sort them by. Files can be sorted by modified date or full path alphabetic. Previously the processing order of the discovered and therefore "watched" files was OS dependent.'),
		createSnippet('file_sort_direction', 'option', 'file_sort_direction => "${1|asc,desc|}"$0', '**[file_sort_direction](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-file_sort_direction) option**\n\n- Value can be any of: asc, desc\n- The default is asc.\n\nSelect between ascending and descending order when sorting "watched" files. If oldest data first is important then the defaults of last_modified + asc are good. If newest data first is more important then opt for last_modified + desc. If you use special naming conventions for the file full paths then perhaps path + asc will help to control the order of file processing.'),
		createSnippet('ignore_older', 'option', 'ignore_older => "${1:1 hour}"', '**[ignore_older](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-ignore_older) option**\n\n- Value type is number or string_duration\n- There is no default value for this setting.\n\nWhen the file input discovers a file that was last modified before the specified duration (seconds if a number is specified), the file is ignored. After it’s discovery, if an ignored file is modified it is no longer ignored and any new data is read. By default, this option is disabled. Note this unit is in seconds.'),
		createSnippet('max_open_files', 'option', 'max_open_files => ${1:123}', '**[max_open_files](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-max_open_files) option**\n\n- Value type is number\n- There is no default value for this setting.\n\nWhat is the maximum number of file_handles that this input consumes at any one time. Use close_older to close some files if you need to process more files than this number. This should not be set to the maximum the OS can do because file handles are needed for other LS plugins and OS processes. A default of 4095 is set in internally.'),
		createSnippet('mode', 'option', 'mode => "${1|tail,read|}"$0', '**[mode](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-mode) option**\n\n- Value can be either tail or read.\n- The default value is tail.\n\nWhat mode do you want the file input to operate in. Tail a few files or read many content-complete files. Read mode now supports gzip file processing.'),
		createSnippet('path', 'option', 'path => ["${1:path}"]', '**[path](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-path) option**\n\n- This is a required setting.\n- Value type is array\n- There is no default value for this setting.\n\nThe path(s) to the file(s) to use as an input. You can use filename patterns here, such as /var/log/*.log. If you use a pattern like /var/log/**/*.log, a recursive search of /var/log will be done for all *.log files. Paths must be absolute and cannot be relative.', true),
		createSnippet('sincedb_clean_after', 'option', 'sincedb_clean_after => "${1:2 weeks}"', '**[sincedb_clean_after](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-sincedb_clean_after) option**\n\n- Value type is number or string_duration\n- The default value for this setting is "2 weeks".\n- If a number is specified then it is interpreted as days and can be decimal e.g. 0.5 is 12 hours.\n\nThe sincedb record now has a last active timestamp associated with it. If no changes are detected in a tracked file in the last N days its sincedb tracking record expires and will not be persisted. This option helps protect against the inode recycling problem. Filebeat has a FAQ about inode recycling.'),
		createSnippet('sincedb_path', 'option', 'sincedb_path => "${1:sincedb_path}"', '**[sincedb_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-sincedb_path) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nPath of the sincedb database file (keeps track of the current position of monitored log files) that will be written to disk. The default will write sincedb files to <path.data>/plugins/inputs/file NOTE: it must be a file path and not a directory path'),
		createSnippet('sincedb_write_interval', 'option', 'sincedb_write_interval => "${1:15 seconds}"', '**[sincedb_write_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-sincedb_write_interval) option**\n\n- Value type is number or string_duration\n- Default value is "15 seconds"\n\nHow often (in seconds) to write a since database with the current position of monitored log files.'),
		createSnippet('start_position', 'option', 'start_position => "${1|end,beginning|}"$0', '**[start_position](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-start_position) option**\n\n- Value can be any of: beginning, end\n- Default value is "end"\n\nChoose where Logstash starts initially reading files: at the beginning or at the end. The default behavior treats files like live streams and thus starts at the end. If you have old data you want to import, set this to beginning.'),
		createSnippet('stat_interval', 'option', 'stat_interval => "${1:1 second}"', '**[stat_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html#plugins-inputs-file-stat_interval) option**\n\n- Value type is number or string_duration\n- Default value is "1 second"\n\nHow often (in seconds) we stat files to see if they have been modified. Increasing this interval will decrease the number of system calls we make, but increase the time to detect new log lines.')
	],
	'logstash-output-google_cloud_storage': [
		createSnippet('bucket', 'option', 'bucket => "${1:bucket}"', '**[bucket](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_cloud_storage.html#plugins-outputs-google_cloud_storage-bucket) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nGCS bucket name, without "gs://" or any other prefix.', true),
		createSnippet('date_pattern', 'option', 'date_pattern => "${1:%Y-%m-%dT%H:00}"', '**[date_pattern](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_cloud_storage.html#plugins-outputs-google_cloud_storage-date_pattern) option**\n\n- Value type is string\n- Default value is "%Y-%m-%dT%H:00"\n\nTime pattern for log file, defaults to hourly files. Must Time.strftime patterns: www.ruby-doc.org/core-2.0/Time.html#method-i-strftime'),
		createSnippet('flush_interval_secs', 'option', 'flush_interval_secs => ${1:2}', '**[flush_interval_secs](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_cloud_storage.html#plugins-outputs-google_cloud_storage-flush_interval_secs) option**\n\n- Value type is number\n- Default value is 2\n\nFlush interval in seconds for flushing writes to log files. 0 will flush on every message.'),
		createSnippet('gzip', 'option', 'gzip => ${1|false,true|}', '**[gzip](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_cloud_storage.html#plugins-outputs-google_cloud_storage-gzip) option**\n\n- Value type is boolean\n- Default value is false\n\nGzip output stream when writing events to log files, set Content-Type to application/gzip instead of text/plain, and use file suffix .log.gz instead of .log.'),
		createSnippet('gzip_content_encoding', 'option', 'gzip_content_encoding => ${1|false,true|}', '**[gzip_content_encoding](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_cloud_storage.html#plugins-outputs-google_cloud_storage-gzip_content_encoding) option**\n\n- Value type is boolean\n- Default value is false\n\nAdded in 3.3.0.'),
		createSnippet('include_hostname', 'option', 'include_hostname => ${1|true,false|}', '**[include_hostname](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_cloud_storage.html#plugins-outputs-google_cloud_storage-include_hostname) option**\n\n- Value type is boolean\n- Default value is true\n\nAdded in 3.1.0.'),
		createSnippet('include_uuid', 'option', 'include_uuid => ${1|false,true|}', '**[include_uuid](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_cloud_storage.html#plugins-outputs-google_cloud_storage-include_uuid) option**\n\n- Value type is boolean\n- Default value is false\n\nAdded in 3.1.0.'),
		createSnippet('json_key_file', 'option', 'json_key_file => "${1:json_key_file}"', '**[json_key_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_cloud_storage.html#plugins-outputs-google_cloud_storage-json_key_file) option**\n\n- Value type is string\n- Default value is nil\n\nThe plugin can use Application Default Credentials (ADC), if it’s running on Compute Engine, Kubernetes Engine, App Engine, or Cloud Functions.'),
		createSnippet('key_password', 'option', 'key_password => "${1:notasecret}"', '**[key_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_cloud_storage.html#plugins-outputs-google_cloud_storage-key_password) option**\n\n- Value type is string\n- Default value is "notasecret"\n\nDeprecated this feature is no longer used, the setting is now a part of json_key_file.'),
		createSnippet('key_path', 'option', 'key_path => "${1:key_path}"', '**[key_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_cloud_storage.html#plugins-outputs-google_cloud_storage-key_path) option**\n\n- Value type is string\n\nObsolete: The PKCS12 key file format is no longer supported. Please use one of the following mechanisms:'),
		createSnippet('log_file_prefix', 'option', 'log_file_prefix => "${1:logstash_gcs}"', '**[log_file_prefix](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_cloud_storage.html#plugins-outputs-google_cloud_storage-log_file_prefix) option**\n\n- Value type is string\n- Default value is "logstash_gcs"\n\nLog file prefix. Log file will follow the format: <prefix>_hostname_date<.part?>.log'),
		createSnippet('max_concurrent_uploads', 'option', 'max_concurrent_uploads => ${1:5}', '**[max_concurrent_uploads](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_cloud_storage.html#plugins-outputs-google_cloud_storage-max_concurrent_uploads) option**\n\n- Value type is number\n- Default value is 5\n\nSets the maximum number of concurrent uploads to Cloud Storage at a time. Uploads are I/O bound so it makes sense to tune this paramater with regards to the network bandwidth available and the latency between your server and Cloud Storage.'),
		createSnippet('max_file_size_kbytes', 'option', 'max_file_size_kbytes => ${1:10000}', '**[max_file_size_kbytes](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_cloud_storage.html#plugins-outputs-google_cloud_storage-max_file_size_kbytes) option**\n\n- Value type is number\n- Default value is 10000\n\nSets max file size in kbytes. 0 disable max file check.'),
		createSnippet('output_format', 'option', 'output_format => "${1|json,plain,null|}"$0', '**[output_format](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_cloud_storage.html#plugins-outputs-google_cloud_storage-output_format) option**\n\n- Value can be any of: json, plain, or no value\n- Default value is no value\n\nDeprecated, this feature will be removed in the next major release. Use codecs instead.'),
		createSnippet('service_account', 'option', 'service_account => "${1:service_account}"', '**[service_account](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_cloud_storage.html#plugins-outputs-google_cloud_storage-service_account) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nDeprecated this feature is no longer used, the setting is now a part of json_key_file.'),
		createSnippet('temp_directory', 'option', 'temp_directory => "${1:temp_directory}"', '**[temp_directory](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_cloud_storage.html#plugins-outputs-google_cloud_storage-temp_directory) option**\n\n- Value type is string\n- Default value is ""\n\nDirectory where temporary files are stored. Defaults to /tmp/logstash-gcs-<random-suffix>'),
		createSnippet('uploader_interval_secs', 'option', 'uploader_interval_secs => ${1:60}', '**[uploader_interval_secs](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_cloud_storage.html#plugins-outputs-google_cloud_storage-uploader_interval_secs) option**\n\n- Value type is number\n- Default value is 60\n\nUploader interval when uploading new files to GCS. Adjust time based on your time pattern (for example, for hourly files, this interval can be around one hour).')
	],
	'logstash-filter-truncate': [
		createSnippet('fields', 'option', 'fields => "${1:fields}"', '**[fields](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-truncate.html#plugins-filters-truncate-fields) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nA list of fieldrefs to truncate if they are too long.'),
		createSnippet('length_bytes', 'option', 'length_bytes => ${1:123}', '**[length_bytes](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-truncate.html#plugins-filters-truncate-length_bytes) option**\n\n- This is a required setting.\n- Value type is number\n- There is no default value for this setting.\n\nFields over this length will be truncated to this length.', true)
	],
	'logstash-filter-drop': [
		createSnippet('percentage', 'option', 'percentage => ${1:100}', '**[percentage](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-drop.html#plugins-filters-drop-percentage) option**\n\n- Value type is number\n- Default value is 100\n\nDrop all the events within a pre-configured percentage.')
	],
	'logstash-output-syslog': [
		createSnippet('appname', 'option', 'appname => "${1:LOGSTASH}"', '**[appname](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-syslog.html#plugins-outputs-syslog-appname) option**\n\n- Value type is string\n- Default value is "LOGSTASH"\n\napplication name for syslog message. The new value can include %{foo} strings to help you build a new value from other parts of the event.'),
		createSnippet('facility', 'option', 'facility => "${1:user-level}"', '**[facility](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-syslog.html#plugins-outputs-syslog-facility) option**\n\n- Value type is string\n- Default value is "user-level"\n\nfacility label for syslog message default fallback to user-level as in rfc3164 The new value can include %{foo} strings to help you build a new value from other parts of the event.'),
		createSnippet('host', 'option', 'host => "${1:host}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-syslog.html#plugins-outputs-syslog-host) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nsyslog server address to connect to', true),
		createSnippet('message', 'option', 'message => "${1:%{message\\}}"', '**[message](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-syslog.html#plugins-outputs-syslog-message) option**\n\n- Value type is string\n- Default value is "%{message}"\n\nmessage text to log. The new value can include %{foo} strings to help you build a new value from other parts of the event.'),
		createSnippet('msgid', 'option', 'msgid => "${1:-}"', '**[msgid](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-syslog.html#plugins-outputs-syslog-msgid) option**\n\n- Value type is string\n- Default value is "-"\n\nmessage id for syslog message. The new value can include %{foo} strings to help you build a new value from other parts of the event.'),
		createSnippet('port', 'option', 'port => ${1:123}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-syslog.html#plugins-outputs-syslog-port) option**\n\n- This is a required setting.\n- Value type is number\n- There is no default value for this setting.\n\nsyslog server port to connect to', true),
		createSnippet('priority', 'option', 'priority => "${1:%{syslog_pri\\}}"', '**[priority](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-syslog.html#plugins-outputs-syslog-priority) option**\n\n- Value type is string\n- Default value is "%{syslog_pri}"\n\nsyslog priority The new value can include %{foo} strings to help you build a new value from other parts of the event.'),
		createSnippet('procid', 'option', 'procid => "${1:-}"', '**[procid](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-syslog.html#plugins-outputs-syslog-procid) option**\n\n- Value type is string\n- Default value is "-"\n\nprocess id for syslog message. The new value can include %{foo} strings to help you build a new value from other parts of the event.'),
		createSnippet('protocol', 'option', 'protocol => "${1|udp,tcp,ssl-tcp|}"$0', '**[protocol](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-syslog.html#plugins-outputs-syslog-protocol) option**\n\n- Value can be any of: tcp, udp, ssl-tcp\n- Default value is "udp"\n\nsyslog server protocol. you can choose between udp, tcp and ssl/tls over tcp'),
		createSnippet('reconnect_interval', 'option', 'reconnect_interval => ${1:1}', '**[reconnect_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-syslog.html#plugins-outputs-syslog-reconnect_interval) option**\n\n- Value type is number\n- Default value is 1\n\nwhen connection fails, retry interval in sec.'),
		createSnippet('rfc', 'option', 'rfc => "${1|rfc3164,rfc5424|}"$0', '**[rfc](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-syslog.html#plugins-outputs-syslog-rfc) option**\n\n- Value can be any of: rfc3164, rfc5424\n- Default value is "rfc3164"\n\nsyslog message format: you can choose between rfc3164 or rfc5424'),
		createSnippet('severity', 'option', 'severity => "${1:notice}"', '**[severity](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-syslog.html#plugins-outputs-syslog-severity) option**\n\n- Value type is string\n- Default value is "notice"\n\nseverity label for syslog message default fallback to notice as in rfc3164 The new value can include %{foo} strings to help you build a new value from other parts of the event.'),
		createSnippet('sourcehost', 'option', 'sourcehost => "${1:%{host\\}}"', '**[sourcehost](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-syslog.html#plugins-outputs-syslog-sourcehost) option**\n\n- Value type is string\n- Default value is "%{host}"\n\nsource host for syslog message. The new value can include %{foo} strings to help you build a new value from other parts of the event.'),
		createSnippet('ssl_cacert', 'option', 'ssl_cacert => "${1:/path/to/file}"', '**[ssl_cacert](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-syslog.html#plugins-outputs-syslog-ssl_cacert) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nThe SSL CA certificate, chainfile or CA path. The system CA path is automatically included.'),
		createSnippet('ssl_cert', 'option', 'ssl_cert => "${1:/path/to/file}"', '**[ssl_cert](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-syslog.html#plugins-outputs-syslog-ssl_cert) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nSSL certificate path'),
		createSnippet('ssl_key', 'option', 'ssl_key => "${1:/path/to/file}"', '**[ssl_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-syslog.html#plugins-outputs-syslog-ssl_key) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nSSL key path'),
		createSnippet('ssl_key_passphrase', 'option', 'ssl_key_passphrase => "${1:ssl_key_passphrase}"', '**[ssl_key_passphrase](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-syslog.html#plugins-outputs-syslog-ssl_key_passphrase) option**\n\n- Value type is password\n- Default value is nil\n\nSSL key passphrase'),
		createSnippet('ssl_verify', 'option', 'ssl_verify => ${1|false,true|}', '**[ssl_verify](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-syslog.html#plugins-outputs-syslog-ssl_verify) option**\n\n- Value type is boolean\n- Default value is false\n\nVerify the identity of the other end of the SSL connection against the CA.'),
		createSnippet('use_labels', 'option', 'use_labels => ${1|true,false|}', '**[use_labels](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-syslog.html#plugins-outputs-syslog-use_labels) option**\n\n- Value type is boolean\n- Default value is true\n\nuse label parsing for severity and facility levels use priority field if set to false')
	],
	'logstash-codec-plain': [
		createSnippet('charset', 'option', 'charset => "${1|UTF-8,ASCII-8BIT,US-ASCII,Big5,Big5-HKSCS,Big5-UAO,CP949,Emacs-Mule,EUC-JP,EUC-KR,EUC-TW,GB2312,GB18030,GBK,ISO-8859-1,ISO-8859-2,ISO-8859-3,ISO-8859-4,ISO-8859-5,ISO-8859-6,ISO-8859-7,ISO-8859-8,ISO-8859-9,ISO-8859-10,ISO-8859-11,ISO-8859-13,ISO-8859-14,ISO-8859-15,ISO-8859-16,KOI8-R,KOI8-U,Shift_JIS,UTF-16BE,UTF-16LE,UTF-32BE,UTF-32LE,Windows-31J,Windows-1250,Windows-1251,Windows-1252,IBM437,IBM737,IBM775,CP850,IBM852,CP852,IBM855,CP855,IBM857,IBM860,IBM861,IBM862,IBM863,IBM864,IBM865,IBM866,IBM869,Windows-1258,GB1988,macCentEuro,macCroatian,macCyrillic,macGreek,macIceland,macRoman,macRomania,macThai,macTurkish,macUkraine,CP950,CP951,IBM037,stateless-ISO-2022-JP,eucJP-ms,CP51932,EUC-JIS-2004,GB12345,ISO-2022-JP,ISO-2022-JP-2,CP50220,CP50221,Windows-1256,Windows-1253,Windows-1255,Windows-1254,TIS-620,Windows-874,Windows-1257,MacJapanese,UTF-7,UTF8-MAC,UTF-16,UTF-32,UTF8-DoCoMo,SJIS-DoCoMo,UTF8-KDDI,SJIS-KDDI,ISO-2022-JP-KDDI,stateless-ISO-2022-JP-KDDI,UTF8-SoftBank,SJIS-SoftBank,BINARY,CP437,CP737,CP775,IBM850,CP857,CP860,CP861,CP862,CP863,CP864,CP865,CP866,CP869,CP1258,Big5-HKSCS:2008,ebcdic-cp-us,eucJP,euc-jp-ms,EUC-JISX0213,eucKR,eucTW,EUC-CN,eucCN,CP936,ISO2022-JP,ISO2022-JP2,ISO8859-1,ISO8859-2,ISO8859-3,ISO8859-4,ISO8859-5,ISO8859-6,CP1256,ISO8859-7,CP1253,ISO8859-8,CP1255,ISO8859-9,CP1254,ISO8859-10,ISO8859-11,CP874,ISO8859-13,CP1257,ISO8859-14,ISO8859-15,ISO8859-16,CP878,MacJapan,ASCII,ANSI_X3.4-1968,646,CP65000,CP65001,UTF-8-MAC,UTF-8-HFS,UCS-2BE,UCS-4BE,UCS-4LE,CP932,csWindows31J,SJIS,PCK,CP1250,CP1251,CP1252,external,locale|}"$0', '**[charset](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-plain.html#plugins-codecs-plain-charset) option**\n\n- Value can be any of: ASCII-8BIT, UTF-8, US-ASCII, Big5, Big5-HKSCS, Big5-UAO, CP949, Emacs-Mule, EUC-JP, EUC-KR, EUC-TW, GB2312, GB18030, GBK, ISO-8859-1, ISO-8859-2, ISO-8859-3, ISO-8859-4, ISO-8859-5, ISO-8859-6, ISO-8859-7, ISO-8859-8, ISO-8859-9, ISO-8859-10, ISO-8859-11, ISO-8859-13, ISO-8859-14, ISO-8859-15, ISO-8859-16, KOI8-R, KOI8-U, Shift_JIS, UTF-16BE, UTF-16LE, UTF-32BE, UTF-32LE, Windows-31J, Windows-1250, Windows-1251, Windows-1252, IBM437, IBM737, IBM775, CP850, IBM852, CP852, IBM855, CP855, IBM857, IBM860, IBM861, IBM862, IBM863, IBM864, IBM865, IBM866, IBM869, Windows-1258, GB1988, macCentEuro, macCroatian, macCyrillic, macGreek, macIceland, macRoman, macRomania, macThai, macTurkish, macUkraine, CP950, CP951, IBM037, stateless-ISO-2022-JP, eucJP-ms, CP51932, EUC-JIS-2004, GB12345, ISO-2022-JP, ISO-2022-JP-2, CP50220, CP50221, Windows-1256, Windows-1253, Windows-1255, Windows-1254, TIS-620, Windows-874, Windows-1257, MacJapanese, UTF-7, UTF8-MAC, UTF-16, UTF-32, UTF8-DoCoMo, SJIS-DoCoMo, UTF8-KDDI, SJIS-KDDI, ISO-2022-JP-KDDI, stateless-ISO-2022-JP-KDDI, UTF8-SoftBank, SJIS-SoftBank, BINARY, CP437, CP737, CP775, IBM850, CP857, CP860, CP861, CP862, CP863, CP864, CP865, CP866, CP869, CP1258, Big5-HKSCS:2008, ebcdic-cp-us, eucJP, euc-jp-ms, EUC-JISX0213, eucKR, eucTW, EUC-CN, eucCN, CP936, ISO2022-JP, ISO2022-JP2, ISO8859-1, ISO8859-2, ISO8859-3, ISO8859-4, ISO8859-5, ISO8859-6, CP1256, ISO8859-7, CP1253, ISO8859-8, CP1255, ISO8859-9, CP1254, ISO8859-10, ISO8859-11, CP874, ISO8859-13, CP1257, ISO8859-14, ISO8859-15, ISO8859-16, CP878, MacJapan, ASCII, ANSI_X3.4-1968, 646, CP65000, CP65001, UTF-8-MAC, UTF-8-HFS, UCS-2BE, UCS-4BE, UCS-4LE, CP932, csWindows31J, SJIS, PCK, CP1250, CP1251, CP1252, external, locale\n- Default value is "UTF-8"\n\nThe character encoding used in this input. Examples include UTF-8 and cp1252'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-plain.html#plugins-codecs-plain-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: plugin only sets the message field v1,v8: Elastic Common Schema compliant behavior ([event][original] is also added)\n- disabled: plugin only sets the message field\n- v1,v8: Elastic Common Schema compliant behavior ([event][original] is also added)\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled\n\nSupported values are:'),
		createSnippet('format', 'option', 'format => "${1:format}"', '**[format](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-plain.html#plugins-codecs-plain-format) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nSet the message you which to emit for each event. This supports sprintf strings.')
	],
	'logstash-input-syslog': [
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-syslog.html#plugins-inputs-syslog-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: does not use ECS-compatible field names (for example, priority for syslog priority) v1,v8: uses fields that are compatible with Elastic Common Schema (for example, [log][syslog][priority])\n- disabled: does not use ECS-compatible field names (for example, priority for syslog priority)\n- v1,v8: uses fields that are compatible with Elastic Common Schema (for example, [log][syslog][priority])\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:'),
		createSnippet('facility_labels', 'option', 'facility_labels => ["${1:kernel}", "user-level", "mail", "system", "security/authorization", "syslogd", "line printer", "network news", "UUCP", "clock", "security/authorization", "FTP", "NTP", "log audit", "log alert", "clock", "local0", "local1", "local2", "local3", "local4", "local5", "local6", "local7"]', '**[facility_labels](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-syslog.html#plugins-inputs-syslog-facility_labels) option**\n\n- Value type is array\n- Default value is ["kernel", "user-level", "mail", "system", "security/authorization", "syslogd", "line printer", "network news", "UUCP", "clock", "security/authorization", "FTP", "NTP", "log audit", "log alert", "clock", "local0", "local1", "local2", "local3", "local4", "local5", "local6", "local7"]\n\nLabels for facility levels defined in RFC3164.'),
		createSnippet('grok_pattern', 'option', 'grok_pattern => "${1:<%{POSINT:priority\\}>%{SYSLOGLINE\\}}"', '**[grok_pattern](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-syslog.html#plugins-inputs-syslog-grok_pattern) option**\n\n- Value type is string\n- Default value is "<%{POSINT:priority}>%{SYSLOGLINE}"\n- Default value depends on whether ecs_compatibility is enabled: ECS Compatibility disabled: "<%{POSINT:priority}>%{SYSLOGLINE}" ECS Compatibility enabled: "<%{POSINT:[log][syslog][priority]:int}>%{SYSLOGLINE}"\n- ECS Compatibility disabled: "<%{POSINT:priority}>%{SYSLOGLINE}"\n- ECS Compatibility enabled: "<%{POSINT:[log][syslog][priority]:int}>%{SYSLOGLINE}"\n\nDefault value depends on whether ecs_compatibility is enabled:'),
		createSnippet('host', 'option', 'host => "${1:0.0.0.0}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-syslog.html#plugins-inputs-syslog-host) option**\n\n- Value type is string\n- Default value is "0.0.0.0"\n\nThe address to listen on.'),
		createSnippet('locale', 'option', 'locale => "${1:locale}"', '**[locale](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-syslog.html#plugins-inputs-syslog-locale) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nSpecify a locale to be used for date parsing using either IETF-BCP47 or POSIX language tag. Simple examples are en,en-US for BCP47 or en_US for POSIX. If not specified, the platform default will be used.'),
		createSnippet('port', 'option', 'port => ${1:514}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-syslog.html#plugins-inputs-syslog-port) option**\n\n- Value type is number\n- Default value is 514\n\nThe port to listen on. Remember that ports less than 1024 (privileged ports) may require root to use.'),
		createSnippet('proxy_protocol', 'option', 'proxy_protocol => ${1|false,true|}', '**[proxy_protocol](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-syslog.html#plugins-inputs-syslog-proxy_protocol) option**\n\n- Value type is boolean\n- Default value is false\n\nProxy protocol support, only v1 is supported at this time http://www.haproxy.org/download/1.5/doc/proxy-protocol.txt'),
		createSnippet('severity_labels', 'option', 'severity_labels => ["${1:Emergency}", "Alert", "Critical", "Error", "Warning", "Notice", "Informational", "Debug"]', '**[severity_labels](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-syslog.html#plugins-inputs-syslog-severity_labels) option**\n\n- Value type is array\n- Default value is ["Emergency", "Alert", "Critical", "Error", "Warning", "Notice", "Informational", "Debug"]\n\nLabels for severity levels defined in RFC3164.'),
		createSnippet('syslog_field', 'option', 'syslog_field => "${1:message}"', '**[syslog_field](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-syslog.html#plugins-inputs-syslog-syslog_field) option**\n\n- Value type is string\n- Default value is "message"\n\nCodecs process the data before the rest of the data is parsed. Some codecs, like CEF, put the syslog data into another field after pre-processing the data. Use this option in conjunction with the grok_pattern configuration to allow the syslog input plugin to fully parse the syslog data in this case.\n\n**_Example:_**  \n``` ruby\ninput {\n  syslog {\n    port => 12345\n    codec => cef\n    syslog_field => "syslog"\n    grok_pattern => "<%{POSINT:priority}>%{SYSLOGTIMESTAMP:timestamp} CUSTOM GROK HERE"\n  }\n}\n```'),
		createSnippet('timezone', 'option', 'timezone => "${1:timezone}"', '**[timezone](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-syslog.html#plugins-inputs-syslog-timezone) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nSpecify a time zone canonical ID to be used for date parsing. The valid IDs are listed on the [Joda.org available time zones page](http://joda-time.sourceforge.net/timezones.html). This is useful in case the time zone cannot be extracted from the value, and is not the platform default. If this is not specified the platform default will be used. Canonical ID is good as it takes care of daylight saving time for you. For example, America/Los_Angeles or Europe/Paris are valid IDs.'),
		createSnippet('use_labels', 'option', 'use_labels => ${1|true,false|}', '**[use_labels](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-syslog.html#plugins-inputs-syslog-use_labels) option**\n\n- Value type is boolean\n- Default value is true\n\nUse label parsing for severity and facility levels.')
	],
	'logstash-input-java_stdin': [
	],
	'logstash-filter-csv': [
		createSnippet('autodetect_column_names', 'option', 'autodetect_column_names => ${1|false,true|}', '**[autodetect_column_names](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-csv.html#plugins-filters-csv-autodetect_column_names) option**\n\n- Value type is boolean\n- Default value is false\n\nDefine whether column names should be auto-detected from the header column or not. Defaults to false.'),
		createSnippet('autogenerate_column_names', 'option', 'autogenerate_column_names => ${1|true,false|}', '**[autogenerate_column_names](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-csv.html#plugins-filters-csv-autogenerate_column_names) option**\n\n- Value type is boolean\n- Default value is true\n\nDefine whether column names should autogenerated or not. Defaults to true. If set to false, columns not having a header specified will not be parsed.'),
		createSnippet('columns', 'option', 'columns => ["${1:column}"]', '**[columns](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-csv.html#plugins-filters-csv-columns) option**\n\n- Value type is array\n- Default value is []\n\nDefine a list of column names (in the order they appear in the CSV, as if it were a header line). If columns is not configured, or there are not enough columns specified, the default column names are "column1", "column2", etc. In the case that there are more columns in the data than specified in this column list, extra columns will be auto-numbered: (e.g. "user_defined_1", "user_defined_2", "column3", "column4", etc.)'),
		createSnippet('convert', 'option', 'convert => {\n\t"${1:key}" => "${2:value}"\n}', '**[convert](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-csv.html#plugins-filters-csv-convert) option**\n\n- Value type is hash\n- Default value is {}\n\nDefine a set of datatype conversions to be applied to columns. Possible conversions are integer, float, date, date_time, boolean\n\n**_Example:_**  \n``` ruby\n    filter {\n      csv {\n        convert => {\n          "column1" => "integer"\n          "column2" => "boolean"\n        }\n      }\n    }\n```'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-csv.html#plugins-filters-csv-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: does not use ECS-compatible field names v1: uses the value in target as field name\n- disabled: does not use ECS-compatible field names\n- v1: uses the value in target as field name\n\nSupported values are:'),
		createSnippet('quote_char', 'option', 'quote_char => "${1:\\"}"', '**[quote_char](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-csv.html#plugins-filters-csv-quote_char) option**\n\n- Value type is string\n- Default value is "\\\\""\n\nDefine the character used to quote CSV fields. If this is not specified the default is a double quote ". Optional.'),
		createSnippet('separator', 'option', 'separator => "${1:,}"', '**[separator](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-csv.html#plugins-filters-csv-separator) option**\n\n- Value type is string\n- Default value is ","\n\nDefine the column separator value. If this is not specified, the default is a comma ,. If you want to define a tabulation as a separator, you need to set the value to the actual tab character and not \\\\t. Optional.'),
		createSnippet('skip_empty_columns', 'option', 'skip_empty_columns => ${1|false,true|}', '**[skip_empty_columns](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-csv.html#plugins-filters-csv-skip_empty_columns) option**\n\n- Value type is boolean\n- Default value is false\n\nDefine whether empty columns should be skipped. Defaults to false. If set to true, columns containing no value will not get set.'),
		createSnippet('skip_empty_rows', 'option', 'skip_empty_rows => ${1|false,true|}', '**[skip_empty_rows](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-csv.html#plugins-filters-csv-skip_empty_rows) option**\n\n- Value type is boolean\n- Default value is false\n\nDefine whether empty rows could potentially be skipped. Defaults to false. If set to true, rows containing no value will be tagged with "_csvskippedemptyfield". This tag can referenced by users if they wish to cancel events using an if conditional statement.'),
		createSnippet('skip_header', 'option', 'skip_header => ${1|false,true|}', '**[skip_header](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-csv.html#plugins-filters-csv-skip_header) option**\n\n- Value type is boolean\n- Default value is false\n\nDefine whether the header should be skipped. Defaults to false. If set to true, the header will be skipped. Assumes that header is not repeated within further rows as such rows will also be skipped. If skip_header is set without autodetect_column_names being set then columns should be set which will result in the skipping of any row that exactly matches the specified column values. If skip_header and autodetect_column_names are specified then columns should not be specified, in this case autodetect_column_names will fill the columns setting in the background, from the first event seen, and any subsequent values that match what was autodetected will be skipped.'),
		createSnippet('source', 'option', 'source => "${1:message}"', '**[source](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-csv.html#plugins-filters-csv-source) option**\n\n- Value type is string\n- Default value is "message"\n\nThe CSV data in the value of the source field will be expanded into a data structure.'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-csv.html#plugins-filters-csv-target) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nDefine target field for placing the data. Defaults to writing to the root of the event.')
	],
	'logstash-input-udp': [
		createSnippet('buffer_size', 'option', 'buffer_size => ${1:65536}', '**[buffer_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-udp.html#plugins-inputs-udp-buffer_size) option**\n\n- Value type is number\n- Default value is 65536\n\nThe maximum packet size to read from the network'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-udp.html#plugins-inputs-udp-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: unstructured connection metadata added at root level v1: structured connection metadata added under ECS compliant namespaces\n- disabled: unstructured connection metadata added at root level\n- v1: structured connection metadata added under ECS compliant namespaces\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:'),
		createSnippet('host', 'option', 'host => "${1:0.0.0.0}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-udp.html#plugins-inputs-udp-host) option**\n\n- Value type is string\n- Default value is "0.0.0.0"\n\nThe address which logstash will listen on.'),
		createSnippet('port', 'option', 'port => ${1:123}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-udp.html#plugins-inputs-udp-port) option**\n\n- This is a required setting.\n- Value type is number\n- There is no default value for this setting.\n\nThe port which logstash will listen on. Remember that ports less than 1024 (privileged ports) may require root or elevated privileges to use.', true),
		createSnippet('queue_size', 'option', 'queue_size => ${1:2000}', '**[queue_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-udp.html#plugins-inputs-udp-queue_size) option**\n\n- Value type is number\n- Default value is 2000\n\nThis is the number of unprocessed UDP packets you can hold in memory before packets will start dropping.'),
		createSnippet('receive_buffer_bytes', 'option', 'receive_buffer_bytes => ${1:123}', '**[receive_buffer_bytes](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-udp.html#plugins-inputs-udp-receive_buffer_bytes) option**\n\n- Value type is number\n- There is no default value for this setting.\n\nThe socket receive buffer size in bytes. If option is not set, the operating system default is used. The operating system will use the max allowed value if receive_buffer_bytes is larger than allowed. Consult your operating system documentation if you need to increase this max allowed value.'),
		createSnippet('source_ip_fieldname', 'option', 'source_ip_fieldname => "${1:source_ip_fieldname}"', '**[source_ip_fieldname](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-udp.html#plugins-inputs-udp-source_ip_fieldname) option**\n\n- Value type is string\n- Default value could be "host" or [host][ip] depending on the value of ecs_compatibility\n\nThe name of the field where the source IP address will be stored. See Event Metadata and the Elastic Common Schema (ECS) for more information on how ECS compatibility settings affect these defaults.\n\n**_Example:_**  \n``` ruby\n    input {\n      udp {\n        source_ip_fieldname => "[appliance][monitoring][ip]"\n      }\n    }\n```'),
		createSnippet('workers', 'option', 'workers => ${1:2}', '**[workers](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-udp.html#plugins-inputs-udp-workers) option**\n\n- Value type is number\n- Default value is 2\n\nNumber of threads processing packets')
	],
	'logstash-input-lumberjack': [
		createSnippet('congestion_threshold', 'option', 'congestion_threshold => ${1:5}', '**[congestion_threshold](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-lumberjack.html#plugins-inputs-lumberjack-congestion_threshold) option**\n\n- Value type is number\n- Default value is 5\n\nThe number of seconds before we raise a timeout, this option is useful to control how much time to wait if something is blocking the pipeline.'),
		createSnippet('host', 'option', 'host => "${1:0.0.0.0}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-lumberjack.html#plugins-inputs-lumberjack-host) option**\n\n- Value type is string\n- Default value is "0.0.0.0"\n\nThe IP address to listen on.'),
		createSnippet('port', 'option', 'port => ${1:123}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-lumberjack.html#plugins-inputs-lumberjack-port) option**\n\n- This is a required setting.\n- Value type is number\n- There is no default value for this setting.\n\nThe port to listen on.', true),
		createSnippet('ssl_certificate', 'option', 'ssl_certificate => "${1:/path/to/file}"', '**[ssl_certificate](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-lumberjack.html#plugins-inputs-lumberjack-ssl_certificate) option**\n\n- This is a required setting.\n- Value type is path\n- There is no default value for this setting.\n\nSSL certificate to use.', true),
		createSnippet('ssl_key', 'option', 'ssl_key => "${1:/path/to/file}"', '**[ssl_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-lumberjack.html#plugins-inputs-lumberjack-ssl_key) option**\n\n- This is a required setting.\n- Value type is path\n- There is no default value for this setting.\n\nSSL key to use.', true),
		createSnippet('ssl_key_passphrase', 'option', 'ssl_key_passphrase => "${1:ssl_key_passphrase}"', '**[ssl_key_passphrase](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-lumberjack.html#plugins-inputs-lumberjack-ssl_key_passphrase) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nSSL key passphrase to use.')
	],
	'logstash-output-riemann': [
		createSnippet('debug', 'option', 'debug => ${1|false,true|}', '**[debug](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-riemann.html#plugins-outputs-riemann-debug) option**\n\n- Value type is boolean\n- Default value is false\n\nEnable debugging output?'),
		createSnippet('host', 'option', 'host => "${1:localhost}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-riemann.html#plugins-outputs-riemann-host) option**\n\n- Value type is string\n- Default value is "localhost"\n\nThe address of the Riemann server.'),
		createSnippet('map_fields', 'option', 'map_fields => ${1|false,true|}', '**[map_fields](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-riemann.html#plugins-outputs-riemann-map_fields) option**\n\n- Value type is boolean\n- Default value is false\n\nIf set to true automatically map all logstash defined fields to riemann event fields. All nested logstash fields will be mapped to riemann fields containing all parent keys separated by dots and the deepest value.'),
		createSnippet('port', 'option', 'port => ${1:5555}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-riemann.html#plugins-outputs-riemann-port) option**\n\n- Value type is number\n- Default value is 5555\n\nThe port to connect to on your Riemann server.'),
		createSnippet('protocol', 'option', 'protocol => "${1|tcp,udp|}"$0', '**[protocol](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-riemann.html#plugins-outputs-riemann-protocol) option**\n\n- Value can be any of: tcp, udp\n- Default value is "tcp"\n\nThe protocol to use UDP is non-blocking TCP is blocking'),
		createSnippet('riemann_event', 'option', 'riemann_event => {\n\t"${1:key}" => "${2:value}"\n}', '**[riemann_event](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-riemann.html#plugins-outputs-riemann-riemann_event) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nA Hash to set Riemann event fields (http://riemann.io/concepts.html).\n\n**_Example:_**  \n``` ruby\n    riemann {\n        riemann_event => {\n            "metric"  => "%{metric}"\n            "service" => "%{service}"\n        }\n    }\n```'),
		createSnippet('sender', 'option', 'sender => "${1:%{host\\}}"', '**[sender](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-riemann.html#plugins-outputs-riemann-sender) option**\n\n- Value type is string\n- Default value is "%{host}"\n\nThe name of the sender. This sets the host value in the Riemann event')
	],
	'logstash-codec-line': [
		createSnippet('charset', 'option', 'charset => "${1|UTF-8,ASCII-8BIT,US-ASCII,Big5,Big5-HKSCS,Big5-UAO,CP949,Emacs-Mule,EUC-JP,EUC-KR,EUC-TW,GB2312,GB18030,GBK,ISO-8859-1,ISO-8859-2,ISO-8859-3,ISO-8859-4,ISO-8859-5,ISO-8859-6,ISO-8859-7,ISO-8859-8,ISO-8859-9,ISO-8859-10,ISO-8859-11,ISO-8859-13,ISO-8859-14,ISO-8859-15,ISO-8859-16,KOI8-R,KOI8-U,Shift_JIS,UTF-16BE,UTF-16LE,UTF-32BE,UTF-32LE,Windows-31J,Windows-1250,Windows-1251,Windows-1252,IBM437,IBM737,IBM775,CP850,IBM852,CP852,IBM855,CP855,IBM857,IBM860,IBM861,IBM862,IBM863,IBM864,IBM865,IBM866,IBM869,Windows-1258,GB1988,macCentEuro,macCroatian,macCyrillic,macGreek,macIceland,macRoman,macRomania,macThai,macTurkish,macUkraine,CP950,CP951,IBM037,stateless-ISO-2022-JP,eucJP-ms,CP51932,EUC-JIS-2004,GB12345,ISO-2022-JP,ISO-2022-JP-2,CP50220,CP50221,Windows-1256,Windows-1253,Windows-1255,Windows-1254,TIS-620,Windows-874,Windows-1257,MacJapanese,UTF-7,UTF8-MAC,UTF-16,UTF-32,UTF8-DoCoMo,SJIS-DoCoMo,UTF8-KDDI,SJIS-KDDI,ISO-2022-JP-KDDI,stateless-ISO-2022-JP-KDDI,UTF8-SoftBank,SJIS-SoftBank,BINARY,CP437,CP737,CP775,IBM850,CP857,CP860,CP861,CP862,CP863,CP864,CP865,CP866,CP869,CP1258,Big5-HKSCS:2008,ebcdic-cp-us,eucJP,euc-jp-ms,EUC-JISX0213,eucKR,eucTW,EUC-CN,eucCN,CP936,ISO2022-JP,ISO2022-JP2,ISO8859-1,ISO8859-2,ISO8859-3,ISO8859-4,ISO8859-5,ISO8859-6,CP1256,ISO8859-7,CP1253,ISO8859-8,CP1255,ISO8859-9,CP1254,ISO8859-10,ISO8859-11,CP874,ISO8859-13,CP1257,ISO8859-14,ISO8859-15,ISO8859-16,CP878,MacJapan,ASCII,ANSI_X3.4-1968,646,CP65000,CP65001,UTF-8-MAC,UTF-8-HFS,UCS-2BE,UCS-4BE,UCS-4LE,CP932,csWindows31J,SJIS,PCK,CP1250,CP1251,CP1252,external,locale|}"$0', '**[charset](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-line.html#plugins-codecs-line-charset) option**\n\n- Value can be any of: ASCII-8BIT, UTF-8, US-ASCII, Big5, Big5-HKSCS, Big5-UAO, CP949, Emacs-Mule, EUC-JP, EUC-KR, EUC-TW, GB2312, GB18030, GBK, ISO-8859-1, ISO-8859-2, ISO-8859-3, ISO-8859-4, ISO-8859-5, ISO-8859-6, ISO-8859-7, ISO-8859-8, ISO-8859-9, ISO-8859-10, ISO-8859-11, ISO-8859-13, ISO-8859-14, ISO-8859-15, ISO-8859-16, KOI8-R, KOI8-U, Shift_JIS, UTF-16BE, UTF-16LE, UTF-32BE, UTF-32LE, Windows-31J, Windows-1250, Windows-1251, Windows-1252, IBM437, IBM737, IBM775, CP850, IBM852, CP852, IBM855, CP855, IBM857, IBM860, IBM861, IBM862, IBM863, IBM864, IBM865, IBM866, IBM869, Windows-1258, GB1988, macCentEuro, macCroatian, macCyrillic, macGreek, macIceland, macRoman, macRomania, macThai, macTurkish, macUkraine, CP950, CP951, IBM037, stateless-ISO-2022-JP, eucJP-ms, CP51932, EUC-JIS-2004, GB12345, ISO-2022-JP, ISO-2022-JP-2, CP50220, CP50221, Windows-1256, Windows-1253, Windows-1255, Windows-1254, TIS-620, Windows-874, Windows-1257, MacJapanese, UTF-7, UTF8-MAC, UTF-16, UTF-32, UTF8-DoCoMo, SJIS-DoCoMo, UTF8-KDDI, SJIS-KDDI, ISO-2022-JP-KDDI, stateless-ISO-2022-JP-KDDI, UTF8-SoftBank, SJIS-SoftBank, BINARY, CP437, CP737, CP775, IBM850, CP857, CP860, CP861, CP862, CP863, CP864, CP865, CP866, CP869, CP1258, Big5-HKSCS:2008, ebcdic-cp-us, eucJP, euc-jp-ms, EUC-JISX0213, eucKR, eucTW, EUC-CN, eucCN, CP936, ISO2022-JP, ISO2022-JP2, ISO8859-1, ISO8859-2, ISO8859-3, ISO8859-4, ISO8859-5, ISO8859-6, CP1256, ISO8859-7, CP1253, ISO8859-8, CP1255, ISO8859-9, CP1254, ISO8859-10, ISO8859-11, CP874, ISO8859-13, CP1257, ISO8859-14, ISO8859-15, ISO8859-16, CP878, MacJapan, ASCII, ANSI_X3.4-1968, 646, CP65000, CP65001, UTF-8-MAC, UTF-8-HFS, UCS-2BE, UCS-4BE, UCS-4LE, CP932, csWindows31J, SJIS, PCK, CP1250, CP1251, CP1252, external, locale\n- Default value is "UTF-8"\n\nThe character encoding used in this input. Examples include UTF-8 and cp1252'),
		createSnippet('delimiter', 'option', 'delimiter => "${1:\n}"', '**[delimiter](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-line.html#plugins-codecs-line-delimiter) option**\n\n- Value type is string\n- Default value is "\n"\n\nChange the delimiter that separates lines'),
		createSnippet('format', 'option', 'format => "${1:format}"', '**[format](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-line.html#plugins-codecs-line-format) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nSet the desired text format for encoding.')
	],
	'logstash-filter-threats_classifier': [
	],
	'logstash-output-pagerduty': [
		createSnippet('description', 'option', 'description => "${1:Logstash event for %{host\\}}"', '**[description](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-pagerduty.html#plugins-outputs-pagerduty-description) option**\n\n- Value type is string\n- Default value is "Logstash event for %{host}"\n\nCustom description'),
		createSnippet('details', 'option', 'details => {\n\t"${1:key}" => "${2:value}"\n}', '**[details](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-pagerduty.html#plugins-outputs-pagerduty-details) option**\n\n- Value type is hash\n- Default value is {"timestamp"=>"%{@timestamp}", "message"=>"%{message}"}\n\nThe event details. These might be data from the Logstash event fields you wish to include. Tags are automatically included if detected so there is no need to explicitly add them here.'),
		createSnippet('event_type', 'option', 'event_type => "${1|trigger,acknowledge,resolve|}"$0', '**[event_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-pagerduty.html#plugins-outputs-pagerduty-event_type) option**\n\n- Value can be any of: trigger, acknowledge, resolve\n- Default value is "trigger"\n\nEvent type'),
		createSnippet('incident_key', 'option', 'incident_key => "${1:logstash/%{host\\}/%{type\\}}"', '**[incident_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-pagerduty.html#plugins-outputs-pagerduty-incident_key) option**\n\n- Value type is string\n- Default value is "logstash/%{host}/%{type}"\n\nThe service key to use. You’ll need to set this up in PagerDuty beforehand.'),
		createSnippet('pdurl', 'option', 'pdurl => "${1:https://events.pagerduty.com/generic/2010-04-15/create_event.json}"', '**[pdurl](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-pagerduty.html#plugins-outputs-pagerduty-pdurl) option**\n\n- Value type is string\n- Default value is "https://events.pagerduty.com/generic/2010-04-15/create_event.json"\n\nPagerDuty API URL. You shouldn’t need to change this, but is included to allow for flexibility should PagerDuty iterate the API and Logstash hasn’t been updated yet.'),
		createSnippet('service_key', 'option', 'service_key => "${1:service_key}"', '**[service_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-pagerduty.html#plugins-outputs-pagerduty-service_key) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe PagerDuty Service API Key', true)
	],
	'logstash-filter-xml': [
		createSnippet('force_array', 'option', 'force_array => ${1|true,false|}', '**[force_array](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-xml.html#plugins-filters-xml-force_array) option**\n\n- Value type is boolean\n- Default value is true\n\nBy default the filter will force single elements to be arrays. Setting this to false will prevent storing single elements in arrays.'),
		createSnippet('force_content', 'option', 'force_content => ${1|false,true|}', '**[force_content](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-xml.html#plugins-filters-xml-force_content) option**\n\n- Value type is boolean\n- Default value is false\n\nBy default the filter will expand attributes differently from content inside of tags. This option allows you to force text content and attributes to always parse to a hash value.'),
		createSnippet('namespaces', 'option', 'namespaces => {\n\t"${1:key}" => "${2:value}"\n}', '**[namespaces](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-xml.html#plugins-filters-xml-namespaces) option**\n\n- Value type is hash\n- Default value is {}\n\nBy default only namespaces declarations on the root element are considered. This allows to configure all namespace declarations to parse the XML document.\n\n**_Example:_**  \n``` ruby\nfilter {\n  xml {\n    namespaces => {\n      "xsl" => "http://www.w3.org/1999/XSL/Transform"\n      "xhtml" => "http://www.w3.org/1999/xhtml"\n    }\n  }\n}\n```'),
		createSnippet('parse_options', 'option', 'parse_options => "${1:parse_options}"', '**[parse_options](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-xml.html#plugins-filters-xml-parse_options) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nSetting XML parse options allows for more control of the parsing process. By default the parser is not strict and thus accepts some invalid content. Currently supported options are:'),
		createSnippet('remove_namespaces', 'option', 'remove_namespaces => ${1|false,true|}', '**[remove_namespaces](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-xml.html#plugins-filters-xml-remove_namespaces) option**\n\n- Value type is boolean\n- Default value is false\n\nRemove all namespaces from all nodes in the document. Of course, if the document had nodes with the same names but different namespaces, they will now be ambiguous.'),
		createSnippet('source', 'option', 'source => "${1:source}"', '**[source](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-xml.html#plugins-filters-xml-source) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nConfig for xml to hash is:\n\n**_Example:_**  \n``` ruby\n    source => source_field\n```', true),
		createSnippet('store_xml', 'option', 'store_xml => ${1|true,false|}', '**[store_xml](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-xml.html#plugins-filters-xml-store_xml) option**\n\n- Value type is boolean\n- Default value is true\n\nBy default the filter will store the whole parsed XML in the destination field as described above. Setting this to false will prevent that.'),
		createSnippet('suppress_empty', 'option', 'suppress_empty => ${1|true,false|}', '**[suppress_empty](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-xml.html#plugins-filters-xml-suppress_empty) option**\n\n- Value type is boolean\n- Default value is true\n\nBy default, output nothing if the element is empty. If set to false, empty element will result in an empty hash object.'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-xml.html#plugins-filters-xml-target) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nDefine target for placing the data\n\n**_Example:_**  \n``` ruby\n    filter {\n      xml {\n        target => "doc"\n      }\n    }\n```'),
		createSnippet('xpath', 'option', 'xpath => {\n\t"${1:key}" => "${2:value}"\n}', '**[xpath](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-xml.html#plugins-filters-xml-xpath) option**\n\n- Value type is hash\n- Default value is {}\n\nxpath will additionally select string values (non-strings will be converted to strings with Ruby’s to_s function) from parsed XML (using each source field defined using the method above) and place those values in the destination fields. Configuration:\n\n**_Example:_**  \n``` ruby\nxpath => [ "xpath-syntax", "destination-field" ]\n```')
	],
	'logstash-codec-cef': [
		createSnippet('default_timezone', 'option', 'default_timezone => "${1:your system time zone}"', '**[default_timezone](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-cef.html#plugins-codecs-cef-default_timezone) option**\n\n- Value type is string\n- Supported values are: Timezone names (such as Europe/Moscow, America/Argentina/Buenos_Aires) UTC Offsets (such as -08:00, +03:00)\n- Timezone names (such as Europe/Moscow, America/Argentina/Buenos_Aires)\n- UTC Offsets (such as -08:00, +03:00)\n- The default value is your system time zone\n- This option has no effect when encoding.\n\nSupported values are:'),
		createSnippet('delimiter', 'option', 'delimiter => "${1:delimiter}"', '**[delimiter](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-cef.html#plugins-codecs-cef-delimiter) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nIf your input puts a delimiter between each CEF event, you’ll want to set this to be that delimiter.\n\n**_Example:_**  \n``` ruby\n    input {\n      tcp {\n        codec => cef { delimiter => "\\\\r\n" }\n        # ...\n      }\n    }\n```'),
		createSnippet('device', 'option', 'device => "${1:observer}"', '**[device](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-cef.html#plugins-codecs-cef-device) option**\n\n- Value type is string\n- Supported values are: observer: indicates that device-specific fields represent the device used to observe the event. host: indicates that device-specific fields represent the device on which the event occurred.\n- observer: indicates that device-specific fields represent the device used to observe the event.\n- host: indicates that device-specific fields represent the device on which the event occurred.\n- The default value for this setting is observer.\n- Option has no effect when ecs_compatibility => disabled.\n- Option has no effect when encoding\n\nSupported values are:'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-cef.html#plugins-codecs-cef-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: uses CEF-defined field names in the event (e.g., bytesIn, sourceAddress) v1: supports ECS-compatible event fields (e.g., [source][bytes], [source][ip])\n- disabled: uses CEF-defined field names in the event (e.g., bytesIn, sourceAddress)\n- v1: supports ECS-compatible event fields (e.g., [source][bytes], [source][ip])\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:'),
		createSnippet('fields', 'option', 'fields => ["${1:field}"]', '**[fields](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-cef.html#plugins-codecs-cef-fields) option**\n\n- Value type is array\n- Default value is []\n- Option has no effect when decoding\n\nWhen this codec is used in an Output Plugin, a list of fields can be provided to be included in CEF extensions part as key/value pairs.'),
		createSnippet('locale', 'option', 'locale => "${1:your system locale}"', '**[locale](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-cef.html#plugins-codecs-cef-locale) option**\n\n- Value type is string\n- Supported values are: Abbreviated language_COUNTRY format (e.g., en_GB, pt_BR) Valid IETF BCP 47 language tag (e.g., zh-cmn-Hans-CN)\n- Abbreviated language_COUNTRY format (e.g., en_GB, pt_BR)\n- Valid IETF BCP 47 language tag (e.g., zh-cmn-Hans-CN)\n- The default value is your system locale\n- Option has no effect when encoding\n\nSupported values are:'),
		createSnippet('name', 'option', 'name => "${1:Logstash}"', '**[name](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-cef.html#plugins-codecs-cef-name) option**\n\n- Value type is string\n- Default value is "Logstash"\n- Option has no effect when decoding\n\nWhen this codec is used in an Output Plugin, this option can be used to specify the value of the name field in the CEF header. The new value can include %{foo} strings to help you build a new value from other parts of the event.'),
		createSnippet('product', 'option', 'product => "${1:Logstash}"', '**[product](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-cef.html#plugins-codecs-cef-product) option**\n\n- Value type is string\n- Default value is "Logstash"\n- Option has no effect when decoding\n\nWhen this codec is used in an Output Plugin, this option can be used to specify the value of the device product field in CEF header. The new value can include %{foo} strings to help you build a new value from other parts of the event.'),
		createSnippet('reverse_mapping', 'option', 'reverse_mapping => ${1|false,true|}', '**[reverse_mapping](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-cef.html#plugins-codecs-cef-reverse_mapping) option**\n\n- Value type is boolean\n- Default value is false\n- Option has no effect when decoding\n\nSet to true to adhere to the specifications and encode using the CEF key name (short name) for the CEF field names.'),
		createSnippet('severity', 'option', 'severity => "${1:6}"', '**[severity](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-cef.html#plugins-codecs-cef-severity) option**\n\n- Value type is string\n- Default value is "6"\n- Option has no effect when decoding\n\nWhen this codec is used in an Output Plugin, this option can be used to specify the value of the severity field in CEF header. The new value can include %{foo} strings to help you build a new value from other parts of the event.'),
		createSnippet('signature', 'option', 'signature => "${1:Logstash}"', '**[signature](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-cef.html#plugins-codecs-cef-signature) option**\n\n- Value type is string\n- Default value is "Logstash"\n- Option has no effect when decoding\n\nWhen this codec is used in an Output Plugin, this option can be used to specify the value of the signature ID field in CEF header. The new value can include %{foo} strings to help you build a new value from other parts of the event.'),
		createSnippet('vendor', 'option', 'vendor => "${1:Elasticsearch}"', '**[vendor](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-cef.html#plugins-codecs-cef-vendor) option**\n\n- Value type is string\n- Default value is "Elasticsearch"\n- Option has no effect when decoding\n\nWhen this codec is used in an Output Plugin, this option can be used to specify the value of the device vendor field in CEF header. The new value can include %{foo} strings to help you build a new value from other parts of the event.'),
		createSnippet('version', 'option', 'version => "${1:1.0}"', '**[version](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-cef.html#plugins-codecs-cef-version) option**\n\n- Value type is string\n- Default value is "1.0"\n- Option has no effect when decoding\n\nWhen this codec is used in an Output Plugin, this option can be used to specify the value of the device version field in CEF header. The new value can include %{foo} strings to help you build a new value from other parts of the event.')
	],
	'logstash-output-common_options': [
		createSnippet('codec', 'common_option', 'codec => ', '**[codec](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-boundary.html#plugins-outputs-boundary-codec) option**\n\n- Value type is codec\n- Default value is "plain"\n\nThe codec used for output data. Output codecs are a convenient method for encoding your data before it leaves the output without needing a separate filter in your Logstash pipeline.'),
		createSnippet('enable_metric', 'common_option', 'enable_metric => ${1|true,false|}', '**[enable_metric](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-boundary.html#plugins-outputs-boundary-enable_metric) option**\n\n- Value type is boolean\n- Default value is true\n\nDisable or enable metric logging for this specific plugin instance. By default we record all the metrics we can, but you can disable metrics collection for a specific plugin.'),
		createSnippet('id', 'common_option', 'id => "${1:id}"', '**[id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-boundary.html#plugins-outputs-boundary-id) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nAdd a unique ID to the plugin configuration. If no ID is specified, Logstash will generate one. It is strongly recommended to set this ID in your configuration. This is particularly useful when you have two or more plugins of the same type. For example, if you have 2 boundary outputs. Adding a named ID in this case will help in monitoring Logstash when using the monitoring APIs.\n\n**_Example:_**  \n``` ruby\noutput {\n  boundary {\n    id => "my_plugin_id"\n  }\n}\n```')
	],
	'logstash-input-sqs': [
		createSnippet('access_key_id', 'option', 'access_key_id => "${1:access_key_id}"', '**[access_key_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-sqs.html#plugins-inputs-sqs-access_key_id) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThis plugin uses the AWS SDK and supports several ways to get credentials, which will be tried in this order:'),
		createSnippet('aws_credentials_file', 'option', 'aws_credentials_file => "${1:aws_credentials_file}"', '**[aws_credentials_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-sqs.html#plugins-inputs-sqs-aws_credentials_file) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nPath to YAML file containing a hash of AWS credentials. This file will only be loaded if access_key_id and secret_access_key aren’t set. The contents of the file should look like this:'),
		createSnippet('endpoint', 'option', 'endpoint => "${1:endpoint}"', '**[endpoint](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-sqs.html#plugins-inputs-sqs-endpoint) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe endpoint to connect to. By default it is constructed using the value of region. This is useful when connecting to S3 compatible services, but beware that these aren’t guaranteed to work correctly with the AWS SDK.'),
		createSnippet('id_field', 'option', 'id_field => "${1:id_field}"', '**[id_field](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-sqs.html#plugins-inputs-sqs-id_field) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nName of the event field in which to store the SQS message ID'),
		createSnippet('md5_field', 'option', 'md5_field => "${1:md5_field}"', '**[md5_field](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-sqs.html#plugins-inputs-sqs-md5_field) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nName of the event field in which to store the SQS message MD5 checksum'),
		createSnippet('polling_frequency', 'option', 'polling_frequency => ${1:20}', '**[polling_frequency](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-sqs.html#plugins-inputs-sqs-polling_frequency) option**\n\n- Value type is number\n- Default value is 20\n\nPolling frequency, default is 20 seconds'),
		createSnippet('proxy_uri', 'option', 'proxy_uri => "${1:proxy_uri}"', '**[proxy_uri](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-sqs.html#plugins-inputs-sqs-proxy_uri) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nURI to proxy server if required'),
		createSnippet('queue', 'option', 'queue => "${1:queue}"', '**[queue](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-sqs.html#plugins-inputs-sqs-queue) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nName of the SQS Queue name to pull messages from. Note that this is just the name of the queue, not the URL or ARN.', true),
		createSnippet('region', 'option', 'region => "${1:us-east-1}"', '**[region](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-sqs.html#plugins-inputs-sqs-region) option**\n\n- Value type is string\n- Default value is "us-east-1"\n\nThe AWS Region'),
		createSnippet('role_arn', 'option', 'role_arn => "${1:role_arn}"', '**[role_arn](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-sqs.html#plugins-inputs-sqs-role_arn) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS IAM Role to assume, if any. This is used to generate temporary credentials, typically for cross-account access. See the AssumeRole API documentation for more information.'),
		createSnippet('role_session_name', 'option', 'role_session_name => "${1:logstash}"', '**[role_session_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-sqs.html#plugins-inputs-sqs-role_session_name) option**\n\n- Value type is string\n- Default value is "logstash"\n\nSession name to use when assuming an IAM role.'),
		createSnippet('secret_access_key', 'option', 'secret_access_key => "${1:secret_access_key}"', '**[secret_access_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-sqs.html#plugins-inputs-sqs-secret_access_key) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS Secret Access Key'),
		createSnippet('sent_timestamp_field', 'option', 'sent_timestamp_field => "${1:sent_timestamp_field}"', '**[sent_timestamp_field](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-sqs.html#plugins-inputs-sqs-sent_timestamp_field) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nName of the event field in which to store the SQS message Sent Timestamp'),
		createSnippet('session_token', 'option', 'session_token => "${1:session_token}"', '**[session_token](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-sqs.html#plugins-inputs-sqs-session_token) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS Session token for temporary credential'),
		createSnippet('threads', 'option', 'threads => ${1:1}', '**[threads](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-sqs.html#plugins-inputs-sqs-threads) option**\n\n- Value type is number\n- Default value is 1')
	],
	'logstash-filter-extractnumbers': [
		createSnippet('source', 'option', 'source => "${1:message}"', '**[source](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-extractnumbers.html#plugins-filters-extractnumbers-source) option**\n\n- Value type is string\n- Default value is "message"\n\nThe source field for the data. By default is message.')
	],
	'logstash-output-google_pubsub': [
		createSnippet('project_id', 'option', 'project_id => "${1:project_id}"', '**[project_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_pubsub.html#plugins-outputs-google_pubsub-project_id) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nGoogle Cloud Project ID (name, not number).', true),
		createSnippet('topic', 'option', 'topic => "${1:topic}"', '**[topic](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_pubsub.html#plugins-outputs-google_pubsub-topic) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nGoogle Cloud Pub/Sub Topic. You must create the topic manually before running this plugin.', true),
		createSnippet('json_key_file', 'option', 'json_key_file => "${1:/path/to/file}"', '**[json_key_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_pubsub.html#plugins-outputs-google_pubsub-json_key_file) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nThe path to the key to authenticate your user to the bucket. This service user must have the pubsub.topics.publish permission so it can publish to the topic.'),
		createSnippet('delay_threshold_secs', 'option', 'delay_threshold_secs => ${1:123}', '**[delay_threshold_secs](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_pubsub.html#plugins-outputs-google_pubsub-delay_threshold_secs) option**\n\n- Value type is number\n- Default is: 5\n\nSend the batch once this delay has passed, from the time the first message is queued. Must be greater than 0.'),
		createSnippet('message_count_threshold', 'option', 'message_count_threshold => ${1:123}', '**[message_count_threshold](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_pubsub.html#plugins-outputs-google_pubsub-message_count_threshold) option**\n\n- Value type is number\n- Default is: 100\n\nOnce this many messages are queued, send all the messages in a single call, even if the delay threshold hasn’t elapsed yet. Must be < 1000. A value of 0 will cause messages to instantly be sent but will reduce total throughput due to overhead.'),
		createSnippet('request_byte_threshold', 'option', 'request_byte_threshold => "${1:1 mb}"', '**[request_byte_threshold](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_pubsub.html#plugins-outputs-google_pubsub-request_byte_threshold) option**\n\n- Value type is bytes\n- Default is: 1000000\n\nOnce the number of bytes in the batched request reaches this threshold, send all of the messages in a single call, even if neither the delay or message count thresholds have been exceeded yet. This includes full message payload size, including any attributes set.'),
		createSnippet('attributes', 'option', 'attributes => {\n\t"${1:key}" => "${2:value}"\n}', '**[attributes](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_pubsub.html#plugins-outputs-google_pubsub-attributes) option**\n\n- Value type is hash\n- Default is: {}\n\nAttributes to add to the message in key: value formats. Keys and values MUST be strings.')
	],
	'logstash-codec-edn_lines': [
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-edn_lines.html#plugins-codecs-edn_lines-target) option**\n\n- Value type is string\n- There is no default value for this setting.\n- The option is only relevant while decoding.\n\nDefine the target field for placing the decoded fields. If this setting is not set, data will be stored at the root (top level) of the event.\n\n**_Example:_**  \n``` ruby\n    input {\n      tcp {\n        port => 4242\n        codec => edn_lines {\n          target => "[document]"\n        }\n      }\n    }\n```')
	],
	'logstash-input-redis': [
		createSnippet('batch_count', 'option', 'batch_count => ${1:125}', '**[batch_count](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-redis.html#plugins-inputs-redis-batch_count) option**\n\n- Value type is number\n- Default value is 125\n\nThe number of events to return from Redis using EVAL.'),
		createSnippet('command_map', 'option', 'command_map => {\n\t"${1:key}" => "${2:value}"\n}', '**[command_map](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-redis.html#plugins-inputs-redis-command_map) option**\n\n- Value type is hash\n- There is no default value for this setting.\n- key is the default command name, value is the renamed command.\n\nConfigure renamed redis commands in the form of "oldname" ⇒ "newname". Redis allows for the renaming or disabling of commands in its protocol, see: https://redis.io/topics/security'),
		createSnippet('data_type', 'option', 'data_type => "${1|list,channel,pattern_channel|}"$0', '**[data_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-redis.html#plugins-inputs-redis-data_type) option**\n\n- This is a required setting.\n- Value can be any of: list, channel, pattern_channel\n- There is no default value for this setting.\n\nSpecify either list or channel. If data_type is list, then we will BLPOP the key. If data_type is channel, then we will SUBSCRIBE to the key. If data_type is pattern_channel, then we will PSUBSCRIBE to the key.', true),
		createSnippet('db', 'option', 'db => ${1:0}', '**[db](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-redis.html#plugins-inputs-redis-db) option**\n\n- Value type is number\n- Default value is 0\n\nThe Redis database number.'),
		createSnippet('host', 'option', 'host => "${1:127.0.0.1}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-redis.html#plugins-inputs-redis-host) option**\n\n- Value type is string\n- Default value is "127.0.0.1"\n\nThe hostname of your Redis server.'),
		createSnippet('path', 'option', 'path => "${1:path}"', '**[path](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-redis.html#plugins-inputs-redis-path) option**\n\n- Value type is string\n- There is no default value for this setting.\n- Path will override Host configuration if both specified.\n\nThe unix socket path of your Redis server.'),
		createSnippet('key', 'option', 'key => "${1:key}"', '**[key](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-redis.html#plugins-inputs-redis-key) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe name of a Redis list or channel.', true),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-redis.html#plugins-inputs-redis-password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nPassword to authenticate with. There is no authentication by default.'),
		createSnippet('port', 'option', 'port => ${1:6379}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-redis.html#plugins-inputs-redis-port) option**\n\n- Value type is number\n- Default value is 6379\n\nThe port to connect on.'),
		createSnippet('ssl', 'option', 'ssl => ${1|false,true|}', '**[ssl](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-redis.html#plugins-inputs-redis-ssl) option**\n\n- Value type is boolean\n- Default value is false\n\nEnable SSL support.'),
		createSnippet('threads', 'option', 'threads => ${1:1}', '**[threads](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-redis.html#plugins-inputs-redis-threads) option**\n\n- Value type is number\n- Default value is 1'),
		createSnippet('timeout', 'option', 'timeout => ${1:5}', '**[timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-redis.html#plugins-inputs-redis-timeout) option**\n\n- Value type is number\n- Default value is 5\n\nInitial connection timeout in seconds.')
	],
	'logstash-output-timber': [
		createSnippet('api_key', 'option', 'api_key => "${1:api_key}"', '**[api_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-timber.html#plugins-outputs-timber-api_key) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nYour Timber.io API key. You can obtain your API by creating an app in the [Timber console](https://app.timber.io).'),
		createSnippet('cacert', 'option', 'cacert => "${1:/path/to/file}"', '**[cacert](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-timber.html#plugins-outputs-timber-cacert) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you need to use a custom X.509 CA (.pem certs) specify the path to that here.'),
		createSnippet('client_cert', 'option', 'client_cert => "${1:/path/to/file}"', '**[client_cert](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-timber.html#plugins-outputs-timber-client_cert) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you’d like to use a client certificate (note, most people don’t want this) set the path to the x509 cert here'),
		createSnippet('client_key', 'option', 'client_key => "${1:/path/to/file}"', '**[client_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-timber.html#plugins-outputs-timber-client_key) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you’re using a client certificate specify the path to the encryption key here'),
		createSnippet('connect_timeout', 'option', 'connect_timeout => ${1:10}', '**[connect_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-timber.html#plugins-outputs-timber-connect_timeout) option**\n\n- Value type is number\n- Default value is 10\n\nTimeout (in seconds) to wait for a connection to be established. Default is 10s'),
		createSnippet('keystore', 'option', 'keystore => "${1:/path/to/file}"', '**[keystore](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-timber.html#plugins-outputs-timber-keystore) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you need to use a custom keystore (.jks) specify that here. This does not work with .pem keys!'),
		createSnippet('keystore_password', 'option', 'keystore_password => "${1:keystore_password}"', '**[keystore_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-timber.html#plugins-outputs-timber-keystore_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nSpecify the keystore password here. Note, most .jks files created with keytool require a password!'),
		createSnippet('keystore_type', 'option', 'keystore_type => "${1:JKS}"', '**[keystore_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-timber.html#plugins-outputs-timber-keystore_type) option**\n\n- Value type is string\n- Default value is "JKS"\n\nSpecify the keystore type here. One of JKS or PKCS12. Default is JKS'),
		createSnippet('pool_max', 'option', 'pool_max => ${1:50}', '**[pool_max](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-timber.html#plugins-outputs-timber-pool_max) option**\n\n- Value type is number\n- Default value is 50\n\nMax number of concurrent connections. Defaults to 50'),
		createSnippet('proxy', 'option', 'proxy => "${1:proxy}"', '**[proxy](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-timber.html#plugins-outputs-timber-proxy) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nIf you’d like to use an HTTP proxy . This supports multiple configuration syntaxes:'),
		createSnippet('request_timeout', 'option', 'request_timeout => ${1:60}', '**[request_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-timber.html#plugins-outputs-timber-request_timeout) option**\n\n- Value type is number\n- Default value is 60\n\nThis module makes it easy to add a very fully configured HTTP client to logstash based on [Manticore](https://github.com/cheald/manticore). For an example of its usage see https://github.com/logstash-plugins/logstash-input-http_poller Timeout (in seconds) for the entire request'),
		createSnippet('socket_timeout', 'option', 'socket_timeout => ${1:10}', '**[socket_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-timber.html#plugins-outputs-timber-socket_timeout) option**\n\n- Value type is number\n- Default value is 10\n\nTimeout (in seconds) to wait for data on the socket. Default is 10s'),
		createSnippet('truststore', 'option', 'truststore => "${1:/path/to/file}"', '**[truststore](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-timber.html#plugins-outputs-timber-truststore) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you need to use a custom truststore (.jks) specify that here. This does not work with .pem certs!'),
		createSnippet('truststore_password', 'option', 'truststore_password => "${1:truststore_password}"', '**[truststore_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-timber.html#plugins-outputs-timber-truststore_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nSpecify the truststore password here. Note, most .jks files created with keytool require a password!'),
		createSnippet('truststore_type', 'option', 'truststore_type => "${1:JKS}"', '**[truststore_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-timber.html#plugins-outputs-timber-truststore_type) option**\n\n- Value type is string\n- Default value is "JKS"\n\nSpecify the truststore type here. One of JKS or PKCS12. Default is JKS')
	],
	'logstash-codec-java_plain': [
		createSnippet('charset', 'option', 'charset => "${1|UTF-8,ASCII-8BIT,US-ASCII,Big5,Big5-HKSCS,Big5-UAO,CP949,Emacs-Mule,EUC-JP,EUC-KR,EUC-TW,GB2312,GB18030,GBK,ISO-8859-1,ISO-8859-2,ISO-8859-3,ISO-8859-4,ISO-8859-5,ISO-8859-6,ISO-8859-7,ISO-8859-8,ISO-8859-9,ISO-8859-10,ISO-8859-11,ISO-8859-13,ISO-8859-14,ISO-8859-15,ISO-8859-16,KOI8-R,KOI8-U,Shift_JIS,UTF-16BE,UTF-16LE,UTF-32BE,UTF-32LE,Windows-31J,Windows-1250,Windows-1251,Windows-1252,IBM437,IBM737,IBM775,CP850,IBM852,CP852,IBM855,CP855,IBM857,IBM860,IBM861,IBM862,IBM863,IBM864,IBM865,IBM866,IBM869,Windows-1258,GB1988,macCentEuro,macCroatian,macCyrillic,macGreek,macIceland,macRoman,macRomania,macThai,macTurkish,macUkraine,CP950,CP951,IBM037,stateless-ISO-2022-JP,eucJP-ms,CP51932,EUC-JIS-2004,GB12345,ISO-2022-JP,ISO-2022-JP-2,CP50220,CP50221,Windows-1256,Windows-1253,Windows-1255,Windows-1254,TIS-620,Windows-874,Windows-1257,MacJapanese,UTF-7,UTF8-MAC,UTF-16,UTF-32,UTF8-DoCoMo,SJIS-DoCoMo,UTF8-KDDI,SJIS-KDDI,ISO-2022-JP-KDDI,stateless-ISO-2022-JP-KDDI,UTF8-SoftBank,SJIS-SoftBank,BINARY,CP437,CP737,CP775,IBM850,CP857,CP860,CP861,CP862,CP863,CP864,CP865,CP866,CP869,CP1258,Big5-HKSCS:2008,ebcdic-cp-us,eucJP,euc-jp-ms,EUC-JISX0213,eucKR,eucTW,EUC-CN,eucCN,CP936,ISO2022-JP,ISO2022-JP2,ISO8859-1,ISO8859-2,ISO8859-3,ISO8859-4,ISO8859-5,ISO8859-6,CP1256,ISO8859-7,CP1253,ISO8859-8,CP1255,ISO8859-9,CP1254,ISO8859-10,ISO8859-11,CP874,ISO8859-13,CP1257,ISO8859-14,ISO8859-15,ISO8859-16,CP878,MacJapan,ASCII,ANSI_X3.4-1968,646,CP65000,CP65001,UTF-8-MAC,UTF-8-HFS,UCS-2BE,UCS-4BE,UCS-4LE,CP932,csWindows31J,SJIS,PCK,CP1250,CP1251,CP1252,external,locale|}"$0', '**[charset](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-java_plain.html#plugins-codecs-java_plain-charset) option**\n\n- Value can be any of: ASCII-8BIT, UTF-8, US-ASCII, Big5, Big5-HKSCS, Big5-UAO, CP949, Emacs-Mule, EUC-JP, EUC-KR, EUC-TW, GB2312, GB18030, GBK, ISO-8859-1, ISO-8859-2, ISO-8859-3, ISO-8859-4, ISO-8859-5, ISO-8859-6, ISO-8859-7, ISO-8859-8, ISO-8859-9, ISO-8859-10, ISO-8859-11, ISO-8859-13, ISO-8859-14, ISO-8859-15, ISO-8859-16, KOI8-R, KOI8-U, Shift_JIS, UTF-16BE, UTF-16LE, UTF-32BE, UTF-32LE, Windows-31J, Windows-1250, Windows-1251, Windows-1252, IBM437, IBM737, IBM775, CP850, IBM852, CP852, IBM855, CP855, IBM857, IBM860, IBM861, IBM862, IBM863, IBM864, IBM865, IBM866, IBM869, Windows-1258, GB1988, macCentEuro, macCroatian, macCyrillic, macGreek, macIceland, macRoman, macRomania, macThai, macTurkish, macUkraine, CP950, CP951, IBM037, stateless-ISO-2022-JP, eucJP-ms, CP51932, EUC-JIS-2004, GB12345, ISO-2022-JP, ISO-2022-JP-2, CP50220, CP50221, Windows-1256, Windows-1253, Windows-1255, Windows-1254, TIS-620, Windows-874, Windows-1257, MacJapanese, UTF-7, UTF8-MAC, UTF-16, UTF-32, UTF8-DoCoMo, SJIS-DoCoMo, UTF8-KDDI, SJIS-KDDI, ISO-2022-JP-KDDI, stateless-ISO-2022-JP-KDDI, UTF8-SoftBank, SJIS-SoftBank, BINARY, CP437, CP737, CP775, IBM850, CP857, CP860, CP861, CP862, CP863, CP864, CP865, CP866, CP869, CP1258, Big5-HKSCS:2008, ebcdic-cp-us, eucJP, euc-jp-ms, EUC-JISX0213, eucKR, eucTW, EUC-CN, eucCN, CP936, ISO2022-JP, ISO2022-JP2, ISO8859-1, ISO8859-2, ISO8859-3, ISO8859-4, ISO8859-5, ISO8859-6, CP1256, ISO8859-7, CP1253, ISO8859-8, CP1255, ISO8859-9, CP1254, ISO8859-10, ISO8859-11, CP874, ISO8859-13, CP1257, ISO8859-14, ISO8859-15, ISO8859-16, CP878, MacJapan, ASCII, ANSI_X3.4-1968, 646, CP65000, CP65001, UTF-8-MAC, UTF-8-HFS, UCS-2BE, UCS-4BE, UCS-4LE, CP932, csWindows31J, SJIS, PCK, CP1250, CP1251, CP1252, external, locale\n- Default value is "UTF-8"\n\nThe character encoding used in this input. Examples include UTF-8 and cp1252. This setting is useful if your data is in a character set other than UTF-8.'),
		createSnippet('format', 'option', 'format => "${1:format}"', '**[format](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-java_plain.html#plugins-codecs-java_plain-format) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nSet the desired text format for encoding in sprintf format.')
	],
	'logstash-input-unix': [
		createSnippet('data_timeout', 'option', 'data_timeout => ${1:-1}', '**[data_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-unix.html#plugins-inputs-unix-data_timeout) option**\n\n- Value type is number\n- Default value is -1\n\nThe read timeout in seconds. If a particular connection is idle for more than this timeout period, we will assume it is dead and close it.'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-unix.html#plugins-inputs-unix-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: uses backwards compatible field names, such as [host] v1, v8: uses fields that are compatible with ECS, such as [host][name]\n- disabled: uses backwards compatible field names, such as [host]\n- v1, v8: uses fields that are compatible with ECS, such as [host][name]\n\nSupported values are:'),
		createSnippet('force_unlink', 'option', 'force_unlink => ${1|false,true|}', '**[force_unlink](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-unix.html#plugins-inputs-unix-force_unlink) option**\n\n- Value type is boolean\n- Default value is false\n\nRemove socket file in case of EADDRINUSE failure'),
		createSnippet('mode', 'option', 'mode => "${1|server,client|}"$0', '**[mode](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-unix.html#plugins-inputs-unix-mode) option**\n\n- Value can be any of: server, client\n- Default value is "server"\n\nMode to operate in. server listens for client connections, client connects to a server.'),
		createSnippet('path', 'option', 'path => "${1:path}"', '**[path](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-unix.html#plugins-inputs-unix-path) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nWhen mode is server, the path to listen on. When mode is client, the path to connect to.', true),
		createSnippet('socket_not_present_retry_interval_seconds', 'option', 'socket_not_present_retry_interval_seconds => ${1:5}', '**[socket_not_present_retry_interval_seconds](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-unix.html#plugins-inputs-unix-socket_not_present_retry_interval_seconds) option**\n\n- This is a required setting.\n- Value type is number\n- Default value is 5\n\nAmount of time in seconds to wait if the socket file is not present, before retrying. Only positive values are allowed.', true)
	],
	'logstash-filter-elapsed': [
		createSnippet('end_tag', 'option', 'end_tag => "${1:end_tag}"', '**[end_tag](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elapsed.html#plugins-filters-elapsed-end_tag) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe name of the tag identifying the "end event"', true),
		createSnippet('new_event_on_match', 'option', 'new_event_on_match => ${1|false,true|}', '**[new_event_on_match](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elapsed.html#plugins-filters-elapsed-new_event_on_match) option**\n\n- Value type is boolean\n- Default value is false\n\nThis property manage what to do when an "end event" matches a "start event". If it’s set to false (default value), the elapsed information are added to the "end event"; if it’s set to true a new "match event" is created.'),
		createSnippet('start_tag', 'option', 'start_tag => "${1:start_tag}"', '**[start_tag](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elapsed.html#plugins-filters-elapsed-start_tag) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe name of the tag identifying the "start event"', true),
		createSnippet('timeout', 'option', 'timeout => ${1:1800}', '**[timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elapsed.html#plugins-filters-elapsed-timeout) option**\n\n- Value type is number\n- Default value is 1800\n\nThe amount of seconds after an "end event" can be considered lost. The corresponding "start event" is discarded and an "expired event" is generated. The default value is 30 minutes (1800 seconds).'),
		createSnippet('unique_id_field', 'option', 'unique_id_field => "${1:unique_id_field}"', '**[unique_id_field](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elapsed.html#plugins-filters-elapsed-unique_id_field) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe name of the field containing the task ID. This value must uniquely identify the task in the system, otherwise it’s impossible to match the couple of events.', true),
		createSnippet('keep_start_event', 'option', 'keep_start_event => "${1:first}"', '**[keep_start_event](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elapsed.html#plugins-filters-elapsed-keep_start_event) option**\n\n- Value type is string\n- Default value is first\n\nThis property manages what to do when several events matched as a start one were received before the end event for the specified ID. There are two supported values: first or last. If it’s set to first (default value), the first event matched as a start will be used; if it’s set to last, the last one will be used.')
	],
	'logstash-codec-multiline': [
		createSnippet('auto_flush_interval', 'option', 'auto_flush_interval => ${1:123}', '**[auto_flush_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-multiline.html#plugins-codecs-multiline-auto_flush_interval) option**\n\n- Value type is number\n- There is no default value for this setting.\n\nThe accumulation of multiple lines will be converted to an event when either a matching new line is seen or there has been no new data appended for this many seconds. No default. If unset, no auto_flush. Units: seconds'),
		createSnippet('charset', 'option', 'charset => "${1|UTF-8,ASCII-8BIT,US-ASCII,Big5,Big5-HKSCS,Big5-UAO,CP949,Emacs-Mule,EUC-JP,EUC-KR,EUC-TW,GB2312,GB18030,GBK,ISO-8859-1,ISO-8859-2,ISO-8859-3,ISO-8859-4,ISO-8859-5,ISO-8859-6,ISO-8859-7,ISO-8859-8,ISO-8859-9,ISO-8859-10,ISO-8859-11,ISO-8859-13,ISO-8859-14,ISO-8859-15,ISO-8859-16,KOI8-R,KOI8-U,Shift_JIS,UTF-16BE,UTF-16LE,UTF-32BE,UTF-32LE,Windows-31J,Windows-1250,Windows-1251,Windows-1252,IBM437,IBM737,IBM775,CP850,IBM852,CP852,IBM855,CP855,IBM857,IBM860,IBM861,IBM862,IBM863,IBM864,IBM865,IBM866,IBM869,Windows-1258,GB1988,macCentEuro,macCroatian,macCyrillic,macGreek,macIceland,macRoman,macRomania,macThai,macTurkish,macUkraine,CP950,CP951,IBM037,stateless-ISO-2022-JP,eucJP-ms,CP51932,EUC-JIS-2004,GB12345,ISO-2022-JP,ISO-2022-JP-2,CP50220,CP50221,Windows-1256,Windows-1253,Windows-1255,Windows-1254,TIS-620,Windows-874,Windows-1257,MacJapanese,UTF-7,UTF8-MAC,UTF-16,UTF-32,UTF8-DoCoMo,SJIS-DoCoMo,UTF8-KDDI,SJIS-KDDI,ISO-2022-JP-KDDI,stateless-ISO-2022-JP-KDDI,UTF8-SoftBank,SJIS-SoftBank,BINARY,CP437,CP737,CP775,IBM850,CP857,CP860,CP861,CP862,CP863,CP864,CP865,CP866,CP869,CP1258,Big5-HKSCS:2008,ebcdic-cp-us,eucJP,euc-jp-ms,EUC-JISX0213,eucKR,eucTW,EUC-CN,eucCN,CP936,ISO2022-JP,ISO2022-JP2,ISO8859-1,ISO8859-2,ISO8859-3,ISO8859-4,ISO8859-5,ISO8859-6,CP1256,ISO8859-7,CP1253,ISO8859-8,CP1255,ISO8859-9,CP1254,ISO8859-10,ISO8859-11,CP874,ISO8859-13,CP1257,ISO8859-14,ISO8859-15,ISO8859-16,CP878,MacJapan,ASCII,ANSI_X3.4-1968,646,CP65000,CP65001,UTF-8-MAC,UTF-8-HFS,UCS-2BE,UCS-4BE,UCS-4LE,CP932,csWindows31J,SJIS,PCK,CP1250,CP1251,CP1252,external,locale|}"$0', '**[charset](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-multiline.html#plugins-codecs-multiline-charset) option**\n\n- Value can be any of: ASCII-8BIT, UTF-8, US-ASCII, Big5, Big5-HKSCS, Big5-UAO, CP949, Emacs-Mule, EUC-JP, EUC-KR, EUC-TW, GB2312, GB18030, GBK, ISO-8859-1, ISO-8859-2, ISO-8859-3, ISO-8859-4, ISO-8859-5, ISO-8859-6, ISO-8859-7, ISO-8859-8, ISO-8859-9, ISO-8859-10, ISO-8859-11, ISO-8859-13, ISO-8859-14, ISO-8859-15, ISO-8859-16, KOI8-R, KOI8-U, Shift_JIS, UTF-16BE, UTF-16LE, UTF-32BE, UTF-32LE, Windows-31J, Windows-1250, Windows-1251, Windows-1252, IBM437, IBM737, IBM775, CP850, IBM852, CP852, IBM855, CP855, IBM857, IBM860, IBM861, IBM862, IBM863, IBM864, IBM865, IBM866, IBM869, Windows-1258, GB1988, macCentEuro, macCroatian, macCyrillic, macGreek, macIceland, macRoman, macRomania, macThai, macTurkish, macUkraine, CP950, CP951, IBM037, stateless-ISO-2022-JP, eucJP-ms, CP51932, EUC-JIS-2004, GB12345, ISO-2022-JP, ISO-2022-JP-2, CP50220, CP50221, Windows-1256, Windows-1253, Windows-1255, Windows-1254, TIS-620, Windows-874, Windows-1257, MacJapanese, UTF-7, UTF8-MAC, UTF-16, UTF-32, UTF8-DoCoMo, SJIS-DoCoMo, UTF8-KDDI, SJIS-KDDI, ISO-2022-JP-KDDI, stateless-ISO-2022-JP-KDDI, UTF8-SoftBank, SJIS-SoftBank, BINARY, CP437, CP737, CP775, IBM850, CP857, CP860, CP861, CP862, CP863, CP864, CP865, CP866, CP869, CP1258, Big5-HKSCS:2008, ebcdic-cp-us, eucJP, euc-jp-ms, EUC-JISX0213, eucKR, eucTW, EUC-CN, eucCN, CP936, ISO2022-JP, ISO2022-JP2, ISO8859-1, ISO8859-2, ISO8859-3, ISO8859-4, ISO8859-5, ISO8859-6, CP1256, ISO8859-7, CP1253, ISO8859-8, CP1255, ISO8859-9, CP1254, ISO8859-10, ISO8859-11, CP874, ISO8859-13, CP1257, ISO8859-14, ISO8859-15, ISO8859-16, CP878, MacJapan, ASCII, ANSI_X3.4-1968, 646, CP65000, CP65001, UTF-8-MAC, UTF-8-HFS, UCS-2BE, UCS-4BE, UCS-4LE, CP932, csWindows31J, SJIS, PCK, CP1250, CP1251, CP1252, external, locale\n- Default value is "UTF-8"\n\nThe character encoding used in this input. Examples include UTF-8 and cp1252'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-multiline.html#plugins-codecs-multiline-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: plugin only sets the message field v1,v8: Elastic Common Schema compliant behavior ([event][original] is also added)\n- disabled: plugin only sets the message field\n- v1,v8: Elastic Common Schema compliant behavior ([event][original] is also added)\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled\n\nSupported values are:'),
		createSnippet('max_bytes', 'option', 'max_bytes => "${1:10 MiB}"', '**[max_bytes](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-multiline.html#plugins-codecs-multiline-max_bytes) option**\n\n- Value type is bytes\n- Default value is "10 MiB"\n\nThe accumulation of events can make logstash exit with an out of memory error if event boundaries are not correctly defined. This settings make sure to flush multiline events after reaching a number of bytes, it is used in combination max_lines.'),
		createSnippet('max_lines', 'option', 'max_lines => ${1:500}', '**[max_lines](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-multiline.html#plugins-codecs-multiline-max_lines) option**\n\n- Value type is number\n- Default value is 500\n\nThe accumulation of events can make logstash exit with an out of memory error if event boundaries are not correctly defined. This settings make sure to flush multiline events after reaching a number of lines, it is used in combination max_bytes.'),
		createSnippet('multiline_tag', 'option', 'multiline_tag => "${1:multiline}"', '**[multiline_tag](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-multiline.html#plugins-codecs-multiline-multiline_tag) option**\n\n- Value type is string\n- Default value is "multiline"\n\nTag multiline events with a given tag. This tag will only be added to events that actually have multiple lines in them.'),
		createSnippet('negate', 'option', 'negate => ${1|false,true|}', '**[negate](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-multiline.html#plugins-codecs-multiline-negate) option**\n\n- Value type is boolean\n- Default value is false\n\nNegate the regexp pattern (if not matched).'),
		createSnippet('pattern', 'option', 'pattern => "${1:pattern}"', '**[pattern](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-multiline.html#plugins-codecs-multiline-pattern) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe regular expression to match.', true),
		createSnippet('patterns_dir', 'option', 'patterns_dir => ["${1:patterns_dir}"]', '**[patterns_dir](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-multiline.html#plugins-codecs-multiline-patterns_dir) option**\n\n- Value type is array\n- Default value is []\n\nLogstash ships by default with a bunch of patterns, so you don’t necessarily need to define this yourself unless you are adding additional patterns.'),
		createSnippet('what', 'option', 'what => "${1|previous,next|}"$0', '**[what](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-multiline.html#plugins-codecs-multiline-what) option**\n\n- This is a required setting.\n- Value can be any of: previous, next\n- There is no default value for this setting.\n\nIf the pattern matched, does event belong to the next or previous event?', true)
	],
	'logstash-output-elastic_workplace_search': [
		createSnippet('access_token', 'option', 'access_token => "${1:access_token}"', '**[access_token](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elastic_workplace_search.html#plugins-outputs-elastic_workplace_search-access_token) option**\n\n- Value type is password\n- There is no default value\n\nThe source access token. Visit the source overview page in the Workplace Search dashboard to find the token associated with your source.', true),
		createSnippet('document_id', 'option', 'document_id => "${1:document_id}"', '**[document_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elastic_workplace_search.html#plugins-outputs-elastic_workplace_search-document_id) option**\n\n- Value type is string\n- There is no default value\n\nThe id for workplace search documents. This can be an interpolated value like myapp-%{sequence_id}. Reusing ids will cause documents to be rewritten.'),
		createSnippet('source', 'option', 'source => "${1:source}"', '**[source](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elastic_workplace_search.html#plugins-outputs-elastic_workplace_search-source) option**\n\n- Value type is string\n- There is no default value\n\nThe ID of the source you created in Workplace Search. The source field supports sprintf format to allow the source ID to be derived from a field value from each event, for example %{source_id}.\n\n**_Example:_**  \n``` ruby\ninput {\n  stdin {\n    codec => json\n  }\n}\n\nfilter {\n  if ![source_id] {\n    mutate {\n      add_field => {"source_id" => "default"}\n    }\n  }\n}\n\noutput {\n  elastic_workplace_search {\n    source => "%{[source_id]}"\n  }\n}\n```', true),
		createSnippet('timestamp_destination', 'option', 'timestamp_destination => "${1:timestamp_destination}"', '**[timestamp_destination](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elastic_workplace_search.html#plugins-outputs-elastic_workplace_search-timestamp_destination) option**\n\n- Value type is string\n- There is no default value\n\nWhere to move the value from the @timestamp field.'),
		createSnippet('url', 'option', 'url => "${1:url}"', '**[url](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elastic_workplace_search.html#plugins-outputs-elastic_workplace_search-url) option**\n\n- Value type is string\n- There is no default value\n\nThe value of the API endpoint in the form of a URL.', true)
	],
	'logstash-input-xmpp': [
		createSnippet('host', 'option', 'host => "${1:host}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-xmpp.html#plugins-inputs-xmpp-host) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe xmpp server to connect to. This is optional. If you omit this setting, the host on the user/identity is used. (foo.com for user@foo.com)'),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-xmpp.html#plugins-inputs-xmpp-password) option**\n\n- This is a required setting.\n- Value type is password\n- There is no default value for this setting.\n\nThe xmpp password for the user/identity.', true),
		createSnippet('rooms', 'option', 'rooms => ["${1:room}"]', '**[rooms](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-xmpp.html#plugins-inputs-xmpp-rooms) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nif muc/multi-user-chat required, give the name of the room that you want to join: room@conference.domain/nick'),
		createSnippet('user', 'option', 'user => "${1:user}"', '**[user](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-xmpp.html#plugins-inputs-xmpp-user) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe user or resource ID, like foo@example.com.', true)
	],
	'logstash-output-rabbitmq': [
		createSnippet('arguments', 'option', 'arguments => {$1}', '**[arguments](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-arguments) option**\n\n- Value type is array\n- Default value is {}\n\nExtra queue arguments as an array. To make a RabbitMQ queue mirrored, use: {"x-ha-policy" => "all"}'),
		createSnippet('automatic_recovery', 'option', 'automatic_recovery => ${1|true,false|}', '**[automatic_recovery](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-automatic_recovery) option**\n\n- Value type is boolean\n- Default value is true\n\nSet this to automatically recover from a broken connection. You almost certainly don’t want to override this!!!'),
		createSnippet('connect_retry_interval', 'option', 'connect_retry_interval => ${1:1}', '**[connect_retry_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-connect_retry_interval) option**\n\n- Value type is number\n- Default value is 1\n\nTime in seconds to wait before retrying a connection'),
		createSnippet('connection_timeout', 'option', 'connection_timeout => ${1:123}', '**[connection_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-connection_timeout) option**\n\n- Value type is number\n- There is no default value for this setting.\n\nThe default connection timeout in milliseconds. If not specified the timeout is infinite.'),
		createSnippet('durable', 'option', 'durable => ${1|true,false|}', '**[durable](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-durable) option**\n\n- Value type is boolean\n- Default value is true\n\nIs this exchange durable? (aka; Should it survive a broker restart?)'),
		createSnippet('exchange', 'option', 'exchange => "${1:exchange}"', '**[exchange](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-exchange) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe name of the exchange', true),
		createSnippet('exchange_type', 'option', 'exchange_type => "${1|fanout,direct,topic,x-consistent-hash,x-modulus-hash|}"$0', '**[exchange_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-exchange_type) option**\n\n- This is a required setting.\n- Value can be any of: fanout, direct, topic, x-consistent-hash, x-modulus-hash\n- There is no default value for this setting.\n\nThe exchange type (fanout, topic, direct)', true),
		createSnippet('heartbeat', 'option', 'heartbeat => ${1:123}', '**[heartbeat](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-heartbeat) option**\n\n- Value type is number\n- There is no default value for this setting.\n\nHeartbeat delay in seconds. If unspecified no heartbeats will be sent'),
		createSnippet('host', 'option', 'host => "${1:host}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-host) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nCommon functionality for the rabbitmq input/output RabbitMQ server address(es) host can either be a single host, or a list of hosts i.e. host ⇒ "localhost" or host ⇒ ["host01", "host02]', true),
		createSnippet('key', 'option', 'key => "${1:logstash}"', '**[key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-key) option**\n\n- Value type is string\n- Default value is "logstash"\n\nThe default codec for this plugin is JSON. You can override this to suit your particular needs however. Key to route to by default. Defaults to logstash'),
		createSnippet('message_properties', 'option', 'message_properties => {\n\t"${1:key}" => "${2:value}"\n}', '**[message_properties](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-message_properties) option**\n\n- Value type is hash\n- Default value is {}\n\nAdd properties to be set per-message here, such as content_type, priority. Values can be sprintf templates, whose value for each message will be populated from the event.\n\n**_Example:_**  \n``` ruby\n    message_properties => {\n      "content_type" => "application/json"\n      "priority" => 1\n    }\n```'),
		createSnippet('passive', 'option', 'passive => ${1|false,true|}', '**[passive](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-passive) option**\n\n- Value type is boolean\n- Default value is false\n\nPassive queue creation? Useful for checking queue existance without modifying server state'),
		createSnippet('password', 'option', 'password => "${1:guest}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-password) option**\n\n- Value type is password\n- Default value is "guest"\n\nRabbitMQ password'),
		createSnippet('persistent', 'option', 'persistent => ${1|true,false|}', '**[persistent](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-persistent) option**\n\n- Value type is boolean\n- Default value is true\n\nShould RabbitMQ persist messages to disk?'),
		createSnippet('port', 'option', 'port => ${1:5672}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-port) option**\n\n- Value type is number\n- Default value is 5672\n\nRabbitMQ port to connect on'),
		createSnippet('ssl', 'option', 'ssl => ${1|true,false|}', '**[ssl](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-ssl) option**\n\n- Value type is boolean\n- There is no default value for this setting.\n\nEnable or disable SSL. Note that by default remote certificate verification is off. Specify ssl_certificate_path and ssl_certificate_password if you need certificate verification'),
		createSnippet('ssl_certificate_password', 'option', 'ssl_certificate_password => "${1:ssl_certificate_password}"', '**[ssl_certificate_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-ssl_certificate_password) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nPassword for the encrypted PKCS12 (.p12) certificate file specified in ssl_certificate_path'),
		createSnippet('ssl_certificate_path', 'option', 'ssl_certificate_path => "${1:/path/to/file}"', '**[ssl_certificate_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-ssl_certificate_path) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nPath to an SSL certificate in PKCS12 (.p12) format used for verifying the remote host'),
		createSnippet('ssl_version', 'option', 'ssl_version => "${1:TLSv1.2}"', '**[ssl_version](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-ssl_version) option**\n\n- Value type is string\n- Default value is "TLSv1.2"\n\nVersion of the SSL protocol to use.'),
		createSnippet('user', 'option', 'user => "${1:guest}"', '**[user](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-user) option**\n\n- Value type is string\n- Default value is "guest"\n\nRabbitMQ username'),
		createSnippet('vhost', 'option', 'vhost => "${1:/}"', '**[vhost](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html#plugins-outputs-rabbitmq-vhost) option**\n\n- Value type is string\n- Default value is "/"\n\nThe vhost (virtual host) to use. If you don’t know what this is, leave the default. With the exception of the default vhost ("/"), names of vhosts should not begin with a forward slash.')
	],
	'logstash-filter-urldecode': [
		createSnippet('all_fields', 'option', 'all_fields => ${1|false,true|}', '**[all_fields](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-urldecode.html#plugins-filters-urldecode-all_fields) option**\n\n- Value type is boolean\n- Default value is false\n\nUrldecode all fields'),
		createSnippet('charset', 'option', 'charset => "${1|UTF-8,ASCII-8BIT,US-ASCII,Big5,Big5-HKSCS,Big5-UAO,CP949,Emacs-Mule,EUC-JP,EUC-KR,EUC-TW,GB2312,GB18030,GBK,ISO-8859-1,ISO-8859-2,ISO-8859-3,ISO-8859-4,ISO-8859-5,ISO-8859-6,ISO-8859-7,ISO-8859-8,ISO-8859-9,ISO-8859-10,ISO-8859-11,ISO-8859-13,ISO-8859-14,ISO-8859-15,ISO-8859-16,KOI8-R,KOI8-U,Shift_JIS,UTF-16BE,UTF-16LE,UTF-32BE,UTF-32LE,Windows-31J,Windows-1250,Windows-1251,Windows-1252,IBM437,IBM737,IBM775,CP850,IBM852,CP852,IBM855,CP855,IBM857,IBM860,IBM861,IBM862,IBM863,IBM864,IBM865,IBM866,IBM869,Windows-1258,GB1988,macCentEuro,macCroatian,macCyrillic,macGreek,macIceland,macRoman,macRomania,macThai,macTurkish,macUkraine,CP950,CP951,IBM037,stateless-ISO-2022-JP,eucJP-ms,CP51932,EUC-JIS-2004,GB12345,ISO-2022-JP,ISO-2022-JP-2,CP50220,CP50221,Windows-1256,Windows-1253,Windows-1255,Windows-1254,TIS-620,Windows-874,Windows-1257,MacJapanese,UTF-7,UTF8-MAC,UTF-16,UTF-32,UTF8-DoCoMo,SJIS-DoCoMo,UTF8-KDDI,SJIS-KDDI,ISO-2022-JP-KDDI,stateless-ISO-2022-JP-KDDI,UTF8-SoftBank,SJIS-SoftBank,BINARY,CP437,CP737,CP775,IBM850,CP857,CP860,CP861,CP862,CP863,CP864,CP865,CP866,CP869,CP1258,Big5-HKSCS:2008,ebcdic-cp-us,eucJP,euc-jp-ms,EUC-JISX0213,eucKR,eucTW,EUC-CN,eucCN,CP936,ISO2022-JP,ISO2022-JP2,ISO8859-1,ISO8859-2,ISO8859-3,ISO8859-4,ISO8859-5,ISO8859-6,CP1256,ISO8859-7,CP1253,ISO8859-8,CP1255,ISO8859-9,CP1254,ISO8859-10,ISO8859-11,CP874,ISO8859-13,CP1257,ISO8859-14,ISO8859-15,ISO8859-16,CP878,MacJapan,ASCII,ANSI_X3.4-1968,646,CP65000,CP65001,UTF-8-MAC,UTF-8-HFS,UCS-2BE,UCS-4BE,UCS-4LE,CP932,csWindows31J,SJIS,PCK,CP1250,CP1251,CP1252,external,locale|}"$0', '**[charset](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-urldecode.html#plugins-filters-urldecode-charset) option**\n\n- Value can be any of: ASCII-8BIT, UTF-8, US-ASCII, Big5, Big5-HKSCS, Big5-UAO, CP949, Emacs-Mule, EUC-JP, EUC-KR, EUC-TW, GB2312, GB18030, GBK, ISO-8859-1, ISO-8859-2, ISO-8859-3, ISO-8859-4, ISO-8859-5, ISO-8859-6, ISO-8859-7, ISO-8859-8, ISO-8859-9, ISO-8859-10, ISO-8859-11, ISO-8859-13, ISO-8859-14, ISO-8859-15, ISO-8859-16, KOI8-R, KOI8-U, Shift_JIS, UTF-16BE, UTF-16LE, UTF-32BE, UTF-32LE, Windows-31J, Windows-1250, Windows-1251, Windows-1252, IBM437, IBM737, IBM775, CP850, IBM852, CP852, IBM855, CP855, IBM857, IBM860, IBM861, IBM862, IBM863, IBM864, IBM865, IBM866, IBM869, Windows-1258, GB1988, macCentEuro, macCroatian, macCyrillic, macGreek, macIceland, macRoman, macRomania, macThai, macTurkish, macUkraine, CP950, CP951, IBM037, stateless-ISO-2022-JP, eucJP-ms, CP51932, EUC-JIS-2004, GB12345, ISO-2022-JP, ISO-2022-JP-2, CP50220, CP50221, Windows-1256, Windows-1253, Windows-1255, Windows-1254, TIS-620, Windows-874, Windows-1257, MacJapanese, UTF-7, UTF8-MAC, UTF-16, UTF-32, UTF8-DoCoMo, SJIS-DoCoMo, UTF8-KDDI, SJIS-KDDI, ISO-2022-JP-KDDI, stateless-ISO-2022-JP-KDDI, UTF8-SoftBank, SJIS-SoftBank, BINARY, CP437, CP737, CP775, IBM850, CP857, CP860, CP861, CP862, CP863, CP864, CP865, CP866, CP869, CP1258, Big5-HKSCS:2008, ebcdic-cp-us, eucJP, euc-jp-ms, EUC-JISX0213, eucKR, eucTW, EUC-CN, eucCN, CP936, ISO2022-JP, ISO2022-JP2, ISO8859-1, ISO8859-2, ISO8859-3, ISO8859-4, ISO8859-5, ISO8859-6, CP1256, ISO8859-7, CP1253, ISO8859-8, CP1255, ISO8859-9, CP1254, ISO8859-10, ISO8859-11, CP874, ISO8859-13, CP1257, ISO8859-14, ISO8859-15, ISO8859-16, CP878, MacJapan, ASCII, ANSI_X3.4-1968, 646, CP65000, CP65001, UTF-8-MAC, UTF-8-HFS, UCS-2BE, UCS-4BE, UCS-4LE, CP932, csWindows31J, SJIS, PCK, CP1250, CP1251, CP1252, external, locale\n- Default value is "UTF-8"\n\nThel character encoding used in this filter. Examples include UTF-8 and cp1252'),
		createSnippet('field', 'option', 'field => "${1:message}"', '**[field](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-urldecode.html#plugins-filters-urldecode-field) option**\n\n- Value type is string\n- Default value is "message"\n\nThe field which value is urldecoded'),
		createSnippet('tag_on_failure', 'option', 'tag_on_failure => ["${1:_urldecodefailure}"]', '**[tag_on_failure](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-urldecode.html#plugins-filters-urldecode-tag_on_failure) option**\n\n- Value type is array\n- Default value is ["_urldecodefailure"]\n\nAppend values to the tags field when an exception is thrown')
	],
	'logstash-input-pipe': [
		createSnippet('command', 'option', 'command => "${1:command}"', '**[command](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-pipe.html#plugins-inputs-pipe-command) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nCommand to run and read events from, one line at a time.\n\n**_Example:_**  \n``` ruby\ninput {\n  pipe {\n    command => "echo ¡Hola!"\n  }\n}\n```', true),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-pipe.html#plugins-inputs-pipe-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: uses backwards compatible field names, such as [host] v1, v8: uses fields that are compatible with ECS, such as [host][name]\n- disabled: uses backwards compatible field names, such as [host]\n- v1, v8: uses fields that are compatible with ECS, such as [host][name]\n\nSupported values are:')
	],
	'logstash-filter-syslog_pri': [
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-syslog_pri.html#plugins-filters-syslog_pri-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: does not use ECS-compatible field names (for example, syslog_severity_code for syslog severity) v1, v8: uses fields that are compatible with Elastic Common Schema (for example, [log][syslog][severity][code])\n- disabled: does not use ECS-compatible field names (for example, syslog_severity_code for syslog severity)\n- v1, v8: uses fields that are compatible with Elastic Common Schema (for example, [log][syslog][severity][code])\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:'),
		createSnippet('facility_labels', 'option', 'facility_labels => ["${1:kernel}", "user-level", "mail", "daemon", "security/authorization", "syslogd", "line printer", "network news", "uucp", "clock", "security/authorization", "ftp", "ntp", "log audit", "log alert", "clock", "local0", "local1", "local2", "local3", "local4", "local5", "local6", "local7"]', '**[facility_labels](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-syslog_pri.html#plugins-filters-syslog_pri-facility_labels) option**\n\n- Value type is array\n- Default value is ["kernel", "user-level", "mail", "daemon", "security/authorization", "syslogd", "line printer", "network news", "uucp", "clock", "security/authorization", "ftp", "ntp", "log audit", "log alert", "clock", "local0", "local1", "local2", "local3", "local4", "local5", "local6", "local7"]\n\nLabels for facility levels. This comes from RFC3164.'),
		createSnippet('severity_labels', 'option', 'severity_labels => ["${1:emergency}", "alert", "critical", "error", "warning", "notice", "informational", "debug"]', '**[severity_labels](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-syslog_pri.html#plugins-filters-syslog_pri-severity_labels) option**\n\n- Value type is array\n- Default value is ["emergency", "alert", "critical", "error", "warning", "notice", "informational", "debug"]\n\nLabels for severity levels. This comes from RFC3164.'),
		createSnippet('syslog_pri_field_name', 'option', 'syslog_pri_field_name => "${1:syslog_pri_field_name}"', '**[syslog_pri_field_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-syslog_pri.html#plugins-filters-syslog_pri-syslog_pri_field_name) option**\n\n- Value type is string\n- Default value depends on whether ecs_compatibility is enabled: ECS Compatibility disabled: "syslog_pri" ECS Compatibility enabled: "[log][syslog][priority]"\n- ECS Compatibility disabled: "syslog_pri"\n- ECS Compatibility enabled: "[log][syslog][priority]"\n\nDefault value depends on whether ecs_compatibility is enabled:'),
		createSnippet('use_labels', 'option', 'use_labels => ${1|true,false|}', '**[use_labels](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-syslog_pri.html#plugins-filters-syslog_pri-use_labels) option**\n\n- Value type is boolean\n- Default value is true\n\nset the status to experimental/beta/stable Add human-readable names after parsing severity and facility from PRI')
	],
	'logstash-output-tcp': [
		createSnippet('host', 'option', 'host => "${1:host}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-tcp.html#plugins-outputs-tcp-host) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nWhen mode is server, the address to listen on. When mode is client, the address to connect to.', true),
		createSnippet('mode', 'option', 'mode => "${1|client,server|}"$0', '**[mode](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-tcp.html#plugins-outputs-tcp-mode) option**\n\n- Value can be any of: server, client\n- Default value is "client"\n\nMode to operate in. server listens for client connections, client connects to a server.'),
		createSnippet('port', 'option', 'port => ${1:123}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-tcp.html#plugins-outputs-tcp-port) option**\n\n- This is a required setting.\n- Value type is number\n- There is no default value for this setting.\n\nWhen mode is server, the port to listen on. When mode is client, the port to connect to.', true),
		createSnippet('reconnect_interval', 'option', 'reconnect_interval => ${1:10}', '**[reconnect_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-tcp.html#plugins-outputs-tcp-reconnect_interval) option**\n\n- Value type is number\n- Default value is 10\n\nWhen connect failed,retry interval in sec.'),
		createSnippet('ssl_cacert', 'option', 'ssl_cacert => "${1:/path/to/file}"', '**[ssl_cacert](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-tcp.html#plugins-outputs-tcp-ssl_cacert) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nThe SSL CA certificate, chainfile or CA path. The system CA path is automatically included.'),
		createSnippet('ssl_cert', 'option', 'ssl_cert => "${1:/path/to/file}"', '**[ssl_cert](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-tcp.html#plugins-outputs-tcp-ssl_cert) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nSSL certificate path'),
		createSnippet('ssl_enable', 'option', 'ssl_enable => ${1|false,true|}', '**[ssl_enable](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-tcp.html#plugins-outputs-tcp-ssl_enable) option**\n\n- Value type is boolean\n- Default value is false\n\nEnable SSL (must be set for other ssl_ options to take effect).'),
		createSnippet('ssl_key', 'option', 'ssl_key => "${1:/path/to/file}"', '**[ssl_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-tcp.html#plugins-outputs-tcp-ssl_key) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nSSL key path'),
		createSnippet('ssl_key_passphrase', 'option', 'ssl_key_passphrase => "${1:ssl_key_passphrase}"', '**[ssl_key_passphrase](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-tcp.html#plugins-outputs-tcp-ssl_key_passphrase) option**\n\n- Value type is password\n- Default value is nil\n\nSSL key passphrase'),
		createSnippet('ssl_verify', 'option', 'ssl_verify => ${1|false,true|}', '**[ssl_verify](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-tcp.html#plugins-outputs-tcp-ssl_verify) option**\n\n- Value type is boolean\n- Default value is false\n\nVerify the identity of the other end of the SSL connection against the CA. For input, sets the field sslsubject to that of the client certificate.')
	],
	'logstash-filter-memcached': [
		createSnippet('hosts', 'option', 'hosts => ["${1:localhost}"]', '**[hosts](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-memcached.html#plugins-filters-memcached-hosts) option**\n\n- Value type is array\n- Default value is localhost\n\nThe hosts parameter accepts an array of addresses corresponding to memcached instances.'),
		createSnippet('namespace', 'option', 'namespace => "${1:namespace}"', '**[namespace](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-memcached.html#plugins-filters-memcached-namespace) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nIf specified, prefix all memcached keys with the given string followed by a colon (:); this is useful if all keys being used by this plugin share a common prefix.'),
		createSnippet('get', 'option', 'get => {\n\t"${1:key}" => "${2:value}"\n}', '**[get](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-memcached.html#plugins-filters-memcached-get) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nIf specified, get the values for the given keys from memcached, and store them in the corresponding fields on the event.'),
		createSnippet('set', 'option', 'set => {\n\t"${1:key}" => "${2:value}"\n}', '**[set](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-memcached.html#plugins-filters-memcached-set) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nIf specified, extracts the values from the given event fields, and sets the corresponding keys to those values in memcached with the configured ttl'),
		createSnippet('tag_on_failure', 'option', 'tag_on_failure => "${1:_memcached_failure}"', '**[tag_on_failure](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-memcached.html#plugins-filters-memcached-tag_on_failure) option**\n\n- Value type is string\n- The default value for this setting is _memcached_failure.\n\nWhen a memcached operation causes a runtime exception to be thrown within the plugin, the operation is safely aborted without crashing the plugin, and the event is tagged with the provided value.'),
		createSnippet('ttl', 'option', 'ttl => ${1:0}', '**[ttl](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-memcached.html#plugins-filters-memcached-ttl) option**\n\n- Value type is number\n- The default value is 0 (no expiry)\n\nFor usages of this plugin that persist data to memcached (e.g., set), the time-to-live in seconds')
	],
	'logstash-input-gelf': [
		createSnippet('host', 'option', 'host => "${1:0.0.0.0}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-gelf.html#plugins-inputs-gelf-host) option**\n\n- Value type is string\n- Default value is "0.0.0.0"\n\nThe IP address or hostname to listen on.'),
		createSnippet('use_udp', 'option', 'use_udp => ${1|true,false|}', '**[use_udp](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-gelf.html#plugins-inputs-gelf-use_udp) option**\n\n- Value type is boolean\n- Default value is true\n\nWhether to listen for gelf messages sent over udp'),
		createSnippet('use_tcp', 'option', 'use_tcp => ${1|false,true|}', '**[use_tcp](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-gelf.html#plugins-inputs-gelf-use_tcp) option**\n\n- Value type is boolean\n- Default value is false\n\nWhether to listen for gelf messages sent over tcp'),
		createSnippet('port', 'option', 'port => ${1:12201}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-gelf.html#plugins-inputs-gelf-port) option**\n\n- Value type is number\n- Default value is 12201\n\nThe port to listen on. Remember that ports less than 1024 (privileged ports) may require root to use. port_tcp and port_udp can be used to set a specific port for each protocol.'),
		createSnippet('port_tcp', 'option', 'port_tcp => ${1:123}', '**[port_tcp](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-gelf.html#plugins-inputs-gelf-port_tcp) option**\n\n- Value type is number\n- There is no default value for this setting.\n\nTcp port to listen on. Use port instead of this setting unless you need a different port for udp than tcp'),
		createSnippet('port_udp', 'option', 'port_udp => ${1:123}', '**[port_udp](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-gelf.html#plugins-inputs-gelf-port_udp) option**\n\n- Value type is number\n- There is no default value for this setting.\n\nUdp port to listen on. Use port instead of this setting unless you need a different port for udp than tcp'),
		createSnippet('remap', 'option', 'remap => ${1|true,false|}', '**[remap](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-gelf.html#plugins-inputs-gelf-remap) option**\n\n- Value type is boolean\n- Default value is true\n\nWhether or not to remap the GELF message fields to Logstash event fields or leave them intact.'),
		createSnippet('strip_leading_underscore', 'option', 'strip_leading_underscore => ${1|true,false|}', '**[strip_leading_underscore](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-gelf.html#plugins-inputs-gelf-strip_leading_underscore) option**\n\n- Value type is boolean\n- Default value is true\n\nWhether or not to remove the leading \\\\_ in GELF fields or leave them in place. (Logstash < 1.2 did not remove them by default.). Note that GELF version 1.1 format now requires all non-standard fields to be added as an "additional" field, beginning with an underscore.')
	],
	'logstash-filter-http': [
		createSnippet('body', 'option', 'body => "${1:body}"', '**[body](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-body) option**\n\n- Value type can be a string, number, array or hash\n- There is no default value\n\nThe body of the HTTP request to be sent.'),
		createSnippet('body_format', 'option', 'body_format => "${1:text}"', '**[body_format](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-body_format) option**\n\n- Value type can be either "json" or "text"\n- Default value is "text"\n\nIf set to "json" the body will be serialized as JSON. Otherwise it is sent as is.'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: does not use ECS-compatible field names (for example, response headers target headers field by default) v1, v8: avoids field names that might conflict with Elastic Common Schema (for example, headers are added as metadata)\n- disabled: does not use ECS-compatible field names (for example, response headers target headers field by default)\n- v1, v8: avoids field names that might conflict with Elastic Common Schema (for example, headers are added as metadata)\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:'),
		createSnippet('headers', 'option', 'headers => {\n\t"${1:key}" => "${2:value}"\n}', '**[headers](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-headers) option**\n\n- Value type is hash\n- There is no default value\n\nThe HTTP headers to be sent in the request. Both the names of the headers and their values can reference values from event fields.'),
		createSnippet('query', 'option', 'query => {\n\t"${1:key}" => "${2:value}"\n}', '**[query](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-query) option**\n\n- Value type is hash\n- There is no default value\n\nDefine the query string parameters (key-value pairs) to be sent in the HTTP request.'),
		createSnippet('target_body', 'option', 'target_body => "${1:target_body}"', '**[target_body](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-target_body) option**\n\n- Value type is hash\n- Default value depends on whether ecs_compatibility is enabled: ECS Compatibility disabled: `"[body]" ECS Compatibility enabled: no default value, needs to be specified explicitly\n- ECS Compatibility disabled: `"[body]"\n- ECS Compatibility enabled: no default value, needs to be specified explicitly\n\nDefault value depends on whether ecs_compatibility is enabled:'),
		createSnippet('target_headers', 'option', 'target_headers => "${1:target_headers}"', '**[target_headers](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-target_headers) option**\n\n- Value type is hash\n- Default value depends on whether ecs_compatibility is enabled: ECS Compatibility disabled: "[headers]" ECS Compatibility enabled: "[@metadata][filter][http][response][headers]"\n- ECS Compatibility disabled: "[headers]"\n- ECS Compatibility enabled: "[@metadata][filter][http][response][headers]"\n\nDefault value depends on whether ecs_compatibility is enabled:'),
		createSnippet('url', 'option', 'url => "${1:url}"', '**[url](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-url) option**\n\n- Value type is string\n- There is no default value\n\nThe URL to send the request to. The value can be fetched from event fields.', true),
		createSnippet('verb', 'option', 'verb => "${1:GET}"', '**[verb](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-verb) option**\n\n- Value type can be either "GET", "HEAD", "PATCH", "DELETE", "POST", "PUT"\n- Default value is "GET"\n\nThe verb to be used for the HTTP request.'),
		createSnippet('automatic_retries', 'option', 'automatic_retries => ${1:1}', '**[automatic_retries](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-automatic_retries) option**\n\n- Value type is number\n- Default value is 1\n\nHow many times should the client retry a failing URL. We highly recommend NOT setting this value to zero if keepalive is enabled. Some servers incorrectly end keepalives early requiring a retry! Note: if retry_non_idempotent is set only GET, HEAD, PUT, DELETE, OPTIONS, and TRACE requests will be retried.'),
		createSnippet('cacert', 'option', 'cacert => "${1:/path/to/file}"', '**[cacert](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-cacert) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you need to use a custom X.509 CA (.pem certs) specify the path to that here'),
		createSnippet('client_cert', 'option', 'client_cert => "${1:/path/to/file}"', '**[client_cert](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-client_cert) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you’d like to use a client certificate (note, most people don’t want this) set the path to the x509 cert here'),
		createSnippet('client_key', 'option', 'client_key => "${1:/path/to/file}"', '**[client_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-client_key) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you’re using a client certificate specify the path to the encryption key here'),
		createSnippet('connect_timeout', 'option', 'connect_timeout => ${1:10}', '**[connect_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-connect_timeout) option**\n\n- Value type is number\n- Default value is 10\n\nTimeout (in seconds) to wait for a connection to be established. Default is 10s'),
		createSnippet('cookies', 'option', 'cookies => ${1|true,false|}', '**[cookies](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-cookies) option**\n\n- Value type is boolean\n- Default value is true\n\nEnable cookie support. With this enabled the client will persist cookies across requests as a normal web browser would. Enabled by default'),
		createSnippet('follow_redirects', 'option', 'follow_redirects => ${1|true,false|}', '**[follow_redirects](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-follow_redirects) option**\n\n- Value type is boolean\n- Default value is true\n\nShould redirects be followed? Defaults to true'),
		createSnippet('keepalive', 'option', 'keepalive => ${1|true,false|}', '**[keepalive](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-keepalive) option**\n\n- Value type is boolean\n- Default value is true\n\nTurn this on to enable HTTP keepalive support. We highly recommend setting automatic_retries to at least one with this to fix interactions with broken keepalive implementations.'),
		createSnippet('keystore', 'option', 'keystore => "${1:/path/to/file}"', '**[keystore](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-keystore) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you need to use a custom keystore (.jks) specify that here. This does not work with .pem keys!'),
		createSnippet('keystore_password', 'option', 'keystore_password => "${1:keystore_password}"', '**[keystore_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-keystore_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nSpecify the keystore password here. Note, most .jks files created with keytool require a password!'),
		createSnippet('keystore_type', 'option', 'keystore_type => "${1:JKS}"', '**[keystore_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-keystore_type) option**\n\n- Value type is string\n- Default value is "JKS"\n\nSpecify the keystore type here. One of JKS or PKCS12. Default is JKS'),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nPassword to be used in conjunction with the username for HTTP authentication.'),
		createSnippet('pool_max', 'option', 'pool_max => ${1:50}', '**[pool_max](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-pool_max) option**\n\n- Value type is number\n- Default value is 50\n\nMax number of concurrent connections. Defaults to 50'),
		createSnippet('pool_max_per_route', 'option', 'pool_max_per_route => ${1:25}', '**[pool_max_per_route](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-pool_max_per_route) option**\n\n- Value type is number\n- Default value is 25\n\nMax number of concurrent connections to a single host. Defaults to 25'),
		createSnippet('proxy', 'option', 'proxy => "${1:proxy}"', '**[proxy](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-proxy) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nIf you’d like to use an HTTP proxy . This supports multiple configuration syntaxes:'),
		createSnippet('request_timeout', 'option', 'request_timeout => ${1:60}', '**[request_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-request_timeout) option**\n\n- Value type is number\n- Default value is 60\n\nTimeout (in seconds) for the entire request.'),
		createSnippet('retry_non_idempotent', 'option', 'retry_non_idempotent => ${1|false,true|}', '**[retry_non_idempotent](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-retry_non_idempotent) option**\n\n- Value type is boolean\n- Default value is false\n\nIf automatic_retries is enabled this will cause non-idempotent HTTP verbs (such as POST) to be retried.'),
		createSnippet('socket_timeout', 'option', 'socket_timeout => ${1:10}', '**[socket_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-socket_timeout) option**\n\n- Value type is number\n- Default value is 10\n\nTimeout (in seconds) to wait for data on the socket. Default is 10s'),
		createSnippet('truststore', 'option', 'truststore => "${1:/path/to/file}"', '**[truststore](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-truststore) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you need to use a custom truststore (.jks) specify that here. This does not work with .pem certs!'),
		createSnippet('truststore_password', 'option', 'truststore_password => "${1:truststore_password}"', '**[truststore_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-truststore_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nSpecify the truststore password here. Note, most .jks files created with keytool require a password!'),
		createSnippet('truststore_type', 'option', 'truststore_type => "${1:JKS}"', '**[truststore_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-truststore_type) option**\n\n- Value type is string\n- Default value is "JKS"\n\nSpecify the truststore type here. One of JKS or PKCS12. Default is JKS'),
		createSnippet('user', 'option', 'user => "${1:user}"', '**[user](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-user) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nUsername to use with HTTP authentication for ALL requests. Note that you can also set this per-URL. If you set this you must also set the password option.'),
		createSnippet('validate_after_inactivity', 'option', 'validate_after_inactivity => ${1:200}', '**[validate_after_inactivity](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-http.html#plugins-filters-http-validate_after_inactivity) option**\n\n- Value type is number\n- Default value is 200\n\nHow long to wait before checking for a stale connection to determine if a keepalive request is needed. Consider setting this value lower than the default, possibly to 0, if you get connection errors regularly.')
	],
	'logstash-input-s3-sns-sqs': [
	],
	'logstash-codec-nmap': [
		createSnippet('emit_hosts', 'option', 'emit_hosts => ${1|true,false|}', '**[emit_hosts](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-nmap.html#plugins-codecs-nmap-emit_hosts) option**\n\n- Value type is boolean\n- Default value is true\n\nEmit all host data as a nested document (including ports + traceroutes) with the type nmap_fullscan'),
		createSnippet('emit_ports', 'option', 'emit_ports => ${1|true,false|}', '**[emit_ports](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-nmap.html#plugins-codecs-nmap-emit_ports) option**\n\n- Value type is boolean\n- Default value is true\n\nEmit each port as a separate document with type nmap_port'),
		createSnippet('emit_scan_metadata', 'option', 'emit_scan_metadata => ${1|true,false|}', '**[emit_scan_metadata](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-nmap.html#plugins-codecs-nmap-emit_scan_metadata) option**\n\n- Value type is boolean\n- Default value is true\n\nEmit scan metadata'),
		createSnippet('emit_traceroute_links', 'option', 'emit_traceroute_links => ${1|true,false|}', '**[emit_traceroute_links](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-nmap.html#plugins-codecs-nmap-emit_traceroute_links) option**\n\n- Value type is boolean\n- Default value is true\n\nEmit each hop_tuple of the traceroute with type nmap_traceroute_link')
	],
	'logstash-output-statsd': [
		createSnippet('count', 'option', 'count => {\n\t"${1:key}" => "${2:value}"\n}', '**[count](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-statsd.html#plugins-outputs-statsd-count) option**\n\n- Value type is hash\n- Default value is {}\n\nA count metric. metric_name => count as hash. %{fieldname} substitutions are allowed in the metric names.'),
		createSnippet('decrement', 'option', 'decrement => ["${1:decrement}"]', '**[decrement](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-statsd.html#plugins-outputs-statsd-decrement) option**\n\n- Value type is array\n- Default value is []\n\nA decrement metric. Metric names as array. %{fieldname} substitutions are allowed in the metric names.'),
		createSnippet('gauge', 'option', 'gauge => {\n\t"${1:key}" => "${2:value}"\n}', '**[gauge](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-statsd.html#plugins-outputs-statsd-gauge) option**\n\n- Value type is hash\n- Default value is {}\n\nA gauge metric. metric_name => gauge as hash. %{fieldname} substitutions are allowed in the metric names.'),
		createSnippet('host', 'option', 'host => "${1:localhost}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-statsd.html#plugins-outputs-statsd-host) option**\n\n- Value type is string\n- Default value is "localhost"\n\nThe hostname or IP address of the statsd server.'),
		createSnippet('increment', 'option', 'increment => ["${1:increment}"]', '**[increment](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-statsd.html#plugins-outputs-statsd-increment) option**\n\n- Value type is array\n- Default value is []\n\nAn increment metric. Metric names as array. %{fieldname} substitutions are allowed in the metric names.'),
		createSnippet('namespace', 'option', 'namespace => "${1:logstash}"', '**[namespace](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-statsd.html#plugins-outputs-statsd-namespace) option**\n\n- Value type is string\n- Default value is "logstash"\n\nThe statsd namespace to use for this metric. %{fieldname} substitutions are allowed.'),
		createSnippet('port', 'option', 'port => ${1:8125}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-statsd.html#plugins-outputs-statsd-port) option**\n\n- Value type is number\n- Default value is 8125\n\nThe port to connect to on your statsd server.'),
		createSnippet('sample_rate', 'option', 'sample_rate => ${1:1}', '**[sample_rate](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-statsd.html#plugins-outputs-statsd-sample_rate) option**\n\n- Value type is number\n- Default value is 1\n\nThe sample rate for the metric.'),
		createSnippet('sender', 'option', 'sender => "${1:%{host\\}}"', '**[sender](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-statsd.html#plugins-outputs-statsd-sender) option**\n\n- Value type is string\n- Default value is "%{host}"\n\nThe name of the sender. Dots will be replaced with underscores. %{fieldname} substitutions are allowed.'),
		createSnippet('set', 'option', 'set => {\n\t"${1:key}" => "${2:value}"\n}', '**[set](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-statsd.html#plugins-outputs-statsd-set) option**\n\n- Value type is hash\n- Default value is {}\n\nA set metric. metric_name => "string" to append as hash. %{fieldname} substitutions are allowed in the metric names.'),
		createSnippet('timing', 'option', 'timing => {\n\t"${1:key}" => "${2:value}"\n}', '**[timing](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-statsd.html#plugins-outputs-statsd-timing) option**\n\n- Value type is hash\n- Default value is {}\n\nA timing metric. metric_name => duration as hash. %{fieldname} substitutions are allowed in the metric names.')
	],
	'logstash-filter-de_dot': [
		createSnippet('fields', 'option', 'fields => ["${1:field}"]', '**[fields](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-de_dot.html#plugins-filters-de_dot-fields) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nThe fields array should contain a list of known fields to act on. If undefined, all top-level fields will be checked. Sub-fields must be manually specified in the array. For example: ["field.suffix","[foo][bar.suffix]"] will result in "field_suffix" and nested or sub field ["foo"]["bar_suffix"]'),
		createSnippet('nested', 'option', 'nested => ${1|false,true|}', '**[nested](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-de_dot.html#plugins-filters-de_dot-nested) option**\n\n- Value type is boolean\n- Default value is false\n\nIf nested is true, then create sub-fields instead of replacing dots with a different separator.'),
		createSnippet('separator', 'option', 'separator => "${1:_}"', '**[separator](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-de_dot.html#plugins-filters-de_dot-separator) option**\n\n- Value type is string\n- Default value is "_"\n\nReplace dots with this value.')
	],
	'logstash-input-jms': [
		createSnippet('broker_url', 'option', 'broker_url => "${1:broker_url}"', '**[broker_url](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-broker_url) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nUrl to use when connecting to the JMS provider. This is only relevant for non-JNDI configurations.'),
		createSnippet('destination', 'option', 'destination => "${1:destination}"', '**[destination](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-destination) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nName of the destination queue or topic to use.', true),
		createSnippet('durable_subscriber', 'option', 'durable_subscriber => ${1|true,false|}', '**[durable_subscriber](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-durable_subscriber) option**\n\n- Value type is boolean\n- This is false by default\n- Requires pub_sub to be true\n\nSetting this value to true will make subscriptions to topics "durable", which allowing messages that arrived on the specified topic while Logstash is not running to still be read. Without setting this value, any messages sent to a topic while Logstash is not actively listening will be lost. A durable subscriber specifies a unique identity consisting of the topic (destination), the client id (durable_subscriber_client_id) and subscriber name (durable_subscriber_subscriber_name). See your JMS Provider documentation for any further requirements/limitations around these settings.'),
		createSnippet('durable_subscriber_client_id', 'option', 'durable_subscriber_client_id => "${1:durable_subscriber_client_id}"', '**[durable_subscriber_client_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-durable_subscriber_client_id) option**\n\n- Value type is string\n- If durable_subscriber is set, the default value for this setting is Logstash, otherwise this setting has no effect\n\nThis represents the value of the client ID for a durable subscribtion, and is only used if durable_subscriber is set to true.'),
		createSnippet('durable_subscriber_name', 'option', 'durable_subscriber_name => "${1:durable_subscriber_name}"', '**[durable_subscriber_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-durable_subscriber_name) option**\n\n- Value type is string\n- If durable_subscriber is set, the default value for this setting will be the same value as the destination setting, otherwise this setting has no effect.\n\nThis represents the value of the subscriber name for a durable subscribtion, and is only used if durable_subscriber is set to true. Please consult your JMS Provider documentation for constraints and requirements for this setting.'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: does not use ECS-compatible field names (fields might be set at the root of the event) v1, v8: avoids field names that might conflict with Elastic Common Schema (for example, JMS specific properties)\n- disabled: does not use ECS-compatible field names (fields might be set at the root of the event)\n- v1, v8: avoids field names that might conflict with Elastic Common Schema (for example, JMS specific properties)\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:'),
		createSnippet('factory', 'option', 'factory => "${1:factory}"', '**[factory](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-factory) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nFull name (including package name) of Java connection factory used to create a connection with your JMS provider.'),
		createSnippet('factory_settings', 'option', 'factory_settings => {\n\t"${1:key}" => "${2:value}"\n}', '**[factory_settings](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-factory_settings) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nHash of implementation specific configuration values to set on the connection factory of the JMS provider. Each JMS Provider will have its own set of parameters that can be used here. These parameters are mapped to set methods on the provided connection factory, and can be supplied in either snake or camel case. For example, a hash including exclusive_consumer => true would call setExclusiveConsumer(true) on the supplied connection factory. See your JMS provider documentation for implementation specific details.'),
		createSnippet('headers_target', 'option', 'headers_target => "${1:headers_target}"', '**[headers_target](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-headers_target) option**\n\n- Value type is string\n- Default value depends on whether ecs_compatibility is enabled: ECS Compatibility disabled: no default value for this setting ECS Compatibility enabled: `"[@metadata][input][jms][headers]"\n- ECS Compatibility disabled: no default value for this setting\n- ECS Compatibility enabled: `"[@metadata][input][jms][headers]"\n\nDefault value depends on whether ecs_compatibility is enabled:'),
		createSnippet('include_body', 'option', 'include_body => ${1|true,false|}', '**[include_body](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-include_body) option**\n\n- Value type is boolean\n- Default value is true\n\nInclude JMS Message Body in the event. Supports TextMessage, MapMessage and BytesMessage.'),
		createSnippet('include_header', 'option', 'include_header => ${1|true,false|}', '**[include_header](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-include_header) option**\n\n- Value type is boolean\n- This option is deprecated\n\nNote: This option is deprecated and it will be removed in the next major version of Logstash. Use include_headers instead.'),
		createSnippet('include_headers', 'option', 'include_headers => ${1|true,false|}', '**[include_headers](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-include_headers) option**\n\n- Value type is boolean\n- Default value is true\n\nA JMS message has three parts:'),
		createSnippet('include_properties', 'option', 'include_properties => ${1|true,false|}', '**[include_properties](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-include_properties) option**\n\n- Value type is boolean\n- Default value is true\n\nInclude JMS Message Properties Field values in the event.'),
		createSnippet('interval', 'option', 'interval => ${1:10}', '**[interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-interval) option**\n\n- Value type is number\n- Default value is 10\n\nPolling interval in seconds. This is the time sleeping between asks to a consumed Queue. This parameter has non influence in the case of a subcribed Topic.'),
		createSnippet('jndi_context', 'option', 'jndi_context => {\n\t"${1:key}" => "${2:value}"\n}', '**[jndi_context](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-jndi_context) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nOnly used if using JNDI lookup. Key value pairs to determine how to connect the JMS message brokers if JNDI is being used. Consult your JMS provider documentation for the correct values to use here.'),
		createSnippet('jndi_name', 'option', 'jndi_name => "${1:jndi_name}"', '**[jndi_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-jndi_name) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nOnly used if using JNDI lookup. Name of JNDI entry at which the Factory can be found.'),
		createSnippet('keystore', 'option', 'keystore => "${1:/path/to/file}"', '**[keystore](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-keystore) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you need to use a custom keystore (.jks) specify it here. This does not work with .pem keys'),
		createSnippet('keystore_password', 'option', 'keystore_password => "${1:keystore_password}"', '**[keystore_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-keystore_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nSpecify the keystore password here. Note, most .jks files created with keytool require a password'),
		createSnippet('oracle_aq_buffered_messages', 'option', 'oracle_aq_buffered_messages => ${1|false,true|}', '**[oracle_aq_buffered_messages](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-oracle_aq_buffered_messages) option**\n\n- Value type is boolean\n- Default value is false\n\nReceive Oracle AQ buffered messages. In this mode persistent Oracle AQ JMS messages will not be received. Only for use with Oracle AQ'),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-password) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nPassword to use when connecting to the JMS provider.'),
		createSnippet('properties_target', 'option', 'properties_target => "${1:properties_target}"', '**[properties_target](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-properties_target) option**\n\n- Value type is string\n- Default value depends on whether ecs_compatibility is enabled: ECS Compatibility disabled: no default value for this setting ECS Compatibility enabled: `"[@metadata][input][jms][properties]"\n- ECS Compatibility disabled: no default value for this setting\n- ECS Compatibility enabled: `"[@metadata][input][jms][properties]"\n\nDefault value depends on whether ecs_compatibility is enabled:'),
		createSnippet('pub_sub', 'option', 'pub_sub => ${1|false,true|}', '**[pub_sub](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-pub_sub) option**\n\n- Value type is boolean\n- Default value is false\n\nIf pub-sub (topic) style should be used. Note that if pub_sub is set to true, threads must be set to 1.'),
		createSnippet('require_jars', 'option', 'require_jars => ["${1:require_jar}"]', '**[require_jars](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-require_jars) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nIf you do not use an yaml configuration use either the factory or jndi_name. An optional array of Jar file names to load for the specified JMS provider. By using this option it is not necessary to put all the JMS Provider specific jar files into the java CLASSPATH prior to starting Logstash.'),
		createSnippet('runner', 'option', 'runner => "${1:runner}"', '**[runner](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-runner) option**\n\n- DEPRECATED WARNING: This configuration item is deprecated and may not be available in future versions.'),
		createSnippet('selector', 'option', 'selector => "${1:selector}"', '**[selector](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-selector) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nJMS message selector. Use in conjunctions with message headers or properties to filter messages to be processed. Only messages that match the query specified here will be processed. Check with your JMS provider for the correct JMS message selector syntax.'),
		createSnippet('skip_headers', 'option', 'skip_headers => ["${1:skip_header}"]', '**[skip_headers](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-skip_headers) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nIf include_headers is set, a list of headers to skip processing on can be specified here.'),
		createSnippet('skip_properties', 'option', 'skip_properties => ["${1:skip_propertie}"]', '**[skip_properties](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-skip_properties) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nIf include_properties is set, a list of properties to skip processing on can be specified here.'),
		createSnippet('system_properties', 'option', 'system_properties => {\n\t"${1:key}" => "${2:value}"\n}', '**[system_properties](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-system_properties) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nAny System properties that the JMS provider requires can be set either in a Hash here, or in jvm.options'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-target) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe name of the field to assign MapMessage data into. If not specified data will be stored in the root of the event.'),
		createSnippet('threads', 'option', 'threads => ${1:1}', '**[threads](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-threads) option**\n\n- Value type is number\n- Default value is 1\n\nIf pub_sub is set to true, this value must be 1. A configuration error will be thrown otherwise!'),
		createSnippet('timeout', 'option', 'timeout => ${1:60}', '**[timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-timeout) option**\n\n- Value type is number\n- Default value is 60\n\nInitial connection timeout in seconds.'),
		createSnippet('truststore', 'option', 'truststore => "${1:/path/to/file}"', '**[truststore](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-truststore) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you need to use a custom truststore (.jks) specify it here. This does not work with .pem certs.'),
		createSnippet('truststore_password', 'option', 'truststore_password => "${1:truststore_password}"', '**[truststore_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-truststore_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nSpecify the truststore password here.'),
		createSnippet('use_jms_timestamp', 'option', 'use_jms_timestamp => ${1|false,true|}', '**[use_jms_timestamp](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-use_jms_timestamp) option**\n\n- Value type is boolean\n- Default value is false\n\nConvert the JMSTimestamp header field to the @timestamp value of the event'),
		createSnippet('username', 'option', 'username => "${1:username}"', '**[username](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-username) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nUsername to use for connecting to JMS provider.'),
		createSnippet('yaml_file', 'option', 'yaml_file => "${1:yaml_file}"', '**[yaml_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-yaml_file) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nYaml config file'),
		createSnippet('yaml_section', 'option', 'yaml_section => "${1:yaml_section}"', '**[yaml_section](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html#plugins-inputs-jms-yaml_section) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nYaml config file section name For some known examples, see jms.yml examples.')
	],
	'logstash-filter-jdbc_streaming': [
		createSnippet('cache_expiration', 'option', 'cache_expiration => ${1:5.0}', '**[cache_expiration](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-cache_expiration) option**\n\n- Value type is number\n- Default value is 5.0\n\nThe minimum number of seconds any entry should remain in the cache. Defaults to 5 seconds.'),
		createSnippet('cache_size', 'option', 'cache_size => ${1:500}', '**[cache_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-cache_size) option**\n\n- Value type is number\n- Default value is 500\n\nThe maximum number of cache entries that will be stored. Defaults to 500 entries. The least recently used entry will be evicted.'),
		createSnippet('default_hash', 'option', 'default_hash => {\n\t"${1:key}" => "${2:value}"\n}', '**[default_hash](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-default_hash) option**\n\n- Value type is hash\n- Default value is {}\n\nDefine a default object to use when lookup fails to return a matching row. Ensure that the key names of this object match the columns from the statement.'),
		createSnippet('jdbc_connection_string', 'option', 'jdbc_connection_string => "${1:jdbc_connection_string}"', '**[jdbc_connection_string](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-jdbc_connection_string) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nJDBC connection string', true),
		createSnippet('jdbc_driver_class', 'option', 'jdbc_driver_class => "${1:jdbc_driver_class}"', '**[jdbc_driver_class](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-jdbc_driver_class) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nJDBC driver class to load, for example "oracle.jdbc.OracleDriver" or "org.apache.derby.jdbc.ClientDriver"', true),
		createSnippet('jdbc_driver_library', 'option', 'jdbc_driver_library => "${1:/path/to/file}"', '**[jdbc_driver_library](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-jdbc_driver_library) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nJDBC driver library path to third party driver library.'),
		createSnippet('jdbc_password', 'option', 'jdbc_password => "${1:jdbc_password}"', '**[jdbc_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-jdbc_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nJDBC password'),
		createSnippet('jdbc_user', 'option', 'jdbc_user => "${1:jdbc_user}"', '**[jdbc_user](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-jdbc_user) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nJDBC user'),
		createSnippet('jdbc_validate_connection', 'option', 'jdbc_validate_connection => ${1|false,true|}', '**[jdbc_validate_connection](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-jdbc_validate_connection) option**\n\n- Value type is boolean\n- Default value is false\n\nConnection pool configuration. Validate connection before use.'),
		createSnippet('jdbc_validation_timeout', 'option', 'jdbc_validation_timeout => ${1:3600}', '**[jdbc_validation_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-jdbc_validation_timeout) option**\n\n- Value type is number\n- Default value is 3600\n\nConnection pool configuration. How often to validate a connection (in seconds).'),
		createSnippet('parameters', 'option', 'parameters => {\n\t"${1:key}" => "${2:value}"\n}', '**[parameters](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-parameters) option**\n\n- Value type is hash\n- Default value is {}\n\nHash of query parameter, for example { "id" => "id_field" }.'),
		createSnippet('prepared_statement_bind_values', 'option', 'prepared_statement_bind_values => ["${1:prepared_statement_bind_value}"]', '**[prepared_statement_bind_values](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-prepared_statement_bind_values) option**\n\n- Value type is array\n- Default value is []\n\nArray of bind values for the prepared statement. Use field references and constants. See the section on prepared_statements for more info.'),
		createSnippet('prepared_statement_name', 'option', 'prepared_statement_name => "${1:prepared_statement_name}"', '**[prepared_statement_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-prepared_statement_name) option**\n\n- Value type is string\n- Default value is ""\n\nName given to the prepared statement. It must be unique in your config and in the database. You need to supply this if use_prepared_statements is true.'),
		createSnippet('prepared_statement_warn_on_constant_usage', 'option', 'prepared_statement_warn_on_constant_usage => ${1|true,false|}', '**[prepared_statement_warn_on_constant_usage](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-prepared_statement_warn_on_constant_usage) option**\n\n- Value type is boolean\n- Default value is true\n\nA flag that controls whether a warning is logged if, in prepared_statement_bind_values, a String constant is detected that might be intended as a field reference.'),
		createSnippet('sequel_opts', 'option', 'sequel_opts => {\n\t"${1:key}" => "${2:value}"\n}', '**[sequel_opts](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-sequel_opts) option**\n\n- Value type is hash\n- Default value is {}\n\nGeneral/Vendor-specific Sequel configuration options'),
		createSnippet('statement', 'option', 'statement => "${1:statement}"', '**[statement](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-statement) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nStatement to execute. To use parameters, use named parameter syntax, for example "SELECT * FROM MYTABLE WHERE ID = :id".', true),
		createSnippet('tag_on_default_use', 'option', 'tag_on_default_use => ["${1:_jdbcstreamingdefaultsused}"]', '**[tag_on_default_use](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-tag_on_default_use) option**\n\n- Value type is array\n- Default value is ["_jdbcstreamingdefaultsused"]\n\nAppend values to the tags field if no record was found and default values were used.'),
		createSnippet('tag_on_failure', 'option', 'tag_on_failure => ["${1:_jdbcstreamingfailure}"]', '**[tag_on_failure](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-tag_on_failure) option**\n\n- Value type is array\n- Default value is ["_jdbcstreamingfailure"]\n\nAppend values to the tags field if sql error occurred.'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-target) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nDefine the target field to store the extracted result(s). Field is overwritten if exists.', true),
		createSnippet('use_cache', 'option', 'use_cache => ${1|true,false|}', '**[use_cache](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-use_cache) option**\n\n- Value type is boolean\n- Default value is true\n\nEnable or disable caching, boolean true or false. Defaults to true.'),
		createSnippet('use_prepared_statements', 'option', 'use_prepared_statements => ${1|false,true|}', '**[use_prepared_statements](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_streaming.html#plugins-filters-jdbc_streaming-use_prepared_statements) option**\n\n- Value type is boolean\n- Default value is false\n\nWhen set to true, enables prepare statement usage')
	],
	'logstash-input-jmx': [
		createSnippet('nb_thread', 'option', 'nb_thread => ${1:4}', '**[nb_thread](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jmx.html#plugins-inputs-jmx-nb_thread) option**\n\n- Value type is number\n- Default value is 4\n\nIndicate number of thread launched to retrieve metrics'),
		createSnippet('path', 'option', 'path => "${1:path}"', '**[path](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jmx.html#plugins-inputs-jmx-path) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nPath where json conf files are stored', true),
		createSnippet('polling_frequency', 'option', 'polling_frequency => ${1:60}', '**[polling_frequency](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jmx.html#plugins-inputs-jmx-polling_frequency) option**\n\n- Value type is number\n- Default value is 60\n\nIndicate interval between two jmx metrics retrieval (in s)')
	],
	'logstash-codec-dots': [
	],
	'logstash-output-sqs': [
		createSnippet('access_key_id', 'option', 'access_key_id => "${1:access_key_id}"', '**[access_key_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sqs.html#plugins-outputs-sqs-access_key_id) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThis plugin uses the AWS SDK and supports several ways to get credentials, which will be tried in this order:'),
		createSnippet('aws_credentials_file', 'option', 'aws_credentials_file => "${1:aws_credentials_file}"', '**[aws_credentials_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sqs.html#plugins-outputs-sqs-aws_credentials_file) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nPath to YAML file containing a hash of AWS credentials. This file will only be loaded if access_key_id and secret_access_key aren’t set. The contents of the file should look like this:'),
		createSnippet('batch_events', 'option', 'batch_events => ${1:10}', '**[batch_events](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sqs.html#plugins-outputs-sqs-batch_events) option**\n\n- Value type is number\n- Default value is 10\n\nThe number of events to be sent in each batch. Set this to 1 to disable the batch sending of messages.'),
		createSnippet('endpoint', 'option', 'endpoint => "${1:endpoint}"', '**[endpoint](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sqs.html#plugins-outputs-sqs-endpoint) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe endpoint to connect to. By default it is constructed using the value of region. This is useful when connecting to S3 compatible services, but beware that these aren’t guaranteed to work correctly with the AWS SDK.'),
		createSnippet('message_max_size', 'option', 'message_max_size => "${1:256KiB}"', '**[message_max_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sqs.html#plugins-outputs-sqs-message_max_size) option**\n\n- Value type is bytes\n- Default value is "256KiB"\n\nThe maximum number of bytes for any message sent to SQS. Messages exceeding this size will be dropped. See http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/limits-messages.html.'),
		createSnippet('proxy_uri', 'option', 'proxy_uri => "${1:proxy_uri}"', '**[proxy_uri](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sqs.html#plugins-outputs-sqs-proxy_uri) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nURI to proxy server if required'),
		createSnippet('queue', 'option', 'queue => "${1:queue}"', '**[queue](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sqs.html#plugins-outputs-sqs-queue) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe name of the target SQS queue. Note that this is just the name of the queue, not the URL or ARN.', true),
		createSnippet('region', 'option', 'region => "${1:us-east-1}"', '**[region](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sqs.html#plugins-outputs-sqs-region) option**\n\n- Value type is string\n- Default value is "us-east-1"\n\nThe AWS Region'),
		createSnippet('role_arn', 'option', 'role_arn => "${1:role_arn}"', '**[role_arn](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sqs.html#plugins-outputs-sqs-role_arn) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS IAM Role to assume, if any. This is used to generate temporary credentials, typically for cross-account access. See the AssumeRole API documentation for more information.'),
		createSnippet('role_session_name', 'option', 'role_session_name => "${1:logstash}"', '**[role_session_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sqs.html#plugins-outputs-sqs-role_session_name) option**\n\n- Value type is string\n- Default value is "logstash"\n\nSession name to use when assuming an IAM role.'),
		createSnippet('secret_access_key', 'option', 'secret_access_key => "${1:secret_access_key}"', '**[secret_access_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sqs.html#plugins-outputs-sqs-secret_access_key) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS Secret Access Key'),
		createSnippet('session_token', 'option', 'session_token => "${1:session_token}"', '**[session_token](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sqs.html#plugins-outputs-sqs-session_token) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS Session token for temporary credential')
	],
	'logstash-input-google_cloud_storage': [
		createSnippet('bucket_id', 'option', 'bucket_id => "${1:bucket_id}"', '**[bucket_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-google_cloud_storage.html#plugins-inputs-google_cloud_storage-bucket_id) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe bucket containing your log files.', true),
		createSnippet('json_key_file', 'option', 'json_key_file => "${1:/path/to/file}"', '**[json_key_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-google_cloud_storage.html#plugins-inputs-google_cloud_storage-json_key_file) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nThe path to the key to authenticate your user to the bucket. This service user should have the storage.objects.update permission so it can create metadata on the object preventing it from being scanned multiple times.'),
		createSnippet('interval', 'option', 'interval => ${1:123}', '**[interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-google_cloud_storage.html#plugins-inputs-google_cloud_storage-interval) option**\n\n- Value type is number\n- Default is: 60\n\nThe number of seconds between looking for new files in your bucket.'),
		createSnippet('file_matches', 'option', 'file_matches => "${1:file_matches}"', '**[file_matches](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-google_cloud_storage.html#plugins-inputs-google_cloud_storage-file_matches) option**\n\n- Value type is string\n- Default is: .*\\\\.log(\\\\.gz)?\n\nA regex pattern to filter files. Only files with names matching this will be considered. All files match by default.'),
		createSnippet('file_exclude', 'option', 'file_exclude => "${1:file_exclude}"', '**[file_exclude](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-google_cloud_storage.html#plugins-inputs-google_cloud_storage-file_exclude) option**\n\n- Value type is string\n- Default is: ^$\n\nAny files matching this regex are excluded from processing. No files are excluded by default.'),
		createSnippet('metadata_key', 'option', 'metadata_key => "${1:metadata_key}"', '**[metadata_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-google_cloud_storage.html#plugins-inputs-google_cloud_storage-metadata_key) option**\n\n- Value type is string\n- Default is: x-goog-meta-ls-gcs-input\n\nThis key will be set on the objects after they’ve been processed by the plugin. That way you can stop the plugin and not upload files again or prevent them from being uploaded by setting the field manually.'),
		createSnippet('processed_db_path', 'option', 'processed_db_path => "${1:/path/to/file}"', '**[processed_db_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-google_cloud_storage.html#plugins-inputs-google_cloud_storage-processed_db_path) option**\n\n- Value type is path\n- Default is: LOGSTASH_DATA/plugins/inputs/google_cloud_storage/db.\n\nIf set, the plugin will store the list of processed files locally. This allows you to create a service account for the plugin that does not have write permissions. However, the data will not be shared across multiple running instances of Logstash.'),
		createSnippet('delete', 'option', 'delete => ${1|true,false|}', '**[delete](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-google_cloud_storage.html#plugins-inputs-google_cloud_storage-delete) option**\n\n- Value type is boolean\n- Default is: false\n\nShould the log file be deleted after its contents have been updated?'),
		createSnippet('unpack_gzip', 'option', 'unpack_gzip => ${1|true,false|}', '**[unpack_gzip](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-google_cloud_storage.html#plugins-inputs-google_cloud_storage-unpack_gzip) option**\n\n- Value type is boolean\n- Default is: true\n\nIf set to true, files ending in .gz are decompressed before they’re parsed by the codec. The file will be skipped if it has the suffix, but can’t be opened as a gzip, e.g. if it has a bad magic number.')
	],
	'logstash-input-relp': [
		createSnippet('host', 'option', 'host => "${1:0.0.0.0}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-relp.html#plugins-inputs-relp-host) option**\n\n- Value type is string\n- Default value is "0.0.0.0"\n\nThe address to listen on.'),
		createSnippet('port', 'option', 'port => ${1:123}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-relp.html#plugins-inputs-relp-port) option**\n\n- This is a required setting.\n- Value type is number\n- There is no default value for this setting.\n\nThe port to listen on.', true),
		createSnippet('ssl_cacert', 'option', 'ssl_cacert => "${1:/path/to/file}"', '**[ssl_cacert](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-relp.html#plugins-inputs-relp-ssl_cacert) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nThe SSL CA certificate, chainfile or CA path. The system CA path is automatically included.'),
		createSnippet('ssl_cert', 'option', 'ssl_cert => "${1:/path/to/file}"', '**[ssl_cert](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-relp.html#plugins-inputs-relp-ssl_cert) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nSSL certificate path'),
		createSnippet('ssl_enable', 'option', 'ssl_enable => ${1|false,true|}', '**[ssl_enable](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-relp.html#plugins-inputs-relp-ssl_enable) option**\n\n- Value type is boolean\n- Default value is false\n\nEnable SSL (must be set for other ssl_ options to take effect).'),
		createSnippet('ssl_key', 'option', 'ssl_key => "${1:/path/to/file}"', '**[ssl_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-relp.html#plugins-inputs-relp-ssl_key) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nSSL key path'),
		createSnippet('ssl_key_passphrase', 'option', 'ssl_key_passphrase => "${1:ssl_key_passphrase}"', '**[ssl_key_passphrase](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-relp.html#plugins-inputs-relp-ssl_key_passphrase) option**\n\n- Value type is password\n- Default value is nil\n\nSSL key passphrase'),
		createSnippet('ssl_verify', 'option', 'ssl_verify => ${1|true,false|}', '**[ssl_verify](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-relp.html#plugins-inputs-relp-ssl_verify) option**\n\n- Value type is boolean\n- Default value is true\n\nVerify the identity of the other end of the SSL connection against the CA. For input, sets the field sslsubject to that of the client certificate.')
	],
	'logstash-filter-jdbc_static': [
		createSnippet('jdbc_connection_string', 'option', 'jdbc_connection_string => "${1:jdbc_connection_string}"', '**[jdbc_connection_string](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_static.html#plugins-filters-jdbc_static-jdbc_connection_string) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nJDBC connection string.', true),
		createSnippet('jdbc_driver_class', 'option', 'jdbc_driver_class => "${1:jdbc_driver_class}"', '**[jdbc_driver_class](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_static.html#plugins-filters-jdbc_static-jdbc_driver_class) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nJDBC driver class to load, for example, "org.apache.derby.jdbc.ClientDriver".', true),
		createSnippet('jdbc_driver_library', 'option', 'jdbc_driver_library => "${1:/path/to/file}"', '**[jdbc_driver_library](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_static.html#plugins-filters-jdbc_static-jdbc_driver_library) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nJDBC driver library path to third-party driver library. Use comma separated paths in one string if you need multiple libraries.'),
		createSnippet('jdbc_password', 'option', 'jdbc_password => "${1:jdbc_password}"', '**[jdbc_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_static.html#plugins-filters-jdbc_static-jdbc_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nJDBC password.'),
		createSnippet('jdbc_user', 'option', 'jdbc_user => "${1:jdbc_user}"', '**[jdbc_user](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_static.html#plugins-filters-jdbc_static-jdbc_user) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nJDBC user.'),
		createSnippet('tag_on_failure', 'option', 'tag_on_failure => ["${1:_jdbcstaticfailure}"]', '**[tag_on_failure](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_static.html#plugins-filters-jdbc_static-tag_on_failure) option**\n\n- Value type is array\n- Default value is ["_jdbcstaticfailure"]\n\nAppend values to the tags field if a SQL error occurred.'),
		createSnippet('tag_on_default_use', 'option', 'tag_on_default_use => ["${1:_jdbcstaticdefaultsused}"]', '**[tag_on_default_use](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_static.html#plugins-filters-jdbc_static-tag_on_default_use) option**\n\n- Value type is array\n- Default value is ["_jdbcstaticdefaultsused"]\n\nAppend values to the tags field if no record was found and default values were used.'),
		createSnippet('staging_directory', 'option', 'staging_directory => "${1:staging_directory}"', '**[staging_directory](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_static.html#plugins-filters-jdbc_static-staging_directory) option**\n\n- Value type is string\n- Default value is derived from the Ruby temp directory + plugin_name + "import_data"\n- e.g. "/tmp/logstash/jdbc_static/import_data"\n\nThe directory used stage the data for bulk loading, there should be sufficient disk space to handle the data you wish to use to enrich events. Previous versions of this plugin did not handle loading datasets of more than several thousand rows well due to an open bug in Apache Derby. This setting introduces an alternative way of loading large recordsets. As each row is received it is spooled to file and then that file is imported using a system import table system call.'),
		createSnippet('loader_schedule', 'option', 'loader_schedule => "${1:loader_schedule}"', '**[loader_schedule](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_static.html#plugins-filters-jdbc_static-loader_schedule) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nYou can schedule remote loading to run periodically according to a specific schedule. This scheduling syntax is powered by rufus-scheduler. The syntax is cron-like with some extensions specific to Rufus (for example, timezone support). For more about this syntax, see parsing cronlines and time strings.'),
		createSnippet('loaders', 'option', 'loaders => ["${1:loader}"]', '**[loaders](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_static.html#plugins-filters-jdbc_static-loaders) option**\n\n- Value type is array\n- Default value is []\n\nThe array should contain one or more Hashes. Each Hash is validated according to the table below.'),
		createSnippet('local_db_objects', 'option', 'local_db_objects => ["${1:local_db_object}"]', '**[local_db_objects](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_static.html#plugins-filters-jdbc_static-local_db_objects) option**\n\n- Value type is array\n- Default value is []\n\nThe array should contain one or more Hashes. Each Hash represents a table schema for the local lookups database. Each Hash is validated according to the table below.'),
		createSnippet('local_lookups', 'option', 'local_lookups => ["${1:local_lookup}"]', '**[local_lookups](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-jdbc_static.html#plugins-filters-jdbc_static-local_lookups) option**\n\n- Value type is array\n- Default value is []\n\nThe array should contain one or more Hashes. Each Hash represents a lookup enrichment. Each Hash is validated according to the table below.')
	],
	'logstash-output-udp': [
		createSnippet('host', 'option', 'host => "${1:host}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-udp.html#plugins-outputs-udp-host) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe address to send messages to', true),
		createSnippet('port', 'option', 'port => "${1:port}"', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-udp.html#plugins-outputs-udp-port) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe port to send messages on. This can be dynamic using the %{[target][port]} syntax.', true),
		createSnippet('retry_count', 'option', 'retry_count => ${1:0}', '**[retry_count](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-udp.html#plugins-outputs-udp-retry_count) option**\n\n- Value type is number\n- Default value is 0\n\nThe number of times to retry a failed UPD socket write'),
		createSnippet('retry_backoff_ms', 'option', 'retry_backoff_ms => ${1:10}', '**[retry_backoff_ms](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-udp.html#plugins-outputs-udp-retry_backoff_ms) option**\n\n- Value type is number\n- Default value is 10\n\nThe amount of time to wait in milliseconds before attempting to retry a failed UPD socket write')
	],
	'logstash-filter-metricize': [
		createSnippet('drop_original_event', 'option', 'drop_original_event => ${1|false,true|}', '**[drop_original_event](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-metricize.html#plugins-filters-metricize-drop_original_event) option**\n\n- Value type is boolean\n- Default value is false\n\nFlag indicating whether the original event should be dropped or not.'),
		createSnippet('metric_field_name', 'option', 'metric_field_name => "${1:metric}"', '**[metric_field_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-metricize.html#plugins-filters-metricize-metric_field_name) option**\n\n- Value type is string\n- Default value is "metric"\n\nName of the field the metric name will be written to.'),
		createSnippet('metrics', 'option', 'metrics => ["${1:metric}"]', '**[metrics](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-metricize.html#plugins-filters-metricize-metrics) option**\n\n- This is a required setting.\n- Value type is array\n- There is no default value for this setting.\n\nA new matrics event will be created for each metric field in this list. All fields in this list will be removed from generated events.', true),
		createSnippet('value_field_name', 'option', 'value_field_name => "${1:value}"', '**[value_field_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-metricize.html#plugins-filters-metricize-value_field_name) option**\n\n- Value type is string\n- Default value is "value"\n\nName of the field the metric value will be written to.')
	],
	'logstash-input-stomp': [
		createSnippet('destination', 'option', 'destination => "${1:destination}"', '**[destination](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-stomp.html#plugins-inputs-stomp-destination) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe destination to read events from.', true),
		createSnippet('host', 'option', 'host => "${1:localhost}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-stomp.html#plugins-inputs-stomp-host) option**\n\n- This is a required setting.\n- Value type is string\n- Default value is "localhost"\n\nThe address of the STOMP server.', true),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-stomp.html#plugins-inputs-stomp-password) option**\n\n- Value type is password\n- Default value is ""\n\nThe password to authenticate with.'),
		createSnippet('port', 'option', 'port => ${1:61613}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-stomp.html#plugins-inputs-stomp-port) option**\n\n- Value type is number\n- Default value is 61613\n\nThe port to connet to on your STOMP server.'),
		createSnippet('reconnect', 'option', 'reconnect => ${1|true,false|}', '**[reconnect](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-stomp.html#plugins-inputs-stomp-reconnect) option**\n\n- Value type is boolean\n- Default value is true\n\nAuto reconnect'),
		createSnippet('reconnect_interval', 'option', 'reconnect_interval => ${1:30}', '**[reconnect_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-stomp.html#plugins-inputs-stomp-reconnect_interval) option**\n\n- Value type is number\n- Default value is 30'),
		createSnippet('user', 'option', 'user => "${1:user}"', '**[user](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-stomp.html#plugins-inputs-stomp-user) option**\n\n- Value type is string\n- Default value is ""\n\nThe username to authenticate with.'),
		createSnippet('vhost', 'option', 'vhost => "${1:vhost}"', '**[vhost](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-stomp.html#plugins-inputs-stomp-vhost) option**\n\n- Value type is string\n- Default value is nil\n\nThe vhost to use')
	],
	'logstash-output-http': [
		createSnippet('user', 'option', 'user => "${1:user}"', '**[user](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html) option**\n\nUsername for HTTP basic authentication'),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html) option**\n\nPassword for HTTP basic authentication'),
		createSnippet('automatic_retries', 'option', 'automatic_retries => ${1:1}', '**[automatic_retries](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-automatic_retries) option**\n\n- Value type is number\n- Default value is 1\n\nHow many times should the client retry a failing URL. We highly recommend NOT setting this value to zero if keepalive is enabled. Some servers incorrectly end keepalives early requiring a retry! Only IO related failures will be retried, such as connection timeouts and unreachable hosts. Valid but non 2xx HTTP responses will always be retried, regardless of the value of this setting, unless retry_failed is set. Note: if retry_non_idempotent is NOT set only GET, HEAD, PUT, DELETE, OPTIONS, and TRACE requests will be retried.'),
		createSnippet('cacert', 'option', 'cacert => "${1:/path/to/file}"', '**[cacert](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-cacert) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you need to use a custom X.509 CA (.pem certs) specify the path to that here'),
		createSnippet('client_cert', 'option', 'client_cert => "${1:/path/to/file}"', '**[client_cert](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-client_cert) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you’d like to use a client certificate (note, most people don’t want this) set the path to the x509 cert here'),
		createSnippet('client_key', 'option', 'client_key => "${1:/path/to/file}"', '**[client_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-client_key) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you’re using a client certificate specify the path to the encryption key here'),
		createSnippet('connect_timeout', 'option', 'connect_timeout => ${1:10}', '**[connect_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-connect_timeout) option**\n\n- Value type is number\n- Default value is 10\n\nTimeout (in seconds) to wait for a connection to be established. Default is 10s'),
		createSnippet('content_type', 'option', 'content_type => "${1:content_type}"', '**[content_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-content_type) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nContent type'),
		createSnippet('cookies', 'option', 'cookies => ${1|true,false|}', '**[cookies](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-cookies) option**\n\n- Value type is boolean\n- Default value is true\n\nEnable cookie support. With this enabled the client will persist cookies across requests as a normal web browser would. Enabled by default'),
		createSnippet('follow_redirects', 'option', 'follow_redirects => ${1|true,false|}', '**[follow_redirects](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-follow_redirects) option**\n\n- Value type is boolean\n- Default value is true\n\nShould redirects be followed? Defaults to true'),
		createSnippet('format', 'option', 'format => "${1|json,json_batch,form,message|}"$0', '**[format](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-format) option**\n\n- Value can be any of: json, json_batch, form, message\n- Default value is "json"\n\nSet the format of the http body.'),
		createSnippet('headers', 'option', 'headers => {\n\t"${1:key}" => "${2:value}"\n}', '**[headers](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-headers) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nCustom headers to use format is headers => ["X-My-Header", "%{host}"]'),
		createSnippet('http_compression', 'option', 'http_compression => ${1|false,true|}', '**[http_compression](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-http_compression) option**\n\n- Value type is boolean\n- Default value is false\n\nEnable request compression support. With this enabled the plugin will compress http requests using gzip.'),
		createSnippet('http_method', 'option', 'http_method => "${1|put,post,patch,delete,get,head|}"$0', '**[http_method](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-http_method) option**\n\n- This is a required setting.\n- Value can be any of: put, post, patch, delete, get, head\n- There is no default value for this setting.\n\nThe HTTP Verb. One of "put", "post", "patch", "delete", "get", "head"', true),
		createSnippet('ignorable_codes', 'option', 'ignorable_codes => ${1:123}', '**[ignorable_codes](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-ignorable_codes) option**\n\n- Value type is number\n- There is no default value for this setting.\n\nIf you would like to consider some non-2xx codes to be successes enumerate them here. Responses returning these codes will be considered successes'),
		createSnippet('keepalive', 'option', 'keepalive => ${1|true,false|}', '**[keepalive](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-keepalive) option**\n\n- Value type is boolean\n- Default value is true\n\nTurn this on to enable HTTP keepalive support. We highly recommend setting automatic_retries to at least one with this to fix interactions with broken keepalive implementations.'),
		createSnippet('keystore', 'option', 'keystore => "${1:/path/to/file}"', '**[keystore](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-keystore) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you need to use a custom keystore (.jks) specify that here. This does not work with .pem keys!'),
		createSnippet('keystore_password', 'option', 'keystore_password => "${1:keystore_password}"', '**[keystore_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-keystore_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nSpecify the keystore password here. Note, most .jks files created with keytool require a password!'),
		createSnippet('keystore_type', 'option', 'keystore_type => "${1:JKS}"', '**[keystore_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-keystore_type) option**\n\n- Value type is string\n- Default value is "JKS"\n\nSpecify the keystore type here. One of JKS or PKCS12. Default is JKS'),
		createSnippet('mapping', 'option', 'mapping => {\n\t"${1:key}" => "${2:value}"\n}', '**[mapping](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-mapping) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nThis lets you choose the structure and parts of the event that are sent.\n\n**_Example:_**  \n``` ruby\n   mapping => {"foo" => "%{host}"\n              "bar" => "%{type}"}\n```'),
		createSnippet('message', 'option', 'message => "${1:message}"', '**[message](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-message) option**\n\n- Value type is string\n- There is no default value for this setting.'),
		createSnippet('pool_max', 'option', 'pool_max => ${1:50}', '**[pool_max](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-pool_max) option**\n\n- Value type is number\n- Default value is 50\n\nMax number of concurrent connections. Defaults to 50'),
		createSnippet('pool_max_per_route', 'option', 'pool_max_per_route => ${1:25}', '**[pool_max_per_route](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-pool_max_per_route) option**\n\n- Value type is number\n- Default value is 25\n\nMax number of concurrent connections to a single host. Defaults to 25'),
		createSnippet('proxy', 'option', 'proxy => "${1:proxy}"', '**[proxy](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-proxy) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nIf you’d like to use an HTTP proxy . This supports multiple configuration syntaxes:'),
		createSnippet('request_timeout', 'option', 'request_timeout => ${1:60}', '**[request_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-request_timeout) option**\n\n- Value type is number\n- Default value is 60\n\nThis module makes it easy to add a very fully configured HTTP client to logstash based on [Manticore](https://github.com/cheald/manticore). For an example of its usage see https://github.com/logstash-plugins/logstash-input-http_poller Timeout (in seconds) for the entire request'),
		createSnippet('retry_failed', 'option', 'retry_failed => ${1|true,false|}', '**[retry_failed](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-retry_failed) option**\n\n- Value type is boolean\n- Default value is true\n\nSet this to false if you don’t want this output to retry failed requests'),
		createSnippet('retry_non_idempotent', 'option', 'retry_non_idempotent => ${1|false,true|}', '**[retry_non_idempotent](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-retry_non_idempotent) option**\n\n- Value type is boolean\n- Default value is false\n\nIf automatic_retries is enabled this will cause non-idempotent HTTP verbs (such as POST) to be retried. This only affects connectivity related errors (see related automatic_retries setting).'),
		createSnippet('retryable_codes', 'option', 'retryable_codes => ${1:[429, 500, 502, 503, 504]}', '**[retryable_codes](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-retryable_codes) option**\n\n- Value type is number\n- Default value is [429, 500, 502, 503, 504]\n\nIf encountered as response codes this plugin will retry these requests'),
		createSnippet('socket_timeout', 'option', 'socket_timeout => ${1:10}', '**[socket_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-socket_timeout) option**\n\n- Value type is number\n- Default value is 10\n\nTimeout (in seconds) to wait for data on the socket. Default is 10s'),
		createSnippet('truststore', 'option', 'truststore => "${1:/path/to/file}"', '**[truststore](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-truststore) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf you need to use a custom truststore (.jks) specify that here. This does not work with .pem certs!'),
		createSnippet('truststore_password', 'option', 'truststore_password => "${1:truststore_password}"', '**[truststore_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-truststore_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nSpecify the truststore password here. Note, most .jks files created with keytool require a password!'),
		createSnippet('truststore_type', 'option', 'truststore_type => "${1:JKS}"', '**[truststore_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-truststore_type) option**\n\n- Value type is string\n- Default value is "JKS"\n\nSpecify the truststore type here. One of JKS or PKCS12. Default is JKS'),
		createSnippet('url', 'option', 'url => "${1:url}"', '**[url](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-url) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nURL to use', true),
		createSnippet('validate_after_inactivity', 'option', 'validate_after_inactivity => ${1:200}', '**[validate_after_inactivity](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html#plugins-outputs-http-validate_after_inactivity) option**\n\n- Value type is number\n- Default value is 200\n\nHow long to wait before checking if the connection is stale before executing a request on a connection using keepalive. You may want to set this lower, possibly to 0 if you get connection errors regularly Quoting the Apache commons docs (this client is based Apache Commmons): Defines period of inactivity in milliseconds after which persistent connections must be re-validated prior to being leased to the consumer. Non-positive value passed to this method disables connection validation. This check helps detect connections that have become stale (half-closed) while kept inactive in the pool. See these docs for more info')
	],
	'logstash-codec-gzip_lines': [
		createSnippet('charset', 'option', 'charset => "${1|UTF-8,ASCII-8BIT,US-ASCII,Big5,Big5-HKSCS,Big5-UAO,CP949,Emacs-Mule,EUC-JP,EUC-KR,EUC-TW,GB2312,GB18030,GBK,ISO-8859-1,ISO-8859-2,ISO-8859-3,ISO-8859-4,ISO-8859-5,ISO-8859-6,ISO-8859-7,ISO-8859-8,ISO-8859-9,ISO-8859-10,ISO-8859-11,ISO-8859-13,ISO-8859-14,ISO-8859-15,ISO-8859-16,KOI8-R,KOI8-U,Shift_JIS,UTF-16BE,UTF-16LE,UTF-32BE,UTF-32LE,Windows-31J,Windows-1250,Windows-1251,Windows-1252,IBM437,IBM737,IBM775,CP850,IBM852,CP852,IBM855,CP855,IBM857,IBM860,IBM861,IBM862,IBM863,IBM864,IBM865,IBM866,IBM869,Windows-1258,GB1988,macCentEuro,macCroatian,macCyrillic,macGreek,macIceland,macRoman,macRomania,macThai,macTurkish,macUkraine,CP950,CP951,IBM037,stateless-ISO-2022-JP,eucJP-ms,CP51932,EUC-JIS-2004,GB12345,ISO-2022-JP,ISO-2022-JP-2,CP50220,CP50221,Windows-1256,Windows-1253,Windows-1255,Windows-1254,TIS-620,Windows-874,Windows-1257,MacJapanese,UTF-7,UTF8-MAC,UTF-16,UTF-32,UTF8-DoCoMo,SJIS-DoCoMo,UTF8-KDDI,SJIS-KDDI,ISO-2022-JP-KDDI,stateless-ISO-2022-JP-KDDI,UTF8-SoftBank,SJIS-SoftBank,BINARY,CP437,CP737,CP775,IBM850,CP857,CP860,CP861,CP862,CP863,CP864,CP865,CP866,CP869,CP1258,Big5-HKSCS:2008,ebcdic-cp-us,eucJP,euc-jp-ms,EUC-JISX0213,eucKR,eucTW,EUC-CN,eucCN,CP936,ISO2022-JP,ISO2022-JP2,ISO8859-1,ISO8859-2,ISO8859-3,ISO8859-4,ISO8859-5,ISO8859-6,CP1256,ISO8859-7,CP1253,ISO8859-8,CP1255,ISO8859-9,CP1254,ISO8859-10,ISO8859-11,CP874,ISO8859-13,CP1257,ISO8859-14,ISO8859-15,ISO8859-16,CP878,MacJapan,ASCII,ANSI_X3.4-1968,646,CP65000,CP65001,UTF-8-MAC,UTF-8-HFS,UCS-2BE,UCS-4BE,UCS-4LE,CP932,csWindows31J,SJIS,PCK,CP1250,CP1251,CP1252,external,locale|}"$0', '**[charset](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-gzip_lines.html#plugins-codecs-gzip_lines-charset) option**\n\n- Value can be any of: ASCII-8BIT, UTF-8, US-ASCII, Big5, Big5-HKSCS, Big5-UAO, CP949, Emacs-Mule, EUC-JP, EUC-KR, EUC-TW, GB2312, GB18030, GBK, ISO-8859-1, ISO-8859-2, ISO-8859-3, ISO-8859-4, ISO-8859-5, ISO-8859-6, ISO-8859-7, ISO-8859-8, ISO-8859-9, ISO-8859-10, ISO-8859-11, ISO-8859-13, ISO-8859-14, ISO-8859-15, ISO-8859-16, KOI8-R, KOI8-U, Shift_JIS, UTF-16BE, UTF-16LE, UTF-32BE, UTF-32LE, Windows-31J, Windows-1250, Windows-1251, Windows-1252, IBM437, IBM737, IBM775, CP850, IBM852, CP852, IBM855, CP855, IBM857, IBM860, IBM861, IBM862, IBM863, IBM864, IBM865, IBM866, IBM869, Windows-1258, GB1988, macCentEuro, macCroatian, macCyrillic, macGreek, macIceland, macRoman, macRomania, macThai, macTurkish, macUkraine, CP950, CP951, IBM037, stateless-ISO-2022-JP, eucJP-ms, CP51932, EUC-JIS-2004, GB12345, ISO-2022-JP, ISO-2022-JP-2, CP50220, CP50221, Windows-1256, Windows-1253, Windows-1255, Windows-1254, TIS-620, Windows-874, Windows-1257, MacJapanese, UTF-7, UTF8-MAC, UTF-16, UTF-32, UTF8-DoCoMo, SJIS-DoCoMo, UTF8-KDDI, SJIS-KDDI, ISO-2022-JP-KDDI, stateless-ISO-2022-JP-KDDI, UTF8-SoftBank, SJIS-SoftBank, BINARY, CP437, CP737, CP775, IBM850, CP857, CP860, CP861, CP862, CP863, CP864, CP865, CP866, CP869, CP1258, Big5-HKSCS:2008, ebcdic-cp-us, eucJP, euc-jp-ms, EUC-JISX0213, eucKR, eucTW, EUC-CN, eucCN, CP936, ISO2022-JP, ISO2022-JP2, ISO8859-1, ISO8859-2, ISO8859-3, ISO8859-4, ISO8859-5, ISO8859-6, CP1256, ISO8859-7, CP1253, ISO8859-8, CP1255, ISO8859-9, CP1254, ISO8859-10, ISO8859-11, CP874, ISO8859-13, CP1257, ISO8859-14, ISO8859-15, ISO8859-16, CP878, MacJapan, ASCII, ANSI_X3.4-1968, 646, CP65000, CP65001, UTF-8-MAC, UTF-8-HFS, UCS-2BE, UCS-4BE, UCS-4LE, CP932, csWindows31J, SJIS, PCK, CP1250, CP1251, CP1252, external, locale\n- Default value is "UTF-8"\n\nThe character encoding used in this codec. Examples include "UTF-8" and "CP1252"')
	],
	'logstash-input-jdbc': [
		createSnippet('clean_run', 'option', 'clean_run => ${1|false,true|}', '**[clean_run](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-clean_run) option**\n\n- Value type is boolean\n- Default value is false\n\nWhether the previous run state should be preserved'),
		createSnippet('columns_charset', 'option', 'columns_charset => {\n\t"${1:key}" => "${2:value}"\n}', '**[columns_charset](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-columns_charset) option**\n\n- Value type is hash\n- Default value is {}\n\nThe character encoding for specific columns. This option will override the :charset option for the specified columns.\n\n**_Example:_**  \n``` ruby\ninput {\n  jdbc {\n    ...\n    columns_charset => { "column0" => "ISO-8859-1" }\n    ...\n  }\n}\n```'),
		createSnippet('connection_retry_attempts', 'option', 'connection_retry_attempts => ${1:1}', '**[connection_retry_attempts](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-connection_retry_attempts) option**\n\n- Value type is number\n- Default value is 1\n\nMaximum number of times to try connecting to database'),
		createSnippet('connection_retry_attempts_wait_time', 'option', 'connection_retry_attempts_wait_time => ${1:0.5}', '**[connection_retry_attempts_wait_time](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-connection_retry_attempts_wait_time) option**\n\n- Value type is number\n- Default value is 0.5\n\nNumber of seconds to sleep between connection attempts'),
		createSnippet('jdbc_connection_string', 'option', 'jdbc_connection_string => "${1:jdbc_connection_string}"', '**[jdbc_connection_string](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-jdbc_connection_string) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nJDBC connection string', true),
		createSnippet('jdbc_default_timezone', 'option', 'jdbc_default_timezone => "${1:jdbc_default_timezone}"', '**[jdbc_default_timezone](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-jdbc_default_timezone) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nTimezone conversion. Logstash (and Elasticsearch) expects that timestamps are expressed in UTC terms. If your database has recorded timestamps that are relative to another timezone, the database timezone if you will, then set this setting to be the timezone that the database is using. However, as SQL does not allow for timezone data in timestamp fields we can’t figure this out on a record by record basis. This plugin will automatically convert your SQL timestamp fields to Logstash timestamps, in relative UTC time in ISO8601 format.'),
		createSnippet('jdbc_driver_class', 'option', 'jdbc_driver_class => "${1:jdbc_driver_class}"', '**[jdbc_driver_class](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-jdbc_driver_class) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nJDBC driver class to load, for example, "org.apache.derby.jdbc.ClientDriver"', true),
		createSnippet('jdbc_driver_library', 'option', 'jdbc_driver_library => "${1:jdbc_driver_library}"', '**[jdbc_driver_library](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-jdbc_driver_library) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nJDBC driver library path to third party driver library. In case of multiple libraries being required you can pass them separated by a comma.'),
		createSnippet('jdbc_fetch_size', 'option', 'jdbc_fetch_size => ${1:123}', '**[jdbc_fetch_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-jdbc_fetch_size) option**\n\n- Value type is number\n- There is no default value for this setting.\n\nJDBC fetch size. if not provided, respective driver’s default will be used'),
		createSnippet('jdbc_page_size', 'option', 'jdbc_page_size => ${1:100000}', '**[jdbc_page_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-jdbc_page_size) option**\n\n- Value type is number\n- Default value is 100000\n\nJDBC page size'),
		createSnippet('jdbc_paging_enabled', 'option', 'jdbc_paging_enabled => ${1|false,true|}', '**[jdbc_paging_enabled](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-jdbc_paging_enabled) option**\n\n- Value type is boolean\n- Default value is false\n\nJDBC enable paging'),
		createSnippet('jdbc_paging_mode', 'option', 'jdbc_paging_mode => "${1|auto,explicit|}"$0', '**[jdbc_paging_mode](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-jdbc_paging_mode) option**\n\n- Value can be any of: auto, explicit\n- Default value is "auto"\n\nWhether to use explicit or auto mode during the JDBC paging\n\n**_Example:_**  \n``` ruby\ninput {\n  jdbc {\n    statement => "SELECT id, mycolumn1, mycolumn2 FROM my_table WHERE id > :sql_last_value LIMIT :size OFFSET :offset",\n    jdbc_paging_enabled => true,\n    jdbc_paging_mode => "explicit",\n    jdbc_page_size => 100000\n  }\n}\n```'),
		createSnippet('jdbc_password', 'option', 'jdbc_password => "${1:jdbc_password}"', '**[jdbc_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-jdbc_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nJDBC password'),
		createSnippet('jdbc_password_filepath', 'option', 'jdbc_password_filepath => "${1:/path/to/file}"', '**[jdbc_password_filepath](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-jdbc_password_filepath) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nJDBC password filename'),
		createSnippet('jdbc_pool_timeout', 'option', 'jdbc_pool_timeout => ${1:5}', '**[jdbc_pool_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-jdbc_pool_timeout) option**\n\n- Value type is number\n- Default value is 5\n\nConnection pool configuration. The amount of seconds to wait to acquire a connection before raising a PoolTimeoutError (default 5)'),
		createSnippet('jdbc_user', 'option', 'jdbc_user => "${1:jdbc_user}"', '**[jdbc_user](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-jdbc_user) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nJDBC user', true),
		createSnippet('jdbc_validate_connection', 'option', 'jdbc_validate_connection => ${1|false,true|}', '**[jdbc_validate_connection](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-jdbc_validate_connection) option**\n\n- Value type is boolean\n- Default value is false\n\nConnection pool configuration. Validate connection before use.'),
		createSnippet('jdbc_validation_timeout', 'option', 'jdbc_validation_timeout => ${1:3600}', '**[jdbc_validation_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-jdbc_validation_timeout) option**\n\n- Value type is number\n- Default value is 3600\n\nConnection pool configuration. How often to validate a connection (in seconds)'),
		createSnippet('last_run_metadata_path', 'option', 'last_run_metadata_path => "${1:\\$HOME/.logstash_jdbc_last_run}"', '**[last_run_metadata_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-last_run_metadata_path) option**\n\n- Value type is string\n- Default value is "$HOME/.logstash_jdbc_last_run"\n\nPath to file with last run time'),
		createSnippet('lowercase_column_names', 'option', 'lowercase_column_names => ${1|true,false|}', '**[lowercase_column_names](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-lowercase_column_names) option**\n\n- Value type is boolean\n- Default value is true\n\nWhether to force the lowercasing of identifier fields'),
		createSnippet('parameters', 'option', 'parameters => {\n\t"${1:key}" => "${2:value}"\n}', '**[parameters](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-parameters) option**\n\n- Value type is hash\n- Default value is {}\n\nHash of query parameter, for example { "target_id" => "321" }'),
		createSnippet('plugin_timezone', 'option', 'plugin_timezone => "${1|utc,local|}"$0', '**[plugin_timezone](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-plugin_timezone) option**\n\n- Value can be any of: utc, local\n- Default value is "utc"\n\nIf you want this plugin to offset timestamps to a timezone other than UTC, you can set this setting to local and the plugin will use the OS timezone for offset adjustments.'),
		createSnippet('prepared_statement_bind_values', 'option', 'prepared_statement_bind_values => ["${1:prepared_statement_bind_value}"]', '**[prepared_statement_bind_values](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-prepared_statement_bind_values) option**\n\n- Value type is array\n- Default value is []\n\nArray of bind values for the prepared statement. :sql_last_value is a reserved predefined string'),
		createSnippet('prepared_statement_name', 'option', 'prepared_statement_name => "${1:prepared_statement_name}"', '**[prepared_statement_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-prepared_statement_name) option**\n\n- Value type is string\n- Default value is ""\n\nName given to the prepared statement. It must be unique in your config and in the database'),
		createSnippet('record_last_run', 'option', 'record_last_run => ${1|true,false|}', '**[record_last_run](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-record_last_run) option**\n\n- Value type is boolean\n- Default value is true\n\nWhether to save state or not in last_run_metadata_path'),
		createSnippet('schedule', 'option', 'schedule => "${1:schedule}"', '**[schedule](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-schedule) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nSchedule of when to periodically run statement, in Cron format for example: "* * * * *" (execute query every minute, on the minute)'),
		createSnippet('sequel_opts', 'option', 'sequel_opts => {\n\t"${1:key}" => "${2:value}"\n}', '**[sequel_opts](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-sequel_opts) option**\n\n- Value type is hash\n- Default value is {}\n\nGeneral/Vendor-specific Sequel configuration options.'),
		createSnippet('sql_log_level', 'option', 'sql_log_level => "${1|info,error,warn,fatal,debug|}"$0', '**[sql_log_level](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-sql_log_level) option**\n\n- Value can be any of: fatal, error, warn, info, debug\n- Default value is "info"\n\nLog level at which to log SQL queries, the accepted values are the common ones fatal, error, warn, info and debug. The default value is info.'),
		createSnippet('statement', 'option', 'statement => "${1:statement}"', '**[statement](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-statement) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nIf undefined, Logstash will complain, even if codec is unused. Statement to execute'),
		createSnippet('statement_filepath', 'option', 'statement_filepath => "${1:/path/to/file}"', '**[statement_filepath](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-statement_filepath) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nPath of file containing statement to execute'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-target) option**\n\n- Value type is field reference\n- There is no default value for this setting.\n\nWithout a target, events are created from each row column at the root level. When the target is set to a field reference, the column of each row is placed in the target field instead.'),
		createSnippet('tracking_column', 'option', 'tracking_column => "${1:tracking_column}"', '**[tracking_column](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-tracking_column) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe column whose value is to be tracked if use_column_value is set to true'),
		createSnippet('tracking_column_type', 'option', 'tracking_column_type => "${1|numeric,timestamp|}"$0', '**[tracking_column_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-tracking_column_type) option**\n\n- Value can be any of: numeric, timestamp\n- Default value is "numeric"\n\nType of tracking column. Currently only "numeric" and "timestamp"'),
		createSnippet('use_column_value', 'option', 'use_column_value => ${1|false,true|}', '**[use_column_value](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-use_column_value) option**\n\n- Value type is boolean\n- Default value is false\n\nWhen set to true, uses the defined tracking_column value as the :sql_last_value. When set to false, :sql_last_value reflects the last time the query was executed.'),
		createSnippet('use_prepared_statements', 'option', 'use_prepared_statements => ${1|false,true|}', '**[use_prepared_statements](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html#plugins-inputs-jdbc-use_prepared_statements) option**\n\n- Value type is boolean\n- Default value is false\n\nWhen set to true, enables prepare statement usage')
	],
	'logstash-output-email': [
		createSnippet('address', 'option', 'address => "${1:localhost}"', '**[address](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html#plugins-outputs-email-address) option**\n\n- Value type is string\n- Default value is "localhost"\n\nThe address used to connect to the mail server'),
		createSnippet('attachments', 'option', 'attachments => ["${1:attachment}"]', '**[attachments](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html#plugins-outputs-email-attachments) option**\n\n- Value type is array\n- Default value is []\n\nAttachments - specify the name(s) and location(s) of the files.'),
		createSnippet('authentication', 'option', 'authentication => "${1:authentication}"', '**[authentication](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html#plugins-outputs-email-authentication) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nAuthentication method used when identifying with the server'),
		createSnippet('body', 'option', 'body => "${1:body}"', '**[body](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html#plugins-outputs-email-body) option**\n\n- Value type is string\n- Default value is ""\n\nBody for the email - plain text only.'),
		createSnippet('cc', 'option', 'cc => "${1:cc}"', '**[cc](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html#plugins-outputs-email-cc) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe fully-qualified email address(es) to include as cc: address(es).'),
		createSnippet('bcc', 'option', 'bcc => "${1:bcc}"', '**[bcc](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html#plugins-outputs-email-bcc) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe fully-qualified email address(es) to include as bcc: address(es).'),
		createSnippet('contenttype', 'option', 'contenttype => "${1:text/html; charset=UTF-8}"', '**[contenttype](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html#plugins-outputs-email-contenttype) option**\n\n- Value type is string\n- Default value is "text/html; charset=UTF-8"\n\ncontenttype : for multipart messages, set the content-type and/or charset of the HTML part. NOTE: this may not be functional (KH)'),
		createSnippet('debug', 'option', 'debug => ${1|false,true|}', '**[debug](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html#plugins-outputs-email-debug) option**\n\n- Value type is boolean\n- Default value is false\n\nRun the mail relay in debug mode'),
		createSnippet('domain', 'option', 'domain => "${1:localhost}"', '**[domain](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html#plugins-outputs-email-domain) option**\n\n- Value type is string\n- Default value is "localhost"\n\nThe HELO/EHLO domain name used in the greeting message when connecting to a remote SMTP server. Some servers require this name to match the actual hostname of the connecting client.'),
		createSnippet('from', 'option', 'from => "${1:logstash.alert@example.com}"', '**[from](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html#plugins-outputs-email-from) option**\n\n- Value type is string\n- Default value is "logstash.alert@example.com"\n\nThe fully-qualified email address for the From: field in the email.'),
		createSnippet('htmlbody', 'option', 'htmlbody => "${1:htmlbody}"', '**[htmlbody](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html#plugins-outputs-email-htmlbody) option**\n\n- Value type is string\n- Default value is ""\n\nHTML Body for the email, which may contain HTML markup.'),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html#plugins-outputs-email-password) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nPassword to authenticate with the server'),
		createSnippet('port', 'option', 'port => ${1:25}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html#plugins-outputs-email-port) option**\n\n- Value type is number\n- Default value is 25\n\nPort used to communicate with the mail server'),
		createSnippet('replyto', 'option', 'replyto => "${1:replyto}"', '**[replyto](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html#plugins-outputs-email-replyto) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe fully qualified email address for the Reply-To: field.'),
		createSnippet('subject', 'option', 'subject => "${1:subject}"', '**[subject](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html#plugins-outputs-email-subject) option**\n\n- Value type is string\n- Default value is ""\n\nSubject: for the email.'),
		createSnippet('to', 'option', 'to => "${1:to}"', '**[to](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html#plugins-outputs-email-to) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe fully-qualified email address to send the email to.', true),
		createSnippet('use_tls', 'option', 'use_tls => ${1|false,true|}', '**[use_tls](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html#plugins-outputs-email-use_tls) option**\n\n- Value type is boolean\n- Default value is false\n\nEnables TLS when communicating with the server'),
		createSnippet('username', 'option', 'username => "${1:username}"', '**[username](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html#plugins-outputs-email-username) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nUsername to authenticate with the server'),
		createSnippet('via', 'option', 'via => "${1:smtp}"', '**[via](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html#plugins-outputs-email-via) option**\n\n- Value type is string\n- Default value is "smtp"\n\nHow Logstash should send the email, either via SMTP or by invoking sendmail.'),
		createSnippet('template_file', 'option', 'template_file => "${1:/path/to/file}"', '**[template_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html#plugins-outputs-email-template_file) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nPath of a [Mustache templating](https://mustache.github.io/) file used for email templating. See example in test fixture. Can be used with body to send multi-part emails. Takes precedence over htmlBody.')
	],
	'logstash-output-stomp': [
		createSnippet('debug', 'option', 'debug => ${1|false,true|}', '**[debug](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-stomp.html#plugins-outputs-stomp-debug) option**\n\n- Value type is boolean\n- Default value is false\n\nEnable debugging output?'),
		createSnippet('destination', 'option', 'destination => "${1:destination}"', '**[destination](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-stomp.html#plugins-outputs-stomp-destination) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe destination to read events from. Supports string expansion, meaning %{foo} values will expand to the field value.', true),
		createSnippet('headers', 'option', 'headers => {\n\t"${1:key}" => "${2:value}"\n}', '**[headers](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-stomp.html#plugins-outputs-stomp-headers) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nCustom headers to send with each message. Supports string expansion, meaning %{foo} values will expand to the field value.'),
		createSnippet('host', 'option', 'host => "${1:host}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-stomp.html#plugins-outputs-stomp-host) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe address of the STOMP server.', true),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-stomp.html#plugins-outputs-stomp-password) option**\n\n- Value type is password\n- Default value is ""\n\nThe password to authenticate with.'),
		createSnippet('port', 'option', 'port => ${1:61613}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-stomp.html#plugins-outputs-stomp-port) option**\n\n- Value type is number\n- Default value is 61613\n\nThe port to connect to on your STOMP server.'),
		createSnippet('user', 'option', 'user => "${1:user}"', '**[user](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-stomp.html#plugins-outputs-stomp-user) option**\n\n- Value type is string\n- Default value is ""\n\nThe username to authenticate with.'),
		createSnippet('vhost', 'option', 'vhost => "${1:vhost}"', '**[vhost](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-stomp.html#plugins-outputs-stomp-vhost) option**\n\n- Value type is string\n- Default value is nil\n\nThe vhost to use')
	],
	'logstash-filter-useragent': [
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-useragent.html#plugins-filters-useragent-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: does not use ECS-compatible field names (fields might be set at the root of the event) v1, v8: uses fields that are compatible with Elastic Common Schema (for example, [user_agent][version])\n- disabled: does not use ECS-compatible field names (fields might be set at the root of the event)\n- v1, v8: uses fields that are compatible with Elastic Common Schema (for example, [user_agent][version])\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:'),
		createSnippet('lru_cache_size', 'option', 'lru_cache_size => ${1:100000}', '**[lru_cache_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-useragent.html#plugins-filters-useragent-lru_cache_size) option**\n\n- Value type is number\n- Default value is 100000\n\nUA parsing is surprisingly expensive. This filter uses an LRU cache to take advantage of the fact that user agents are often found adjacent to one another in log files and rarely have a random distribution. The higher you set this the more likely an item is to be in the cache and the faster this filter will run. However, if you set this too high you can use more memory than desired.'),
		createSnippet('prefix', 'option', 'prefix => "${1:prefix}"', '**[prefix](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-useragent.html#plugins-filters-useragent-prefix) option**\n\n- Value type is string\n- Default value is ""\n\nA string to prepend to all of the extracted keys'),
		createSnippet('regexes', 'option', 'regexes => "${1:regexes}"', '**[regexes](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-useragent.html#plugins-filters-useragent-regexes) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nIf not specified, this will default to the regexes.yaml that ships with logstash. Otherwise use the provided regexes.yaml file.'),
		createSnippet('source', 'option', 'source => "${1:source}"', '**[source](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-useragent.html#plugins-filters-useragent-source) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe field containing the user agent string. If this field is an array, only the first value will be used.', true),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-useragent.html#plugins-filters-useragent-target) option**\n\n- Value type is string\n- Default value depends on whether ecs_compatibility is enabled: ECS Compatibility disabled: no default value for this setting ECS Compatibility enabled: "user_agent"\n- ECS Compatibility disabled: no default value for this setting\n- ECS Compatibility enabled: "user_agent"\n\nDefault value depends on whether ecs_compatibility is enabled:')
	],
	'logstash-input-salesforce': [
		createSnippet('api_version', 'option', 'api_version => "${1:api_version}"', '**[api_version](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-salesforce.html#plugins-inputs-salesforce-api_version) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nBy default, this uses the default Restforce API version. To override this, set this to something like "32.0" for example'),
		createSnippet('client_id', 'option', 'client_id => "${1:client_id}"', '**[client_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-salesforce.html#plugins-inputs-salesforce-client_id) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nConsumer Key for authentication. You must set up a new SFDC connected app with oath to use this output. More information can be found here: https://help.salesforce.com/apex/HTViewHelpDoc?id=connected_app_create.htm', true),
		createSnippet('client_secret', 'option', 'client_secret => "${1:client_secret}"', '**[client_secret](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-salesforce.html#plugins-inputs-salesforce-client_secret) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nConsumer Secret from your oauth enabled connected app', true),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-salesforce.html#plugins-inputs-salesforce-password) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe password used to login to sfdc', true),
		createSnippet('security_token', 'option', 'security_token => "${1:security_token}"', '**[security_token](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-salesforce.html#plugins-inputs-salesforce-security_token) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe security token for this account. For more information about generting a security token, see: https://help.salesforce.com/apex/HTViewHelpDoc?id=user_security_token.htm', true),
		createSnippet('sfdc_fields', 'option', 'sfdc_fields => ["${1:sfdc_field}"]', '**[sfdc_fields](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-salesforce.html#plugins-inputs-salesforce-sfdc_fields) option**\n\n- Value type is array\n- Default value is []\n\nThese are the field names to return in the Salesforce query If this is empty, all fields are returned.'),
		createSnippet('sfdc_filters', 'option', 'sfdc_filters => "${1:sfdc_filters}"', '**[sfdc_filters](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-salesforce.html#plugins-inputs-salesforce-sfdc_filters) option**\n\n- Value type is string\n- Default value is ""\n\nThese options will be added to the WHERE clause in the SOQL statement. Additional fields can be filtered on by adding field1 = value1 AND field2 = value2 AND…'),
		createSnippet('sfdc_instance_url', 'option', 'sfdc_instance_url => "${1:sfdc_instance_url}"', '**[sfdc_instance_url](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-salesforce.html#plugins-inputs-salesforce-sfdc_instance_url) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe url of a Salesforce instance. Provide the url if you want to connect to your Salesforce instance instead of login.salesforce.com or test.salesforce.com at login.'),
		createSnippet('sfdc_object_name', 'option', 'sfdc_object_name => "${1:sfdc_object_name}"', '**[sfdc_object_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-salesforce.html#plugins-inputs-salesforce-sfdc_object_name) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe name of the salesforce object you are creating or updating', true),
		createSnippet('to_underscores', 'option', 'to_underscores => ${1|false,true|}', '**[to_underscores](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-salesforce.html#plugins-inputs-salesforce-to_underscores) option**\n\n- Value type is boolean\n- Default value is false\n\nSetting this to true will convert SFDC’s NamedFieldsc to named_fieldsc'),
		createSnippet('use_test_sandbox', 'option', 'use_test_sandbox => ${1|false,true|}', '**[use_test_sandbox](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-salesforce.html#plugins-inputs-salesforce-use_test_sandbox) option**\n\n- Value type is boolean\n- Default value is false\n\nSet this to true to connect to a sandbox sfdc instance logging in through test.salesforce.com'),
		createSnippet('use_tooling_api', 'option', 'use_tooling_api => ${1|false,true|}', '**[use_tooling_api](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-salesforce.html#plugins-inputs-salesforce-use_tooling_api) option**\n\n- Value type is boolean\n- Default value is false\n\nSet this to true to connect to the sfdc tooling api instead of the regular sfdc rest api. See https://developer.salesforce.com/docs/atlas.en-us.api_tooling.meta/api_tooling for details about the sfdc tooling api. Use cases for the sfdc tooling api include reading apex unit test results, flow coverage results (e.g. coverage of elements of sfdc flows) and security health check risks.'),
		createSnippet('username', 'option', 'username => "${1:username}"', '**[username](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-salesforce.html#plugins-inputs-salesforce-username) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nA valid salesforce user name, usually your email address. Used for authentication and will be the user all objects are created or modified by', true)
	],
	'logstash-codec-es_bulk': [
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-es_bulk.html#plugins-codecs-es_bulk-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: unstructured metadata added at @metadata v1: uses [@metadata][codec][es_bulk] fields\n- disabled: unstructured metadata added at @metadata\n- v1: uses [@metadata][codec][es_bulk] fields\n\nSupported values are:'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-es_bulk.html#plugins-codecs-es_bulk-target) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nDefine the target field for placing the values. If this setting is not set, the data will be stored at the root (top level) of the event.\n\n**_Example:_**  \n``` ruby\ninput {\n  kafka {\n    codec => es_bulk {\n        target => "[document]"\n    }\n  }\n}\n```')
	],
	'logstash-filter-java_uuid': [
		createSnippet('overwrite', 'option', 'overwrite => ${1|false,true|}', '**[overwrite](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-java_uuid.html#plugins-filters-java_uuid-overwrite) option**\n\n- Value type is boolean\n- Default value is false\n\nDetermines if an existing value in the field specified by the target option should be overwritten by the filter.\n\n**_Example:_**  \n``` ruby\n   filter {\n      java_uuid {\n        target    => "uuid"\n        overwrite => true\n      }\n   }\n```'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-java_uuid.html#plugins-filters-java_uuid-target) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nSpecifies the name of the field in which the generated UUID should be stored.\n\n**_Example:_**  \n``` ruby\n    filter {\n      java_uuid {\n        target => "uuid"\n      }\n    }\n```', true)
	],
	'logstash-input-ganglia': [
		createSnippet('host', 'option', 'host => "${1:0.0.0.0}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-ganglia.html#plugins-inputs-ganglia-host) option**\n\n- Value type is string\n- Default value is "0.0.0.0"\n\nThe address to listen on'),
		createSnippet('port', 'option', 'port => ${1:8649}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-ganglia.html#plugins-inputs-ganglia-port) option**\n\n- Value type is number\n- Default value is 8649\n\nThe port to listen on. Remember that ports less than 1024 (privileged ports) may require root to use.')
	],
	'logstash-output-riak': [
		createSnippet('bucket', 'option', 'bucket => ["${1:logstash-%{+YYYY.MM.dd\\}}"]', '**[bucket](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-riak.html#plugins-outputs-riak-bucket) option**\n\n- Value type is array\n- Default value is ["logstash-%{+YYYY.MM.dd}"]\n\nThe bucket name to write events to Expansion is supported here as values are passed through event.sprintf Multiple buckets can be specified here but any bucket-specific settings defined apply to ALL the buckets.'),
		createSnippet('bucket_props', 'option', 'bucket_props => {\n\t"${1:key}" => "${2:value}"\n}', '**[bucket_props](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-riak.html#plugins-outputs-riak-bucket_props) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nBucket properties (NYI) Logstash hash of properties for the bucket i.e.\n\n**_Example:_**  \n``` ruby\n    bucket_props => {\n        "r" => "one"\n        "w" => "one"\n        "dw", "one\n     }\n```'),
		createSnippet('enable_search', 'option', 'enable_search => ${1|false,true|}', '**[enable_search](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-riak.html#plugins-outputs-riak-enable_search) option**\n\n- Value type is boolean\n- Default value is false\n\nSearch Enable search on the bucket defined above'),
		createSnippet('enable_ssl', 'option', 'enable_ssl => ${1|false,true|}', '**[enable_ssl](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-riak.html#plugins-outputs-riak-enable_ssl) option**\n\n- Value type is boolean\n- Default value is false\n\nSSL Enable SSL'),
		createSnippet('indices', 'option', 'indices => ["${1:indice}"]', '**[indices](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-riak.html#plugins-outputs-riak-indices) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nIndices Array of fields to add 2i on e.g.\n\n**_Example:_**  \n``` ruby\n    `indices => ["source_host", "type"]\n```'),
		createSnippet('key_name', 'option', 'key_name => "${1:key_name}"', '**[key_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-riak.html#plugins-outputs-riak-key_name) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe event key name variables are valid here.'),
		createSnippet('nodes', 'option', 'nodes => {\n\t"${1:key}" => "${2:value}"\n}', '**[nodes](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-riak.html#plugins-outputs-riak-nodes) option**\n\n- Value type is hash\n- Default value is {"localhost"=>"8098"}\n\nThe nodes of your Riak cluster This can be a single host or a Logstash hash of node/port pairs e.g'),
		createSnippet('proto', 'option', 'proto => "${1|http,pb|}"$0', '**[proto](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-riak.html#plugins-outputs-riak-proto) option**\n\n- Value can be any of: http, pb\n- Default value is "http"\n\nThe protocol to use HTTP or ProtoBuf Applies to ALL backends listed above No mix and match'),
		createSnippet('ssl_opts', 'option', 'ssl_opts => {\n\t"${1:key}" => "${2:value}"\n}', '**[ssl_opts](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-riak.html#plugins-outputs-riak-ssl_opts) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nOptions for SSL connections. Only applied if SSL is enabled. Logstash hash that maps to the riak-client options here: https://github.com/basho/riak-ruby-client/wiki/Connecting-to-Riak.\n\n**_Example:_**  \n``` ruby\n    ssl_opts => {\n       "pem" => "/etc/riak.pem"\n       "ca_path" => "/usr/share/certificates"\n    }\n```')
	],
	'logstash-output-boundary': [
		createSnippet('api_key', 'option', 'api_key => "${1:api_key}"', '**[api_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-boundary.html#plugins-outputs-boundary-api_key) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nYour Boundary API key', true),
		createSnippet('auto', 'option', 'auto => ${1|false,true|}', '**[auto](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-boundary.html#plugins-outputs-boundary-auto) option**\n\n- Value type is boolean\n- Default value is false\n\nAuto If set to true, logstash will try to pull boundary fields out of the event. Any field explicitly set by config options will override these. [\'type\', \'subtype\', \'creation_time\', \'end_time\', \'links\', \'tags\', \'loc\']'),
		createSnippet('bsubtype', 'option', 'bsubtype => "${1:bsubtype}"', '**[bsubtype](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-boundary.html#plugins-outputs-boundary-bsubtype) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nSub-Type'),
		createSnippet('btags', 'option', 'btags => ["${1:btag}"]', '**[btags](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-boundary.html#plugins-outputs-boundary-btags) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nTags Set any custom tags for this event Default are the Logstash tags if any'),
		createSnippet('btype', 'option', 'btype => "${1:btype}"', '**[btype](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-boundary.html#plugins-outputs-boundary-btype) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nType'),
		createSnippet('end_time', 'option', 'end_time => "${1:end_time}"', '**[end_time](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-boundary.html#plugins-outputs-boundary-end_time) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nEnd time Override the stop time Note that Boundary requires this to be seconds since epoch If overriding, it is your responsibility to type this correctly By default this is set to event.get("@timestamp").to_i'),
		createSnippet('org_id', 'option', 'org_id => "${1:org_id}"', '**[org_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-boundary.html#plugins-outputs-boundary-org_id) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nYour Boundary Org ID', true),
		createSnippet('start_time', 'option', 'start_time => "${1:start_time}"', '**[start_time](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-boundary.html#plugins-outputs-boundary-start_time) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nStart time Override the start time Note that Boundary requires this to be seconds since epoch If overriding, it is your responsibility to type this correctly By default this is set to event.get("@timestamp").to_i')
	],
	'logstash-output-exec': [
		createSnippet('command', 'option', 'command => "${1:command}"', '**[command](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-exec.html#plugins-outputs-exec-command) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nCommand line to execute via subprocess. Use dtach or screen to make it non blocking. This value can include %{name} and other dynamic strings.', true),
		createSnippet('quiet', 'option', 'quiet => ${1|false,true|}', '**[quiet](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-exec.html#plugins-outputs-exec-quiet) option**\n\n- Value type is boolean\n- Default value is false\n\ndisplay the result of the command to the terminal')
	],
	'logstash-input-java_generator': [
		createSnippet('count', 'option', 'count => ${1:0}', '**[count](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-java_generator.html#plugins-inputs-java_generator-count) option**\n\n- Value type is number\n- Default value is 0\n\nSets the number of events that should be generated.'),
		createSnippet('eps', 'option', 'eps => ${1:0}', '**[eps](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-java_generator.html#plugins-inputs-java_generator-eps) option**\n\n- Value type is number\n- Default value is 0\n\nSets the rate at which events should be generated. Fractional values may be specified. For example, a rate of 0.25 means that one event will be generated every four seconds.'),
		createSnippet('lines', 'option', 'lines => ["${1:line}"]', '**[lines](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-java_generator.html#plugins-inputs-java_generator-lines) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nThe lines to emit, in order. This option overrides the message setting if it has also been specified.\n\n**_Example:_**  \n``` ruby\n    input {\n      java_generator {\n        lines => [\n          "line 1",\n          "line 2",\n          "line 3"\n        ]\n        # Emit all lines 2 times.\n        count => 2\n      }\n    }\n```'),
		createSnippet('message', 'option', 'message => "${1:Hello world!}"', '**[message](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-java_generator.html#plugins-inputs-java_generator-message) option**\n\n- Value type is string\n- Default value is "Hello world!"\n\nThe message string to use in the event.'),
		createSnippet('threads', 'option', 'threads => ${1:1}', '**[threads](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-java_generator.html#plugins-inputs-java_generator-threads) option**\n\n- Value type is number\n- Default value is 1\n\nIncreasing the number of generator threads up to about the number of CPU cores generally increases overall event throughput. The count, eps, and lines settings all apply on a per-thread basis. In other words, each thread will emit the number of events specified in the count setting for a total of threads * count events. Each thread will emit events at the eps rate for a total rate of threads * eps, and each thread will emit each line specified in the lines option.')
	],
	'logstash-output-websocket': [
		createSnippet('host', 'option', 'host => "${1:0.0.0.0}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-websocket.html#plugins-outputs-websocket-host) option**\n\n- Value type is string\n- Default value is "0.0.0.0"\n\nThe address to serve websocket data from'),
		createSnippet('port', 'option', 'port => ${1:3232}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-websocket.html#plugins-outputs-websocket-port) option**\n\n- Value type is number\n- Default value is 3232\n\nThe port to serve websocket data from')
	],
	'logstash-output-sink': [
	],
	'logstash-output-metriccatcher': [
		createSnippet('biased', 'option', 'biased => {\n\t"${1:key}" => "${2:value}"\n}', '**[biased](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-metriccatcher.html#plugins-outputs-metriccatcher-biased) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nThe metrics to send. This supports dynamic strings like %{host} for metric names and also for values. This is a hash field with key of the metric name, value of the metric value.'),
		createSnippet('counter', 'option', 'counter => {\n\t"${1:key}" => "${2:value}"\n}', '**[counter](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-metriccatcher.html#plugins-outputs-metriccatcher-counter) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nThe metrics to send. This supports dynamic strings like %{host} for metric names and also for values. This is a hash field with key of the metric name, value of the metric value. Example:\n\n**_Example:_**  \n``` ruby\n  counter => { "%{host}.apache.hits.%{response} => "1" }\n```'),
		createSnippet('gauge', 'option', 'gauge => {\n\t"${1:key}" => "${2:value}"\n}', '**[gauge](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-metriccatcher.html#plugins-outputs-metriccatcher-gauge) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nThe metrics to send. This supports dynamic strings like %{host} for metric names and also for values. This is a hash field with key of the metric name, value of the metric value.'),
		createSnippet('host', 'option', 'host => "${1:localhost}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-metriccatcher.html#plugins-outputs-metriccatcher-host) option**\n\n- Value type is string\n- Default value is "localhost"\n\nThe address of the MetricCatcher'),
		createSnippet('meter', 'option', 'meter => {\n\t"${1:key}" => "${2:value}"\n}', '**[meter](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-metriccatcher.html#plugins-outputs-metriccatcher-meter) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nThe metrics to send. This supports dynamic strings like %{host} for metric names and also for values. This is a hash field with key of the metric name, value of the metric value.'),
		createSnippet('port', 'option', 'port => ${1:1420}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-metriccatcher.html#plugins-outputs-metriccatcher-port) option**\n\n- Value type is number\n- Default value is 1420\n\nThe port to connect on your MetricCatcher'),
		createSnippet('timer', 'option', 'timer => {\n\t"${1:key}" => "${2:value}"\n}', '**[timer](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-metriccatcher.html#plugins-outputs-metriccatcher-timer) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nThe metrics to send. This supports dynamic strings like %{host} for metric names and also for values. This is a hash field with key of the metric name, value of the metric value. Example:\n\n**_Example:_**  \n``` ruby\n  timer => { "%{host}.apache.response_time => "%{response_time}" }\n```'),
		createSnippet('uniform', 'option', 'uniform => {\n\t"${1:key}" => "${2:value}"\n}', '**[uniform](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-metriccatcher.html#plugins-outputs-metriccatcher-uniform) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nThe metrics to send. This supports dynamic strings like %{host} for metric names and also for values. This is a hash field with key of the metric name, value of the metric value.')
	],
	'logstash-output-circonus': [
		createSnippet('annotation', 'option', 'annotation => {\n\t"${1:key}" => "${2:value}"\n}', '**[annotation](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-circonus.html#plugins-outputs-circonus-annotation) option**\n\n- This is a required setting.\n- Value type is hash\n- Default value is {}\n\nAnnotations Registers an annotation with Circonus The only required field is title and description. start and stop will be set to the event timestamp. You can add any other optional annotation values as well. All values will be passed through event.sprintf', true),
		createSnippet('api_token', 'option', 'api_token => "${1:api_token}"', '**[api_token](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-circonus.html#plugins-outputs-circonus-api_token) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nYour Circonus API Token', true),
		createSnippet('app_name', 'option', 'app_name => "${1:app_name}"', '**[app_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-circonus.html#plugins-outputs-circonus-app_name) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nYour Circonus App name This will be passed through event.sprintf so variables are allowed here:', true)
	],
	'logstash-input-graphite': [
		createSnippet('host', 'option', 'host => "${1:0.0.0.0}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-graphite.html#plugins-inputs-graphite-host) option**\n\n- Value type is string\n- Default value is "0.0.0.0"\n\nRead events over a TCP socket.'),
		createSnippet('mode', 'option', 'mode => "${1|server,client|}"$0', '**[mode](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-graphite.html#plugins-inputs-graphite-mode) option**\n\n- Value can be any of: server, client\n- Default value is "server"\n\nMode to operate in. server listens for client connections, client connects to a server.'),
		createSnippet('port', 'option', 'port => ${1:123}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-graphite.html#plugins-inputs-graphite-port) option**\n\n- This is a required setting.\n- Value type is number\n- There is no default value for this setting.\n\nWhen mode is server, the port to listen on. When mode is client, the port to connect to.', true),
		createSnippet('proxy_protocol', 'option', 'proxy_protocol => ${1|false,true|}', '**[proxy_protocol](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-graphite.html#plugins-inputs-graphite-proxy_protocol) option**\n\n- Value type is boolean\n- Default value is false\n\nProxy protocol support, only v1 is supported at this time http://www.haproxy.org/download/1.5/doc/proxy-protocol.txt'),
		createSnippet('ssl_cert', 'option', 'ssl_cert => "${1:/path/to/file}"', '**[ssl_cert](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-graphite.html#plugins-inputs-graphite-ssl_cert) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nSSL certificate path'),
		createSnippet('ssl_enable', 'option', 'ssl_enable => ${1|false,true|}', '**[ssl_enable](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-graphite.html#plugins-inputs-graphite-ssl_enable) option**\n\n- Value type is boolean\n- Default value is false\n\nEnable SSL (must be set for other ssl_ options to take effect).'),
		createSnippet('ssl_extra_chain_certs', 'option', 'ssl_extra_chain_certs => ["${1:ssl_extra_chain_cert}"]', '**[ssl_extra_chain_certs](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-graphite.html#plugins-inputs-graphite-ssl_extra_chain_certs) option**\n\n- Value type is array\n- Default value is []\n\nAn Array of extra X509 certificates to be added to the certificate chain. Useful when the CA chain is not necessary in the system store.'),
		createSnippet('ssl_key', 'option', 'ssl_key => "${1:/path/to/file}"', '**[ssl_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-graphite.html#plugins-inputs-graphite-ssl_key) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nSSL key path'),
		createSnippet('ssl_key_passphrase', 'option', 'ssl_key_passphrase => "${1:ssl_key_passphrase}"', '**[ssl_key_passphrase](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-graphite.html#plugins-inputs-graphite-ssl_key_passphrase) option**\n\n- Value type is password\n- Default value is nil\n\nSSL key passphrase'),
		createSnippet('ssl_verify', 'option', 'ssl_verify => ${1|true,false|}', '**[ssl_verify](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-graphite.html#plugins-inputs-graphite-ssl_verify) option**\n\n- Value type is boolean\n- Default value is true\n\nVerify the identity of the other end of the SSL connection against the CA. For input, sets the field sslsubject to that of the client certificate.')
	],
	'logstash-filter-prune': [
		createSnippet('blacklist_names', 'option', 'blacklist_names => ["${1:%{[^\\}]+\\}}"]', '**[blacklist_names](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-prune.html#plugins-filters-prune-blacklist_names) option**\n\n- Value type is array\n- Default value is ["%{[^}]+}"]\n\nExclude fields whose names match specified regexps, by default exclude unresolved %{field} strings.\n\n**_Example:_**  \n``` ruby\n    filter {\n      prune {\n        blacklist_names => [ "method", "(referrer|status)", "${some}_field" ]\n      }\n    }\n```'),
		createSnippet('blacklist_values', 'option', 'blacklist_values => {\n\t"${1:key}" => "${2:value}"\n}', '**[blacklist_values](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-prune.html#plugins-filters-prune-blacklist_values) option**\n\n- Value type is hash\n- Default value is {}\n\nExclude specified fields if their values match one of the supplied regular expressions. In case field values are arrays, each array item is matched against the regular expressions and matching array items will be excluded.\n\n**_Example:_**  \n``` ruby\n    filter {\n      prune {\n        blacklist_values => [ "uripath", "/index.php",\n                              "method", "(HEAD|OPTIONS)",\n                              "status", "^[^2]" ]\n      }\n    }\n```'),
		createSnippet('interpolate', 'option', 'interpolate => ${1|false,true|}', '**[interpolate](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-prune.html#plugins-filters-prune-interpolate) option**\n\n- Value type is boolean\n- Default value is false\n\nTrigger whether configuration fields and values should be interpolated for dynamic values (when resolving %{some_field}). Probably adds some performance overhead. Defaults to false.'),
		createSnippet('whitelist_names', 'option', 'whitelist_names => ["${1:whitelist_name}"]', '**[whitelist_names](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-prune.html#plugins-filters-prune-whitelist_names) option**\n\n- Value type is array\n- Default value is []\n\nInclude only fields only if their names match specified regexps, default to empty list which means include everything.\n\n**_Example:_**  \n``` ruby\n    filter {\n      prune {\n        whitelist_names => [ "method", "(referrer|status)", "${some}_field" ]\n      }\n    }\n```'),
		createSnippet('whitelist_values', 'option', 'whitelist_values => {\n\t"${1:key}" => "${2:value}"\n}', '**[whitelist_values](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-prune.html#plugins-filters-prune-whitelist_values) option**\n\n- Value type is hash\n- Default value is {}\n\nInclude specified fields only if their values match one of the supplied regular expressions. In case field values are arrays, each array item is matched against the regular expressions and only matching array items will be included. By default all fields that are not listed in this setting are kept unless pruned by other settings.\n\n**_Example:_**  \n``` ruby\n    filter {\n      prune {\n        whitelist_values => [ "uripath", "/index.php",\n                              "method", "(GET|POST)",\n                              "status", "^[^2]" ]\n      }\n    }\n```')
	],
	'logstash-input-github': [
		createSnippet('drop_invalid', 'option', 'drop_invalid => ${1|false,true|}', '**[drop_invalid](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-github.html#plugins-inputs-github-drop_invalid) option**\n\n- Value type is boolean\n- Default value is false\n\nIf Secret is defined, we drop the events that don’t match. Otherwise, we’ll just add an invalid tag'),
		createSnippet('ip', 'option', 'ip => "${1:0.0.0.0}"', '**[ip](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-github.html#plugins-inputs-github-ip) option**\n\n- Value type is string\n- Default value is "0.0.0.0"\n\nThe ip to listen on'),
		createSnippet('port', 'option', 'port => ${1:123}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-github.html#plugins-inputs-github-port) option**\n\n- This is a required setting.\n- Value type is number\n- There is no default value for this setting.\n\nThe port to listen on', true),
		createSnippet('secret_token', 'option', 'secret_token => "${1:secret_token}"', '**[secret_token](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-github.html#plugins-inputs-github-secret_token) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nYour GitHub Secret Token for the webhook')
	],
	'logstash-input-sqlite': [
		createSnippet('batch', 'option', 'batch => ${1:5}', '**[batch](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-sqlite.html#plugins-inputs-sqlite-batch) option**\n\n- Value type is number\n- Default value is 5\n\nHow many rows to fetch at a time from each SELECT call.'),
		createSnippet('exclude_tables', 'option', 'exclude_tables => ["${1:exclude_table}"]', '**[exclude_tables](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-sqlite.html#plugins-inputs-sqlite-exclude_tables) option**\n\n- Value type is array\n- Default value is []\n\nAny tables to exclude by name. By default all tables are followed.'),
		createSnippet('path', 'option', 'path => "${1:path}"', '**[path](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-sqlite.html#plugins-inputs-sqlite-path) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe path to the sqlite database file.', true)
	],
	'logstash-output-csv': [
		createSnippet('create_if_deleted', 'option', 'create_if_deleted => ${1|true,false|}', '**[create_if_deleted](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-csv.html#plugins-outputs-csv-create_if_deleted) option**\n\n- Value type is boolean\n- Default value is true\n\nIf the configured file is deleted, but an event is handled by the plugin, the plugin will recreate the file. Default ⇒ true'),
		createSnippet('csv_options', 'option', 'csv_options => {\n\t"${1:key}" => "${2:value}"\n}', '**[csv_options](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-csv.html#plugins-outputs-csv-csv_options) option**\n\n- Value type is hash\n- Default value is {}\n\nOptions for CSV output. This is passed directly to the Ruby stdlib to_csv function. Full documentation is available on the Ruby CSV documentation page. A typical use case would be to use alternative column or row separators eg: csv_options => {"col_sep" => "\\\\t" "row_sep" => "\\\\r\n"} gives tab separated data with windows line endings'),
		createSnippet('dir_mode', 'option', 'dir_mode => ${1:-1}', '**[dir_mode](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-csv.html#plugins-outputs-csv-dir_mode) option**\n\n- Value type is number\n- Default value is -1\n\nDir access mode to use. Note that due to the bug in jruby system umask is ignored on linux: https://github.com/jruby/jruby/issues/3426 Setting it to -1 uses default OS value. Example: "dir_mode" => 0750'),
		createSnippet('fields', 'option', 'fields => ["${1:field}"]', '**[fields](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-csv.html#plugins-outputs-csv-fields) option**\n\n- This is a required setting.\n- Value type is array\n- There is no default value for this setting.\n\nThe field names from the event that should be written to the CSV file. Fields are written to the CSV in the same order as the array. If a field does not exist on the event, an empty string will be written. Supports field reference syntax eg: fields => ["field1", "[nested][field]"].', true),
		createSnippet('file_mode', 'option', 'file_mode => ${1:-1}', '**[file_mode](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-csv.html#plugins-outputs-csv-file_mode) option**\n\n- Value type is number\n- Default value is -1\n\nFile access mode to use. Note that due to the bug in jruby system umask is ignored on linux: https://github.com/jruby/jruby/issues/3426 Setting it to -1 uses default OS value. Example: "file_mode" => 0640'),
		createSnippet('filename_failure', 'option', 'filename_failure => "${1:_filepath_failures}"', '**[filename_failure](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-csv.html#plugins-outputs-csv-filename_failure) option**\n\n- Value type is string\n- Default value is "_filepath_failures"\n\nIf the generated path is invalid, the events will be saved into this file and inside the defined path.'),
		createSnippet('flush_interval', 'option', 'flush_interval => ${1:2}', '**[flush_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-csv.html#plugins-outputs-csv-flush_interval) option**\n\n- Value type is number\n- Default value is 2\n\nFlush interval (in seconds) for flushing writes to log files. 0 will flush on every message.'),
		createSnippet('gzip', 'option', 'gzip => ${1|false,true|}', '**[gzip](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-csv.html#plugins-outputs-csv-gzip) option**\n\n- Value type is boolean\n- Default value is false\n\nGzip the output stream before writing to disk.'),
		createSnippet('path', 'option', 'path => "${1:path}"', '**[path](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-csv.html#plugins-outputs-csv-path) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThis output writes events to files on disk. You can use fields from the event as parts of the filename and/or path.\n\n**_Example:_**  \n``` ruby\noutput {\n file {\n   path => ...\n   codec => line { format => "custom format: %{message}"}\n }\n}\n```', true),
		createSnippet('spreadsheet_safe', 'option', 'spreadsheet_safe => ${1|true,false|}', '**[spreadsheet_safe](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-csv.html#plugins-outputs-csv-spreadsheet_safe) option**\n\n- Value type is boolean\n- Default value is true\n\nOption to not escape/munge string values. Please note turning off this option may not make the values safe in your spreadsheet application')
	],
	'logstash-input-snmp': [
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-snmp.html#plugins-inputs-snmp-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: does not use ECS-compatible field names (fields might be set at the root of the event) v1, v8: avoids field names that might conflict with Elastic Common Schema (for example, the host field)\n- disabled: does not use ECS-compatible field names (fields might be set at the root of the event)\n- v1, v8: avoids field names that might conflict with Elastic Common Schema (for example, the host field)\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:'),
		createSnippet('get', 'option', 'get => ["${1:get}"]', '**[get](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-snmp.html#plugins-inputs-snmp-get) option**\n\n- Value type is array\n- There is no default value for this setting\n\nUse the get option to query for scalar values for the given OID(s). One or more OID(s) are specified as an array of strings of OID(s).\n\n**_Example:_**  \n``` ruby\ninput {\n  snmp {\n    get => ["1.3.6.1.2.1.1.1.0", "1.3.6.1.2.1.1.3.0", "1.3.6.1.2.1.1.5.0"]\n    hosts => [{host => "udp:127.0.0.1/161" community => "public"}]\n  }\n}\n```'),
		createSnippet('hosts', 'option', 'hosts => ["${1:host}"]', '**[hosts](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-snmp.html#plugins-inputs-snmp-hosts) option**\n\n- Value type is array\n- There is no default value for this setting\n\nThe hosts option specifies the list of hosts to query the configured get and walk options.\n\n**_Example:_**  \n``` ruby\ninput {\n  snmp {\n    get => ["1.3.6.1.2.1.1.1.0"]\n    hosts => [{host => "udp:127.0.0.1/161" community => "public" version => "2c"  retries => 2  timeout => 1000}]\n  }\n}\n```'),
		createSnippet('interval', 'option', 'interval => ${1:30}', '**[interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-snmp.html#plugins-inputs-snmp-interval) option**\n\n- Value type is number\n- Default value is 30\n\nThe interval option specifies the polling interval in seconds. If polling all configured hosts takes longer than this interval, a warning will be emitted to the logs.'),
		createSnippet('mib_paths', 'option', 'mib_paths => "${1:/path/to/file}"', '**[mib_paths](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-snmp.html#plugins-inputs-snmp-mib_paths) option**\n\n- Value type is path\n- There is no default value for this setting\n\nThe mib_paths option specifies the location of one or more imported MIB files. The value can be either a dir path containing the imported MIB .dic files or a file path to a single MIB .dic file.'),
		createSnippet('oid_root_skip', 'option', 'oid_root_skip => ${1:0}', '**[oid_root_skip](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-snmp.html#plugins-inputs-snmp-oid_root_skip) option**\n\n- Value type is number\n- Default value is 0\n\nThe oid_root_skip option specifies the number of OID root digits to ignore in the event field name. For example, in a numeric OID like "1.3.6.1.2.1.1.1.0" the first 5 digits could be ignored by setting oid_root_skip => 5 which would result in a field name "1.1.1.0". Similarly when a MIB is used an OID such "1.3.6.1.2.mib-2.system.sysDescr.0" would become "mib-2.system.sysDescr.0"'),
		createSnippet('oid_path_length', 'option', 'oid_path_length => ${1:0}', '**[oid_path_length](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-snmp.html#plugins-inputs-snmp-oid_path_length) option**\n\n- Value type is number\n- Default value is 0\n\nThe oid_path_length option specifies the number of OID root digits to retain in the event field name. For example, in a numeric OID like "1.3.6.1.2.1.1.1.0" the last 2 digits could be retained by setting oid_path_length => 2 which would result in a field name "1.0". Similarly when a MIB is used an OID such "1.3.6.1.2.mib-2.system.sysDescr.0" would become "sysDescr.0"'),
		createSnippet('walk', 'option', 'walk => ["${1:walk}"]', '**[walk](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-snmp.html#plugins-inputs-snmp-walk) option**\n\n- Value type is array\n- There is no default value for this setting\n\nUse the walk option to retrieve the subtree of information for the given OID(s). One or more OID(s) are specified as an array of strings of OID(s).\n\n**_Example:_**  \n``` ruby\n  snmp {\n    walk => ["1.3.6.1.2.1.1"]\n    hosts => [{host => "udp:127.0.0.1/161" community => "public"}]\n  }\n}\n```'),
		createSnippet('tables', 'option', 'tables => ["${1:table}"]', '**[tables](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-snmp.html#plugins-inputs-snmp-tables) option**\n\n- Value type is array\n- There is no default value for this setting\n- Results are returned under a field using the table name\n\nThe tables option is used to query for tabular values for the given column OID(s).\n\n**_Example:_**  \n``` ruby\ninput {\n  snmp {\n    hosts => [{host => "udp:127.0.0.1/161" community => "public" version => "2c"  retries => 2  timeout => 1000}]\n    tables => [ {"name" => "interfaces" "columns" => ["1.3.6.1.2.1.2.2.1.1", "1.3.6.1.2.1.2.2.1.2", "1.3.6.1.2.1.2.2.1.5"]} ]\n  }\n}\n```'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-snmp.html#plugins-inputs-snmp-target) option**\n\n- Value type is string\n- There is no default value for this setting\n\nThe name of the field under which SNMP payloads are assigned. If not specified data will be stored in the root of the event.')
	],
	'logstash-output-cloudwatch': [
		createSnippet('access_key_id', 'option', 'access_key_id => "${1:access_key_id}"', '**[access_key_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-cloudwatch.html#plugins-outputs-cloudwatch-access_key_id) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThis plugin uses the AWS SDK and supports several ways to get credentials, which will be tried in this order:'),
		createSnippet('aws_credentials_file', 'option', 'aws_credentials_file => "${1:aws_credentials_file}"', '**[aws_credentials_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-cloudwatch.html#plugins-outputs-cloudwatch-aws_credentials_file) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nPath to YAML file containing a hash of AWS credentials. This file will only be loaded if access_key_id and secret_access_key aren’t set. The contents of the file should look like this:'),
		createSnippet('batch_size', 'option', 'batch_size => ${1:20}', '**[batch_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-cloudwatch.html#plugins-outputs-cloudwatch-batch_size) option**\n\n- Value type is number\n- Default value is 20\n\nHow many data points can be given in one call to the CloudWatch API'),
		createSnippet('dimensions', 'option', 'dimensions => {\n\t"${1:key}" => "${2:value}"\n}', '**[dimensions](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-cloudwatch.html#plugins-outputs-cloudwatch-dimensions) option**\n\n- Value type is hash\n- There is no default value for this setting.\n\nThe default dimensions [ name, value, … ] to use for events which do not have a CW_dimensions field'),
		createSnippet('field_dimensions', 'option', 'field_dimensions => "${1:CW_dimensions}"', '**[field_dimensions](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-cloudwatch.html#plugins-outputs-cloudwatch-field_dimensions) option**\n\n- Value type is string\n- Default value is "CW_dimensions"\n\nThe name of the field used to set the dimensions on an event metric The field named here, if present in an event, must have an array of one or more key & value pairs, for example… add_field => [ "CW_dimensions", "Environment", "CW_dimensions", "prod" ] or, equivalently… add_field => [ "CW_dimensions", "Environment" ] add_field => [ "CW_dimensions", "prod" ]'),
		createSnippet('field_metricname', 'option', 'field_metricname => "${1:CW_metricname}"', '**[field_metricname](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-cloudwatch.html#plugins-outputs-cloudwatch-field_metricname) option**\n\n- Value type is string\n- Default value is "CW_metricname"\n\nThe name of the field used to set the metric name on an event The author of this plugin recommends adding this field to events in inputs & filters rather than using the per-output default setting so that one output plugin on your logstash indexer can serve all events (which of course had fields set on your logstash shippers.)'),
		createSnippet('field_namespace', 'option', 'field_namespace => "${1:CW_namespace}"', '**[field_namespace](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-cloudwatch.html#plugins-outputs-cloudwatch-field_namespace) option**\n\n- Value type is string\n- Default value is "CW_namespace"\n\nThe name of the field used to set a different namespace per event Note: Only one namespace can be sent to CloudWatch per API call so setting different namespaces will increase the number of API calls and those cost money.'),
		createSnippet('field_unit', 'option', 'field_unit => "${1:CW_unit}"', '**[field_unit](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-cloudwatch.html#plugins-outputs-cloudwatch-field_unit) option**\n\n- Value type is string\n- Default value is "CW_unit"\n\nThe name of the field used to set the unit on an event metric'),
		createSnippet('field_value', 'option', 'field_value => "${1:CW_value}"', '**[field_value](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-cloudwatch.html#plugins-outputs-cloudwatch-field_value) option**\n\n- Value type is string\n- Default value is "CW_value"\n\nThe name of the field used to set the value (float) on an event metric'),
		createSnippet('metricname', 'option', 'metricname => "${1:metricname}"', '**[metricname](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-cloudwatch.html#plugins-outputs-cloudwatch-metricname) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe default metric name to use for events which do not have a CW_metricname field. Beware: If this is provided then all events which pass through this output will be aggregated and sent to CloudWatch, so use this carefully. Furthermore, when providing this option, you will probably want to also restrict events from passing through this output using event type, tag, and field matching'),
		createSnippet('namespace', 'option', 'namespace => "${1:Logstash}"', '**[namespace](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-cloudwatch.html#plugins-outputs-cloudwatch-namespace) option**\n\n- Value type is string\n- Default value is "Logstash"\n\nThe default namespace to use for events which do not have a CW_namespace field'),
		createSnippet('proxy_uri', 'option', 'proxy_uri => "${1:proxy_uri}"', '**[proxy_uri](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-cloudwatch.html#plugins-outputs-cloudwatch-proxy_uri) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nURI to proxy server if required'),
		createSnippet('queue_size', 'option', 'queue_size => ${1:10000}', '**[queue_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-cloudwatch.html#plugins-outputs-cloudwatch-queue_size) option**\n\n- Value type is number\n- Default value is 10000\n\nHow many events to queue before forcing a call to the CloudWatch API ahead of timeframe schedule Set this to the number of events-per-timeframe you will be sending to CloudWatch to avoid extra API calls'),
		createSnippet('region', 'option', 'region => "${1|us-east-1,us-east-2,us-west-1,us-west-2,eu-central-1,eu-west-1,eu-west-2,ap-southeast-1,ap-southeast-2,ap-northeast-1,ap-northeast-2,sa-east-1,us-gov-west-1,cn-north-1,ap-south-1,ca-central-1|}"$0', '**[region](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-cloudwatch.html#plugins-outputs-cloudwatch-region) option**\n\n- Value can be any of: us-east-1, us-east-2, us-west-1, us-west-2, eu-central-1, eu-west-1, eu-west-2, ap-southeast-1, ap-southeast-2, ap-northeast-1, ap-northeast-2, sa-east-1, us-gov-west-1, cn-north-1, ap-south-1, ca-central-1\n- Default value is "us-east-1"\n\nThe AWS Region'),
		createSnippet('secret_access_key', 'option', 'secret_access_key => "${1:secret_access_key}"', '**[secret_access_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-cloudwatch.html#plugins-outputs-cloudwatch-secret_access_key) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS Secret Access Key'),
		createSnippet('session_token', 'option', 'session_token => "${1:session_token}"', '**[session_token](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-cloudwatch.html#plugins-outputs-cloudwatch-session_token) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS Session token for temporary credential'),
		createSnippet('timeframe', 'option', 'timeframe => "${1:1m}"', '**[timeframe](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-cloudwatch.html#plugins-outputs-cloudwatch-timeframe) option**\n\n- Value type is string\n- Default value is "1m"\n\nConstants aggregate_key members Units How often to send data to CloudWatch This does not affect the event timestamps, events will always have their actual timestamp (to-the-minute) sent to CloudWatch.'),
		createSnippet('unit', 'option', 'unit => "${1|Count,Microseconds,Milliseconds,Bytes,Kilobytes,Megabytes,Gigabytes,Terabytes,Bits,Kilobits,Megabits,Gigabits,Terabits,Percent,Seconds,Bytes/Second,Kilobytes/Second,Megabytes/Second,Gigabytes/Second,Terabytes/Second,Bits/Second,Kilobits/Second,Megabits/Second,Gigabits/Second,Terabits/Second,Count/Second,None|}"$0', '**[unit](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-cloudwatch.html#plugins-outputs-cloudwatch-unit) option**\n\n- Value can be any of: Seconds, Microseconds, Milliseconds, Bytes, Kilobytes, Megabytes, Gigabytes, Terabytes, Bits, Kilobits, Megabits, Gigabits, Terabits, Percent, Count, Bytes/Second, Kilobytes/Second, Megabytes/Second, Gigabytes/Second, Terabytes/Second, Bits/Second, Kilobits/Second, Megabits/Second, Gigabits/Second, Terabits/Second, Count/Second, None\n- Default value is "Count"\n\nThe default unit to use for events which do not have a CW_unit field If you set this option you should probably set the "value" option along with it'),
		createSnippet('value', 'option', 'value => "${1:1}"', '**[value](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-cloudwatch.html#plugins-outputs-cloudwatch-value) option**\n\n- Value type is string\n- Default value is "1"\n\nThe default value to use for events which do not have a CW_value field If provided, this must be a string which can be converted to a float, for example… "1", "2.34", ".5", and "0.67" If you set this option you should probably set the unit option along with it')
	],
	'logstash-output-google_bigquery': [
		createSnippet('batch_size', 'option', 'batch_size => ${1:128}', '**[batch_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-batch_size) option**\n\n- Value type is number\n- Default value is 128\n\nAdded in 4.0.0.'),
		createSnippet('batch_size_bytes', 'option', 'batch_size_bytes => ${1:1_000_000}', '**[batch_size_bytes](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-batch_size_bytes) option**\n\n- Value type is number\n- Default value is 1_000_000\n\nAdded in 4.0.0.'),
		createSnippet('csv_schema', 'option', 'csv_schema => "${1:csv_schema}"', '**[csv_schema](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-csv_schema) option**\n\n- Value type is string\n- Default value is nil\n\nSchema for log data. It must follow the format name1:type1(,name2:type2)*. For example, path:STRING,status:INTEGER,score:FLOAT.'),
		createSnippet('dataset', 'option', 'dataset => "${1:dataset}"', '**[dataset](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-dataset) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe BigQuery dataset the tables for the events will be added to.', true),
		createSnippet('date_pattern', 'option', 'date_pattern => "${1:%Y-%m-%dT%H:00}"', '**[date_pattern](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-date_pattern) option**\n\n- Value type is string\n- Default value is "%Y-%m-%dT%H:00"\n\nTime pattern for BigQuery table, defaults to hourly tables. Must Time.strftime patterns: www.ruby-doc.org/core-2.0/Time.html#method-i-strftime'),
		createSnippet('deleter_interval_secs', 'option', 'deleter_interval_secs => ${1:123}', '**[deleter_interval_secs](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-deleter_interval_secs) option**\n\n- Value type is number\n\nEvents are uploaded in real-time without being stored to disk.'),
		createSnippet('error_directory', 'option', 'error_directory => "${1:/tmp/bigquery}"', '**[error_directory](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-error_directory) option**\n\n- This is a required setting.\n- Value type is string\n- Default value is "/tmp/bigquery".\n\nAdded in 4.0.0.', true),
		createSnippet('flush_interval_secs', 'option', 'flush_interval_secs => ${1:5}', '**[flush_interval_secs](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-flush_interval_secs) option**\n\n- Value type is number\n- Default value is 5\n\nUploads all data this often even if other upload criteria aren’t met.'),
		createSnippet('ignore_unknown_values', 'option', 'ignore_unknown_values => ${1|false,true|}', '**[ignore_unknown_values](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-ignore_unknown_values) option**\n\n- Value type is boolean\n- Default value is false\n\nIndicates if BigQuery should ignore values that are not represented in the table schema. If true, the extra values are discarded. If false, BigQuery will reject the records with extra fields and the job will fail. The default value is false.'),
		createSnippet('json_key_file', 'option', 'json_key_file => "${1:json_key_file}"', '**[json_key_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-json_key_file) option**\n\n- Value type is string\n- Default value is nil\n\nReplaces key_password, key_path and service_account.'),
		createSnippet('json_schema', 'option', 'json_schema => {\n\t"${1:key}" => "${2:value}"\n}', '**[json_schema](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-json_schema) option**\n\n- Value type is hash\n- Default value is nil\n\nSchema for log data as a hash. These can include nested records, descriptions, and modes.\n\n**_Example:_**  \n``` ruby\njson_schema => {\n  fields => [{\n    name => "endpoint"\n    type => "STRING"\n    description => "Request route"\n  }, {\n    name => "status"\n    type => "INTEGER"\n    mode => "NULLABLE"\n  }, {\n    name => "params"\n    type => "RECORD"\n    mode => "REPEATED"\n    fields => [{\n      name => "key"\n      type => "STRING"\n     }, {\n      name => "value"\n      type => "STRING"\n    }]\n  }]\n}\n```'),
		createSnippet('key_password', 'option', 'key_password => "${1:key_password}"', '**[key_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-key_password) option**\n\n- Value type is string\n\nReplaced by json_key_file or by using ADC. See json_key_file'),
		createSnippet('key_path', 'option', 'key_path => "${1:key_path}"', '**[key_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-key_path) option**\n\n- Value type is string\n\nObsolete: The PKCS12 key file format is no longer supported.'),
		createSnippet('project_id', 'option', 'project_id => "${1:project_id}"', '**[project_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-project_id) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nGoogle Cloud Project ID (number, not Project Name!).', true),
		createSnippet('service_account', 'option', 'service_account => "${1:service_account}"', '**[service_account](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-service_account) option**\n\n- Value type is string\n\nReplaced by json_key_file or by using ADC. See json_key_file'),
		createSnippet('skip_invalid_rows', 'option', 'skip_invalid_rows => ${1|false,true|}', '**[skip_invalid_rows](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-skip_invalid_rows) option**\n\n- Value type is boolean\n- Default value is false\n\nAdded in 4.1.0.'),
		createSnippet('table_prefix', 'option', 'table_prefix => "${1:logstash}"', '**[table_prefix](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-table_prefix) option**\n\n- Value type is string\n- Default value is "logstash"\n\nBigQuery table ID prefix to be used when creating new tables for log data. Table name will be <table_prefix><table_separator><date>'),
		createSnippet('table_separator', 'option', 'table_separator => "${1:_}"', '**[table_separator](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-table_separator) option**\n\n- Value type is string\n- Default value is "_"\n\nBigQuery table separator to be added between the table_prefix and the date suffix.'),
		createSnippet('temp_directory', 'option', 'temp_directory => "${1:temp_directory}"', '**[temp_directory](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-temp_directory) option**\n\n- Value type is string\n\nEvents are uploaded in real-time without being stored to disk.'),
		createSnippet('temp_file_prefix', 'option', 'temp_file_prefix => "${1:temp_file_prefix}"', '**[temp_file_prefix](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-temp_file_prefix) option**\n\n- Value type is string\n\nEvents are uploaded in real-time without being stored to disk'),
		createSnippet('uploader_interval_secs', 'option', 'uploader_interval_secs => ${1:60}', '**[uploader_interval_secs](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html#plugins-outputs-google_bigquery-uploader_interval_secs) option**\n\n- Value type is number\n- Default value is 60\n\nThis field is no longer used')
	],
	'logstash-output-mongodb': [
		createSnippet('bulk', 'option', 'bulk => ${1|false,true|}', '**[bulk](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-mongodb.html#plugins-outputs-mongodb-bulk) option**\n\n- Value type is boolean\n- Default value is false\n\nBulk insert flag, set to true to allow bulk insertion, else it will insert events one by one.'),
		createSnippet('bulk_interval', 'option', 'bulk_interval => ${1:2}', '**[bulk_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-mongodb.html#plugins-outputs-mongodb-bulk_interval) option**\n\n- Value type is number\n- Default value is 2\n\nBulk interval, Used to insert events periodically if the "bulk" flag is activated.'),
		createSnippet('bulk_size', 'option', 'bulk_size => ${1:900}', '**[bulk_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-mongodb.html#plugins-outputs-mongodb-bulk_size) option**\n\n- Value type is number\n- Default value is 900\n\nBulk events number, if the number of events to insert into a collection raise that limit, it will be bulk inserted whatever the bulk interval value (mongodb hard limit is 1000).'),
		createSnippet('collection', 'option', 'collection => "${1:collection}"', '**[collection](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-mongodb.html#plugins-outputs-mongodb-collection) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe collection to use. This value can use %{foo} values to dynamically select a collection based on data in the event.', true),
		createSnippet('database', 'option', 'database => "${1:database}"', '**[database](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-mongodb.html#plugins-outputs-mongodb-database) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe database to use.', true),
		createSnippet('generateId', 'option', 'generateId => ${1|false,true|}', '**[generateId](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-mongodb.html#plugins-outputs-mongodb-generateId) option**\n\n- Value type is boolean\n- Default value is false\n\nIf true, an "_id" field will be added to the document before insertion. The "_id" field will use the timestamp of the event and overwrite an existing "_id" field in the event.'),
		createSnippet('isodate', 'option', 'isodate => ${1|false,true|}', '**[isodate](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-mongodb.html#plugins-outputs-mongodb-isodate) option**\n\n- Value type is boolean\n- Default value is false\n\nIf true, store the @timestamp field in MongoDB as an ISODate type instead of an ISO8601 string. For more information about this, see http://www.mongodb.org/display/DOCS/Dates.'),
		createSnippet('retry_delay', 'option', 'retry_delay => ${1:3}', '**[retry_delay](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-mongodb.html#plugins-outputs-mongodb-retry_delay) option**\n\n- Value type is number\n- Default value is 3\n\nThe number of seconds to wait after failure before retrying.'),
		createSnippet('uri', 'option', 'uri => "${1:uri}"', '**[uri](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-mongodb.html#plugins-outputs-mongodb-uri) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nA MongoDB URI to connect to. See http://docs.mongodb.org/manual/reference/connection-string/.', true)
	],
	'logstash-input-twitter': [
		createSnippet('consumer_key', 'option', 'consumer_key => "${1:consumer_key}"', '**[consumer_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-twitter.html#plugins-inputs-twitter-consumer_key) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nYour Twitter App’s consumer key', true),
		createSnippet('consumer_secret', 'option', 'consumer_secret => "${1:consumer_secret}"', '**[consumer_secret](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-twitter.html#plugins-inputs-twitter-consumer_secret) option**\n\n- This is a required setting.\n- Value type is password\n- There is no default value for this setting.\n\nYour Twitter App’s consumer secret', true),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-twitter.html#plugins-inputs-twitter-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: does not use ECS-compatible field names (fields might be set at the root of the event) v1, v8: avoids field names that might conflict with Elastic Common Schema (for example, Twitter specific properties)\n- disabled: does not use ECS-compatible field names (fields might be set at the root of the event)\n- v1, v8: avoids field names that might conflict with Elastic Common Schema (for example, Twitter specific properties)\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:'),
		createSnippet('follows', 'option', 'follows => ["${1:follow}"]', '**[follows](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-twitter.html#plugins-inputs-twitter-follows) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nA comma separated list of user IDs, indicating the users to return statuses for in the Twitter stream. See https://developer.twitter.com/en/docs/tweets/filter-realtime/guides/basic-stream-parameters for more details.'),
		createSnippet('full_tweet', 'option', 'full_tweet => ${1|false,true|}', '**[full_tweet](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-twitter.html#plugins-inputs-twitter-full_tweet) option**\n\n- Value type is boolean\n- Default value is false\n\nRecord full tweet object as given to us by the Twitter Streaming API.'),
		createSnippet('ignore_retweets', 'option', 'ignore_retweets => ${1|false,true|}', '**[ignore_retweets](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-twitter.html#plugins-inputs-twitter-ignore_retweets) option**\n\n- Value type is boolean\n- Default value is false\n\nLets you ignore the retweets coming out of the Twitter API. Default ⇒ false'),
		createSnippet('keywords', 'option', 'keywords => ["${1:keyword}"]', '**[keywords](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-twitter.html#plugins-inputs-twitter-keywords) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nAny keywords to track in the Twitter stream. For multiple keywords, use the syntax ["foo", "bar"]. There’s a logical OR between each keyword string listed and a logical AND between words separated by spaces per keyword string. See https://dev.twitter.com/streaming/overview/request-parameters#track for more details.'),
		createSnippet('languages', 'option', 'languages => ["${1:language}"]', '**[languages](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-twitter.html#plugins-inputs-twitter-languages) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nA list of BCP 47 language identifiers corresponding to any of the languages listed on Twitter’s advanced search page will only return tweets that have been detected as being written in the specified languages.'),
		createSnippet('locations', 'option', 'locations => "${1:locations}"', '**[locations](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-twitter.html#plugins-inputs-twitter-locations) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nA comma-separated list of longitude, latitude pairs specifying a set of bounding boxes to filter tweets by. See https://dev.twitter.com/streaming/overview/request-parameters#locations for more details.'),
		createSnippet('oauth_token', 'option', 'oauth_token => "${1:oauth_token}"', '**[oauth_token](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-twitter.html#plugins-inputs-twitter-oauth_token) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nYour oauth token.', true),
		createSnippet('oauth_token_secret', 'option', 'oauth_token_secret => "${1:oauth_token_secret}"', '**[oauth_token_secret](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-twitter.html#plugins-inputs-twitter-oauth_token_secret) option**\n\n- This is a required setting.\n- Value type is password\n- There is no default value for this setting.\n\nYour oauth token secret.', true),
		createSnippet('proxy_address', 'option', 'proxy_address => "${1:127.0.0.1}"', '**[proxy_address](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-twitter.html#plugins-inputs-twitter-proxy_address) option**\n\n- Value type is string\n- Default value is "127.0.0.1"\n\nLocation of the proxy, by default the same machine as the one running this LS instance'),
		createSnippet('proxy_port', 'option', 'proxy_port => ${1:3128}', '**[proxy_port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-twitter.html#plugins-inputs-twitter-proxy_port) option**\n\n- Value type is number\n- Default value is 3128\n\nPort where the proxy is listening, by default 3128 (squid)'),
		createSnippet('rate_limit_reset_in', 'option', 'rate_limit_reset_in => ${1:300}', '**[rate_limit_reset_in](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-twitter.html#plugins-inputs-twitter-rate_limit_reset_in) option**\n\n- Value type is number\n- Default value is 300\n\nDuration in seconds to wait before retrying a connection when twitter responds with a 429 TooManyRequests In some cases the x-rate-limit-reset header is not set in the response and <error>.rate_limit.reset_in is nil. If this occurs then we use the integer specified here. The default is 5 minutes.'),
		createSnippet('use_proxy', 'option', 'use_proxy => ${1|false,true|}', '**[use_proxy](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-twitter.html#plugins-inputs-twitter-use_proxy) option**\n\n- Value type is boolean\n- Default value is false\n\nWhen to use a proxy to handle the connections'),
		createSnippet('use_samples', 'option', 'use_samples => ${1|false,true|}', '**[use_samples](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-twitter.html#plugins-inputs-twitter-use_samples) option**\n\n- Value type is boolean\n- Default value is false\n\nReturns a small random sample of all public statuses. The tweets returned by the default access level are the same, so if two different clients connect to this endpoint, they will see the same tweets. If set to true, the keywords, follows, locations, and languages options will be ignored. Default ⇒ false'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-twitter.html#plugins-inputs-twitter-target) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nWithout a target, events are created from tweets at the root level. When the target is set to a field reference, the tweet data is placed in the target field instead.')
	],
	'logstash-codec-cloudfront': [
		createSnippet('charset', 'option', 'charset => "${1|UTF-8,ASCII-8BIT,US-ASCII,Big5,Big5-HKSCS,Big5-UAO,CP949,Emacs-Mule,EUC-JP,EUC-KR,EUC-TW,GB2312,GB18030,GBK,ISO-8859-1,ISO-8859-2,ISO-8859-3,ISO-8859-4,ISO-8859-5,ISO-8859-6,ISO-8859-7,ISO-8859-8,ISO-8859-9,ISO-8859-10,ISO-8859-11,ISO-8859-13,ISO-8859-14,ISO-8859-15,ISO-8859-16,KOI8-R,KOI8-U,Shift_JIS,UTF-16BE,UTF-16LE,UTF-32BE,UTF-32LE,Windows-31J,Windows-1250,Windows-1251,Windows-1252,IBM437,IBM737,IBM775,CP850,IBM852,CP852,IBM855,CP855,IBM857,IBM860,IBM861,IBM862,IBM863,IBM864,IBM865,IBM866,IBM869,Windows-1258,GB1988,macCentEuro,macCroatian,macCyrillic,macGreek,macIceland,macRoman,macRomania,macThai,macTurkish,macUkraine,CP950,CP951,IBM037,stateless-ISO-2022-JP,eucJP-ms,CP51932,EUC-JIS-2004,GB12345,ISO-2022-JP,ISO-2022-JP-2,CP50220,CP50221,Windows-1256,Windows-1253,Windows-1255,Windows-1254,TIS-620,Windows-874,Windows-1257,MacJapanese,UTF-7,UTF8-MAC,UTF-16,UTF-32,UTF8-DoCoMo,SJIS-DoCoMo,UTF8-KDDI,SJIS-KDDI,ISO-2022-JP-KDDI,stateless-ISO-2022-JP-KDDI,UTF8-SoftBank,SJIS-SoftBank,BINARY,CP437,CP737,CP775,IBM850,CP857,CP860,CP861,CP862,CP863,CP864,CP865,CP866,CP869,CP1258,Big5-HKSCS:2008,ebcdic-cp-us,eucJP,euc-jp-ms,EUC-JISX0213,eucKR,eucTW,EUC-CN,eucCN,CP936,ISO2022-JP,ISO2022-JP2,ISO8859-1,ISO8859-2,ISO8859-3,ISO8859-4,ISO8859-5,ISO8859-6,CP1256,ISO8859-7,CP1253,ISO8859-8,CP1255,ISO8859-9,CP1254,ISO8859-10,ISO8859-11,CP874,ISO8859-13,CP1257,ISO8859-14,ISO8859-15,ISO8859-16,CP878,MacJapan,ASCII,ANSI_X3.4-1968,646,CP65000,CP65001,UTF-8-MAC,UTF-8-HFS,UCS-2BE,UCS-4BE,UCS-4LE,CP932,csWindows31J,SJIS,PCK,CP1250,CP1251,CP1252,external,locale|}"$0', '**[charset](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-cloudfront.html#plugins-codecs-cloudfront-charset) option**\n\n- Value can be any of: ASCII-8BIT, UTF-8, US-ASCII, Big5, Big5-HKSCS, Big5-UAO, CP949, Emacs-Mule, EUC-JP, EUC-KR, EUC-TW, GB2312, GB18030, GBK, ISO-8859-1, ISO-8859-2, ISO-8859-3, ISO-8859-4, ISO-8859-5, ISO-8859-6, ISO-8859-7, ISO-8859-8, ISO-8859-9, ISO-8859-10, ISO-8859-11, ISO-8859-13, ISO-8859-14, ISO-8859-15, ISO-8859-16, KOI8-R, KOI8-U, Shift_JIS, UTF-16BE, UTF-16LE, UTF-32BE, UTF-32LE, Windows-31J, Windows-1250, Windows-1251, Windows-1252, IBM437, IBM737, IBM775, CP850, IBM852, CP852, IBM855, CP855, IBM857, IBM860, IBM861, IBM862, IBM863, IBM864, IBM865, IBM866, IBM869, Windows-1258, GB1988, macCentEuro, macCroatian, macCyrillic, macGreek, macIceland, macRoman, macRomania, macThai, macTurkish, macUkraine, CP950, CP951, IBM037, stateless-ISO-2022-JP, eucJP-ms, CP51932, EUC-JIS-2004, GB12345, ISO-2022-JP, ISO-2022-JP-2, CP50220, CP50221, Windows-1256, Windows-1253, Windows-1255, Windows-1254, TIS-620, Windows-874, Windows-1257, MacJapanese, UTF-7, UTF8-MAC, UTF-16, UTF-32, UTF8-DoCoMo, SJIS-DoCoMo, UTF8-KDDI, SJIS-KDDI, ISO-2022-JP-KDDI, stateless-ISO-2022-JP-KDDI, UTF8-SoftBank, SJIS-SoftBank, BINARY, CP437, CP737, CP775, IBM850, CP857, CP860, CP861, CP862, CP863, CP864, CP865, CP866, CP869, CP1258, Big5-HKSCS:2008, ebcdic-cp-us, eucJP, euc-jp-ms, EUC-JISX0213, eucKR, eucTW, EUC-CN, eucCN, CP936, ISO2022-JP, ISO2022-JP2, ISO8859-1, ISO8859-2, ISO8859-3, ISO8859-4, ISO8859-5, ISO8859-6, CP1256, ISO8859-7, CP1253, ISO8859-8, CP1255, ISO8859-9, CP1254, ISO8859-10, ISO8859-11, CP874, ISO8859-13, CP1257, ISO8859-14, ISO8859-15, ISO8859-16, CP878, MacJapan, ASCII, ANSI_X3.4-1968, 646, CP65000, CP65001, UTF-8-MAC, UTF-8-HFS, UCS-2BE, UCS-4BE, UCS-4LE, CP932, csWindows31J, SJIS, PCK, CP1250, CP1251, CP1252, external, locale\n- Default value is "UTF-8"\n\nThe character encoding used in this codec. Examples include "UTF-8" and "CP1252"')
	],
	'logstash-output-solr_http': [
		createSnippet('document_id', 'option', 'document_id => "${1:document_id}"', '**[document_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-solr_http.html#plugins-outputs-solr_http-document_id) option**\n\n- Value type is string\n- Default value is nil\n\nSolr document ID for events. You’d typically have a variable here, like %{foo} so you can assign your own IDs'),
		createSnippet('flush_size', 'option', 'flush_size => ${1:100}', '**[flush_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-solr_http.html#plugins-outputs-solr_http-flush_size) option**\n\n- Value type is number\n- Default value is 100\n\nNumber of events to queue up before writing to Solr'),
		createSnippet('idle_flush_time', 'option', 'idle_flush_time => ${1:1}', '**[idle_flush_time](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-solr_http.html#plugins-outputs-solr_http-idle_flush_time) option**\n\n- Value type is number\n- Default value is 1\n\nAmount of time since the last flush before a flush is done even if the number of buffered events is smaller than flush_size'),
		createSnippet('solr_url', 'option', 'solr_url => "${1:http://localhost:8983/solr}"', '**[solr_url](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-solr_http.html#plugins-outputs-solr_http-solr_url) option**\n\n- Value type is string\n- Default value is "http://localhost:8983/solr"\n\nURL used to connect to Solr')
	],
	'logstash-filter-clone': [
		createSnippet('clones', 'option', 'clones => ["${1:clone}"]', '**[clones](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-clone.html#plugins-filters-clone-clones) option**\n\n- This is a required setting.\n- Value type is array\n- There is no default value for this setting.\n- a new clone will be created with a type of the given value in this list when ECS is disabled\n- a new clone will be created with a tags of the given value in this list when ECS is enabled\n\nNote: setting an empty array will not create any clones. A warning message is logged.', true),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-clone.html#plugins-filters-clone-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: does not use ECS-compatible field names v1, v8: uses fields that are compatible with Elastic Common Schema\n- disabled: does not use ECS-compatible field names\n- v1, v8: uses fields that are compatible with Elastic Common Schema\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:')
	],
	'logstash-input-imap': [
		createSnippet('attachments_target', 'option', 'attachments_target => "${1:attachments_target}"', '**[attachments_target](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html#plugins-inputs-imap-attachments_target) option**\n\n- Value type is string\n- Default value depends on whether ecs_compatibility is enabled: ECS Compatibility disabled: "[attachments]" ECS Compatibility enabled: `"[@metadata][input][imap][attachments]"\n- ECS Compatibility disabled: "[attachments]"\n- ECS Compatibility enabled: `"[@metadata][input][imap][attachments]"\n\nDefault value depends on whether ecs_compatibility is enabled:'),
		createSnippet('check_interval', 'option', 'check_interval => ${1:300}', '**[check_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html#plugins-inputs-imap-check_interval) option**\n\n- Value type is number\n- Default value is 300'),
		createSnippet('content_type', 'option', 'content_type => "${1:text/plain}"', '**[content_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html#plugins-inputs-imap-content_type) option**\n\n- Value type is string\n- Default value is "text/plain"\n\nFor multipart messages, use the first part that has this content-type as the event message.'),
		createSnippet('delete', 'option', 'delete => ${1|false,true|}', '**[delete](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html#plugins-inputs-imap-delete) option**\n\n- Value type is boolean\n- Default value is false'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html#plugins-inputs-imap-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: does not use ECS-compatible field names (for example, From header field is added to the event) v1, v8: avoids field names that might conflict with Elastic Common Schema (for example, the From header is added as metadata)\n- disabled: does not use ECS-compatible field names (for example, From header field is added to the event)\n- v1, v8: avoids field names that might conflict with Elastic Common Schema (for example, the From header is added as metadata)\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:'),
		createSnippet('expunge', 'option', 'expunge => ${1|false,true|}', '**[expunge](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html#plugins-inputs-imap-expunge) option**\n\n- Value type is boolean\n- Default value is false'),
		createSnippet('fetch_count', 'option', 'fetch_count => ${1:50}', '**[fetch_count](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html#plugins-inputs-imap-fetch_count) option**\n\n- Value type is number\n- Default value is 50'),
		createSnippet('folder', 'option', 'folder => "${1:INBOX}"', '**[folder](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html#plugins-inputs-imap-folder) option**\n\n- Value type is string\n- Default value is "INBOX"'),
		createSnippet('headers_target', 'option', 'headers_target => "${1:headers_target}"', '**[headers_target](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html#plugins-inputs-imap-headers_target) option**\n\n- Value type is string\n- Default value depends on whether ecs_compatibility is enabled: ECS Compatibility disabled: no default value (for example, the subject header is stored under the "subject" name) ECS Compatibility enabled: "[@metadata][input][imap][headers]"\n- ECS Compatibility disabled: no default value (for example, the subject header is stored under the "subject" name)\n- ECS Compatibility enabled: "[@metadata][input][imap][headers]"\n\nDefault value depends on whether ecs_compatibility is enabled:'),
		createSnippet('host', 'option', 'host => "${1:host}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html#plugins-inputs-imap-host) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.', true),
		createSnippet('lowercase_headers', 'option', 'lowercase_headers => ${1|true,false|}', '**[lowercase_headers](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html#plugins-inputs-imap-lowercase_headers) option**\n\n- Value type is boolean\n- Default value is true'),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html#plugins-inputs-imap-password) option**\n\n- This is a required setting.\n- Value type is password\n- There is no default value for this setting.', true),
		createSnippet('port', 'option', 'port => ${1:123}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html#plugins-inputs-imap-port) option**\n\n- Value type is number\n- There is no default value for this setting.'),
		createSnippet('save_attachments', 'option', 'save_attachments => ${1|false,true|}', '**[save_attachments](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html#plugins-inputs-imap-save_attachments) option**\n\n- Value type is boolean\n- Default value is false\n\nWhen set to true the content of attachments will be included in the attachments.data field.'),
		createSnippet('secure', 'option', 'secure => ${1|true,false|}', '**[secure](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html#plugins-inputs-imap-secure) option**\n\n- Value type is boolean\n- Default value is true'),
		createSnippet('sincedb_path', 'option', 'sincedb_path => "${1:sincedb_path}"', '**[sincedb_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html#plugins-inputs-imap-sincedb_path) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nPath of the sincedb database file (keeps track of the UID of the last processed mail) that will be written to disk. The default will write sincedb file to <path.data>/plugins/inputs/imap directory. NOTE: it must be a file path and not a directory path.'),
		createSnippet('strip_attachments', 'option', 'strip_attachments => ${1|false,true|}', '**[strip_attachments](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html#plugins-inputs-imap-strip_attachments) option**\n\n- Value type is boolean\n- Default value is false'),
		createSnippet('uid_tracking', 'option', 'uid_tracking => ${1|false,true|}', '**[uid_tracking](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html#plugins-inputs-imap-uid_tracking) option**\n\n- Value type is boolean\n- Default value is false\n\nWhen the IMAP input plugin connects to the mailbox for the first time and the UID of the last processed mail is not yet known, the unread mails are first downloaded and the UID of the last processed mail is saved. From this point on, if uid_tracking is set to true, all new mail will be downloaded regardless of whether they are marked as read or unread. This allows users or other services to use the mailbox simultaneously with the IMAP input plugin. UID of the last processed mail is always saved regardles of the uid_tracking value, so you can switch its value as needed. In transition from the previous IMAP input plugin version, first process at least one mail with uid_tracking set to false to save the UID of the last processed mail and then switch uid_tracking to true.'),
		createSnippet('user', 'option', 'user => "${1:user}"', '**[user](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html#plugins-inputs-imap-user) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.', true),
		createSnippet('verify_cert', 'option', 'verify_cert => ${1|true,false|}', '**[verify_cert](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html#plugins-inputs-imap-verify_cert) option**\n\n- Value type is boolean\n- Default value is true')
	],
	'logstash-codec-json_lines': [
		createSnippet('charset', 'option', 'charset => "${1|UTF-8,ASCII-8BIT,US-ASCII,Big5,Big5-HKSCS,Big5-UAO,CP949,Emacs-Mule,EUC-JP,EUC-KR,EUC-TW,GB2312,GB18030,GBK,ISO-8859-1,ISO-8859-2,ISO-8859-3,ISO-8859-4,ISO-8859-5,ISO-8859-6,ISO-8859-7,ISO-8859-8,ISO-8859-9,ISO-8859-10,ISO-8859-11,ISO-8859-13,ISO-8859-14,ISO-8859-15,ISO-8859-16,KOI8-R,KOI8-U,Shift_JIS,UTF-16BE,UTF-16LE,UTF-32BE,UTF-32LE,Windows-31J,Windows-1250,Windows-1251,Windows-1252,IBM437,IBM737,IBM775,CP850,IBM852,CP852,IBM855,CP855,IBM857,IBM860,IBM861,IBM862,IBM863,IBM864,IBM865,IBM866,IBM869,Windows-1258,GB1988,macCentEuro,macCroatian,macCyrillic,macGreek,macIceland,macRoman,macRomania,macThai,macTurkish,macUkraine,CP950,CP951,IBM037,stateless-ISO-2022-JP,eucJP-ms,CP51932,EUC-JIS-2004,GB12345,ISO-2022-JP,ISO-2022-JP-2,CP50220,CP50221,Windows-1256,Windows-1253,Windows-1255,Windows-1254,TIS-620,Windows-874,Windows-1257,MacJapanese,UTF-7,UTF8-MAC,UTF-16,UTF-32,UTF8-DoCoMo,SJIS-DoCoMo,UTF8-KDDI,SJIS-KDDI,ISO-2022-JP-KDDI,stateless-ISO-2022-JP-KDDI,UTF8-SoftBank,SJIS-SoftBank,BINARY,CP437,CP737,CP775,IBM850,CP857,CP860,CP861,CP862,CP863,CP864,CP865,CP866,CP869,CP1258,Big5-HKSCS:2008,ebcdic-cp-us,eucJP,euc-jp-ms,EUC-JISX0213,eucKR,eucTW,EUC-CN,eucCN,CP936,ISO2022-JP,ISO2022-JP2,ISO8859-1,ISO8859-2,ISO8859-3,ISO8859-4,ISO8859-5,ISO8859-6,CP1256,ISO8859-7,CP1253,ISO8859-8,CP1255,ISO8859-9,CP1254,ISO8859-10,ISO8859-11,CP874,ISO8859-13,CP1257,ISO8859-14,ISO8859-15,ISO8859-16,CP878,MacJapan,ASCII,ANSI_X3.4-1968,646,CP65000,CP65001,UTF-8-MAC,UTF-8-HFS,UCS-2BE,UCS-4BE,UCS-4LE,CP932,csWindows31J,SJIS,PCK,CP1250,CP1251,CP1252,external,locale|}"$0', '**[charset](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-json_lines.html#plugins-codecs-json_lines-charset) option**\n\n- Value can be any of: ASCII-8BIT, UTF-8, US-ASCII, Big5, Big5-HKSCS, Big5-UAO, CP949, Emacs-Mule, EUC-JP, EUC-KR, EUC-TW, GB2312, GB18030, GBK, ISO-8859-1, ISO-8859-2, ISO-8859-3, ISO-8859-4, ISO-8859-5, ISO-8859-6, ISO-8859-7, ISO-8859-8, ISO-8859-9, ISO-8859-10, ISO-8859-11, ISO-8859-13, ISO-8859-14, ISO-8859-15, ISO-8859-16, KOI8-R, KOI8-U, Shift_JIS, UTF-16BE, UTF-16LE, UTF-32BE, UTF-32LE, Windows-31J, Windows-1250, Windows-1251, Windows-1252, IBM437, IBM737, IBM775, CP850, IBM852, CP852, IBM855, CP855, IBM857, IBM860, IBM861, IBM862, IBM863, IBM864, IBM865, IBM866, IBM869, Windows-1258, GB1988, macCentEuro, macCroatian, macCyrillic, macGreek, macIceland, macRoman, macRomania, macThai, macTurkish, macUkraine, CP950, CP951, IBM037, stateless-ISO-2022-JP, eucJP-ms, CP51932, EUC-JIS-2004, GB12345, ISO-2022-JP, ISO-2022-JP-2, CP50220, CP50221, Windows-1256, Windows-1253, Windows-1255, Windows-1254, TIS-620, Windows-874, Windows-1257, MacJapanese, UTF-7, UTF8-MAC, UTF-16, UTF-32, UTF8-DoCoMo, SJIS-DoCoMo, UTF8-KDDI, SJIS-KDDI, ISO-2022-JP-KDDI, stateless-ISO-2022-JP-KDDI, UTF8-SoftBank, SJIS-SoftBank, BINARY, CP437, CP737, CP775, IBM850, CP857, CP860, CP861, CP862, CP863, CP864, CP865, CP866, CP869, CP1258, Big5-HKSCS:2008, ebcdic-cp-us, eucJP, euc-jp-ms, EUC-JISX0213, eucKR, eucTW, EUC-CN, eucCN, CP936, ISO2022-JP, ISO2022-JP2, ISO8859-1, ISO8859-2, ISO8859-3, ISO8859-4, ISO8859-5, ISO8859-6, CP1256, ISO8859-7, CP1253, ISO8859-8, CP1255, ISO8859-9, CP1254, ISO8859-10, ISO8859-11, CP874, ISO8859-13, CP1257, ISO8859-14, ISO8859-15, ISO8859-16, CP878, MacJapan, ASCII, ANSI_X3.4-1968, 646, CP65000, CP65001, UTF-8-MAC, UTF-8-HFS, UCS-2BE, UCS-4BE, UCS-4LE, CP932, csWindows31J, SJIS, PCK, CP1250, CP1251, CP1252, external, locale\n- Default value is "UTF-8"\n\nThe character encoding used in this codec. Examples include UTF-8 and CP1252'),
		createSnippet('delimiter', 'option', 'delimiter => "${1:\n}"', '**[delimiter](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-json_lines.html#plugins-codecs-json_lines-delimiter) option**\n\n- Value type is string\n- Default value is "\n"\n\nChange the delimiter that separates lines'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-json_lines.html#plugins-codecs-json_lines-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: does not use ECS-compatible field names v1, v8: Elastic Common Schema compliant behavior (warns when target isn’t set)\n- disabled: does not use ECS-compatible field names\n- v1, v8: Elastic Common Schema compliant behavior (warns when target isn’t set)\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled\n\nSupported values are:'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-json_lines.html#plugins-codecs-json_lines-target) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nDefine the target field for placing the parsed data. If this setting is not set, the JSON data will be stored at the root (top level) of the event.\n\n**_Example:_**  \n``` ruby\n    input {\n      http {\n        codec => json_lines {\n          target => "[document]"\n        }\n      }\n    }\n```')
	],
	'logstash-filter-grok': [
		createSnippet('match', 'option', 'match => {\n\t"${1:field}" => "${2:pattern}"\n}', '**[match](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-grok.html#plugins-filters-grok-match) option**\n\n- Value type is hash\n- Default value is {}\n\nA hash that defines the mapping of where to look, and with which patterns.\n\n**_Example:_**  \n``` ruby\n    filter {\n      grok {\n        match => {\n          "message" => "Duration: %{NUMBER:duration}"\n        }\n      }\n    }\n```'),
		createSnippet('break_on_match', 'option', 'break_on_match => ${1|true,false|}', '**[break_on_match](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-grok.html#plugins-filters-grok-break_on_match) option**\n\n- Value type is boolean\n- Default value is true\n\nBreak on first match. The first successful match by grok will result in the filter being finished. If you want grok to try all patterns (maybe you are parsing different things), then set this to false.'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-grok.html#plugins-filters-grok-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: the plugin will load legacy (built-in) pattern definitions v1,v8: all patterns provided by the plugin will use ECS compliant captures\n- disabled: the plugin will load legacy (built-in) pattern definitions\n- v1,v8: all patterns provided by the plugin will use ECS compliant captures\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:'),
		createSnippet('keep_empty_captures', 'option', 'keep_empty_captures => ${1|false,true|}', '**[keep_empty_captures](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-grok.html#plugins-filters-grok-keep_empty_captures) option**\n\n- Value type is boolean\n- Default value is false\n\nIf true, keep empty captures as event fields.'),
		createSnippet('named_captures_only', 'option', 'named_captures_only => ${1|true,false|}', '**[named_captures_only](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-grok.html#plugins-filters-grok-named_captures_only) option**\n\n- Value type is boolean\n- Default value is true\n\nIf true, only store named captures from grok.'),
		createSnippet('overwrite', 'option', 'overwrite => ["${1:overwrite}"]', '**[overwrite](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-grok.html#plugins-filters-grok-overwrite) option**\n\n- Value type is array\n- Default value is []\n\nThe fields to overwrite.\n\n**_Example:_**  \n``` ruby\n    filter {\n      grok {\n        match => { "message" => "%{SYSLOGBASE} %{DATA:message}" }\n        overwrite => [ "message" ]\n      }\n    }\n```'),
		createSnippet('pattern_definitions', 'option', 'pattern_definitions => {\n\t"${1:key}" => "${2:value}"\n}', '**[pattern_definitions](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-grok.html#plugins-filters-grok-pattern_definitions) option**\n\n- Value type is hash\n- Default value is {}\n\nA hash of pattern-name and pattern tuples defining custom patterns to be used by the current filter. Patterns matching existing names will override the pre-existing definition. Think of this as inline patterns available just for this definition of grok'),
		createSnippet('patterns_dir', 'option', 'patterns_dir => ["${1:patterns_dir}"]', '**[patterns_dir](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-grok.html#plugins-filters-grok-patterns_dir) option**\n\n- Value type is array\n- Default value is []\n\nLogstash ships by default with a bunch of patterns, so you don’t necessarily need to define this yourself unless you are adding additional patterns. You can point to multiple pattern directories using this setting. Note that Grok will read all files in the directory matching the patterns_files_glob and assume it’s a pattern file (including any tilde backup files).\n\n**_Example:_**  \n``` ruby\n    patterns_dir => ["/opt/logstash/patterns", "/opt/logstash/extra_patterns"]\n```'),
		createSnippet('patterns_files_glob', 'option', 'patterns_files_glob => "${1:*}"', '**[patterns_files_glob](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-grok.html#plugins-filters-grok-patterns_files_glob) option**\n\n- Value type is string\n- Default value is "*"\n\nGlob pattern, used to select the pattern files in the directories specified by patterns_dir'),
		createSnippet('tag_on_failure', 'option', 'tag_on_failure => ["${1:_grokparsefailure}"]', '**[tag_on_failure](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-grok.html#plugins-filters-grok-tag_on_failure) option**\n\n- Value type is array\n- Default value is ["_grokparsefailure"]\n\nAppend values to the tags field when there has been no successful match'),
		createSnippet('tag_on_timeout', 'option', 'tag_on_timeout => "${1:_groktimeout}"', '**[tag_on_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-grok.html#plugins-filters-grok-tag_on_timeout) option**\n\n- Value type is string\n- Default value is "_groktimeout"\n\nTag to apply if a grok regexp times out.'),
		createSnippet('timeout_millis', 'option', 'timeout_millis => ${1:30000}', '**[timeout_millis](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-grok.html#plugins-filters-grok-timeout_millis) option**\n\n- Value type is number\n- Default value is 30000\n\nAttempt to terminate regexps after this amount of time. This applies per pattern if multiple patterns are applied This will never timeout early, but may take a little longer to timeout. Actual timeout is approximate based on a 250ms quantization. Set to 0 to disable timeouts'),
		createSnippet('timeout_scope', 'option', 'timeout_scope => "${1:pattern}"', '**[timeout_scope](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-grok.html#plugins-filters-grok-timeout_scope) option**\n\n- Value type is string\n- Default value is "pattern"\n- Supported values are "pattern" and "event"\n\nWhen multiple patterns are provided to match, the timeout has historically applied to each pattern, incurring overhead for each and every pattern that is attempted; when the grok filter is configured with timeout_scope => event, the plugin instead enforces a single timeout across all attempted matches on the event, so it can achieve similar safeguard against runaway matchers with significantly less overhead.')
	],
	'logstash-input-pipeline': [
		createSnippet('address', 'option', 'address => "${1:address}"', '**[address](https://www.elastic.co/guide/en/logstash/7.17/pipeline-to-pipeline.html) option**\n\nAddress of the pipeline', true)
	],
	'logstash-input-heartbeat': [
		createSnippet('count', 'option', 'count => ${1:-1}', '**[count](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-heartbeat.html#plugins-inputs-heartbeat-count) option**\n\n- Value type is number\n- Default value is -1\n\nHow many times to iterate. This is typically used only for testing purposes.'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-heartbeat.html#plugins-inputs-heartbeat-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: clock counter field added at root level v1,v8: ECS compliant [event][sequence] counter field added to the event\n- disabled: clock counter field added at root level\n- v1,v8: ECS compliant [event][sequence] counter field added to the event\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:'),
		createSnippet('interval', 'option', 'interval => ${1:60}', '**[interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-heartbeat.html#plugins-inputs-heartbeat-interval) option**\n\n- Value type is number\n- Default value is 60\n\nSet how frequently messages should be sent.'),
		createSnippet('message', 'option', 'message => "${1:ok}"', '**[message](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-heartbeat.html#plugins-inputs-heartbeat-message) option**\n\n- Value type is string\n- Default value is "ok"\n\nThe message string to use in the event.'),
		createSnippet('sequence', 'option', 'sequence => "${1|none,epoch,sequence|}"$0', '**[sequence](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-heartbeat.html#plugins-inputs-heartbeat-sequence) option**\n\n- Value can be any of: none, epoch, sequence\n- Default value is "none""\n\nIf you set this value to none, then no sequence field is added.'),
		createSnippet('threads', 'option', 'threads => ${1:1}', '**[threads](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-heartbeat.html#plugins-inputs-heartbeat-threads) option**\n\n- Value type is number\n- Default value is 1')
	],
	'logstash-filter-i18n': [
		createSnippet('transliterate', 'option', 'transliterate => ["${1:transliterate}"]', '**[transliterate](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-i18n.html#plugins-filters-i18n-transliterate) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nReplaces non-ASCII characters with an ASCII approximation, or if none exists, a replacement character which defaults to ?\n\n**_Example:_**  \n``` ruby\n    filter {\n      i18n {\n         transliterate => ["field1", "field2"]\n      }\n    }\n```')
	],
	'logstash-output-opentsdb': [
		createSnippet('host', 'option', 'host => "${1:localhost}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-opentsdb.html#plugins-outputs-opentsdb-host) option**\n\n- Value type is string\n- Default value is "localhost"\n\nThe address of the opentsdb server.'),
		createSnippet('metrics', 'option', 'metrics => ["${1:metric}"]', '**[metrics](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-opentsdb.html#plugins-outputs-opentsdb-metrics) option**\n\n- This is a required setting.\n- Value type is array\n- There is no default value for this setting.\n\nThe metric(s) to use. This supports dynamic strings like %{source_host} for metric names and also for values. This is an array field with key of the metric name, value of the metric value, and multiple tag,values . Example:', true),
		createSnippet('port', 'option', 'port => ${1:4242}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-opentsdb.html#plugins-outputs-opentsdb-port) option**\n\n- Value type is number\n- Default value is 4242\n\nThe port to connect on your graphite server.')
	],
	'logstash-codec-common_options': [
	],
	'logstash-output-graphite': [
		createSnippet('exclude_metrics', 'option', 'exclude_metrics => ["${1:%{[^\\}]+\\}}"]', '**[exclude_metrics](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphite.html#plugins-outputs-graphite-exclude_metrics) option**\n\n- Value type is array\n- Default value is ["%{[^}]+}"]\n\nExclude regex matched metric names, by default exclude unresolved %{field} strings.'),
		createSnippet('fields_are_metrics', 'option', 'fields_are_metrics => ${1|false,true|}', '**[fields_are_metrics](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphite.html#plugins-outputs-graphite-fields_are_metrics) option**\n\n- Value type is boolean\n- Default value is false\n\nAn array indicating that these event fields should be treated as metrics and will be sent verbatim to Graphite. You may use either fields_are_metrics or metrics, but not both.'),
		createSnippet('host', 'option', 'host => "${1:localhost}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphite.html#plugins-outputs-graphite-host) option**\n\n- Value type is string\n- Default value is "localhost"\n\nThe hostname or IP address of the Graphite server.'),
		createSnippet('include_metrics', 'option', 'include_metrics => ["${1:.*}"]', '**[include_metrics](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphite.html#plugins-outputs-graphite-include_metrics) option**\n\n- Value type is array\n- Default value is [".*"]\n\nInclude only regex matched metric names.'),
		createSnippet('metrics', 'option', 'metrics => {\n\t"${1:key}" => "${2:value}"\n}', '**[metrics](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphite.html#plugins-outputs-graphite-metrics) option**\n\n- Value type is hash\n- Default value is {}\n\nThe metric(s) to use. This supports dynamic strings like %{host} for metric names and also for values. This is a hash field with key being the metric name, value being the metric value. Example:\n\n**_Example:_**  \n``` ruby\n    metrics => { "%{host}/uptime" => "%{uptime_1m}" }\n```'),
		createSnippet('metrics_format', 'option', 'metrics_format => "${1:*}"', '**[metrics_format](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphite.html#plugins-outputs-graphite-metrics_format) option**\n\n- Value type is string\n- Default value is "*"\n\nDefines the format of the metric string. The placeholder * will be replaced with the name of the actual metric.\n\n**_Example:_**  \n``` ruby\n    metrics_format => "foo.bar.*.sum"\n```'),
		createSnippet('nested_object_separator', 'option', 'nested_object_separator => "${1:.}"', '**[nested_object_separator](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphite.html#plugins-outputs-graphite-nested_object_separator) option**\n\n- Value type is string\n- Default value is "."\n\nWhen hashes are passed in as values they are broken out into a dotted notation For instance if you configure this plugin with # [source,ruby] metrics ⇒ "mymetrics"'),
		createSnippet('port', 'option', 'port => ${1:2003}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphite.html#plugins-outputs-graphite-port) option**\n\n- Value type is number\n- Default value is 2003\n\nThe port to connect to on the Graphite server.'),
		createSnippet('reconnect_interval', 'option', 'reconnect_interval => ${1:2}', '**[reconnect_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphite.html#plugins-outputs-graphite-reconnect_interval) option**\n\n- Value type is number\n- Default value is 2\n\nInterval between reconnect attempts to Carbon.'),
		createSnippet('resend_on_failure', 'option', 'resend_on_failure => ${1|false,true|}', '**[resend_on_failure](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphite.html#plugins-outputs-graphite-resend_on_failure) option**\n\n- Value type is boolean\n- Default value is false\n\nShould metrics be resent on failure?'),
		createSnippet('timestamp_field', 'option', 'timestamp_field => "${1:@timestamp}"', '**[timestamp_field](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphite.html#plugins-outputs-graphite-timestamp_field) option**\n\n- Value type is string\n- Default value is "@timestamp"\n\nUse this field for the timestamp instead of @timestamp which is the default. Useful when backfilling or just getting more accurate data into graphite since you probably have a cache layer infront of Logstash.')
	],
	'logstash-filter-elasticsearch': [
		createSnippet('aggregation_fields', 'option', 'aggregation_fields => {\n\t"${1:key}" => "${2:value}"\n}', '**[aggregation_fields](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elasticsearch.html#plugins-filters-elasticsearch-aggregation_fields) option**\n\n- Value type is hash\n- Default value is {}\n\nHash of aggregation names to copy from elasticsearch response into Logstash event fields\n\n**_Example:_**  \n``` ruby\n    filter {\n      elasticsearch {\n        aggregation_fields => {\n          "my_agg_name" => "my_ls_field"\n        }\n      }\n    }\n```'),
		createSnippet('api_key', 'option', 'api_key => "${1:api_key}"', '**[api_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elasticsearch.html#plugins-filters-elasticsearch-api_key) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nAuthenticate using Elasticsearch API key. Note that this option also requires enabling the ssl option.'),
		createSnippet('ca_file', 'option', 'ca_file => "${1:/path/to/file}"', '**[ca_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elasticsearch.html#plugins-filters-elasticsearch-ca_file) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nSSL Certificate Authority file'),
		createSnippet('cloud_auth', 'option', 'cloud_auth => "${1:cloud_auth}"', '**[cloud_auth](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elasticsearch.html#plugins-filters-elasticsearch-cloud_auth) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nCloud authentication string ("<username>:<password>" format) is an alternative for the user/password pair.'),
		createSnippet('cloud_id', 'option', 'cloud_id => "${1:cloud_id}"', '**[cloud_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elasticsearch.html#plugins-filters-elasticsearch-cloud_id) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nCloud ID, from the Elastic Cloud web console. If set hosts should not be used.'),
		createSnippet('docinfo_fields', 'option', 'docinfo_fields => {\n\t"${1:key}" => "${2:value}"\n}', '**[docinfo_fields](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elasticsearch.html#plugins-filters-elasticsearch-docinfo_fields) option**\n\n- Value type is hash\n- Default value is {}\n\nHash of docinfo fields to copy from old event (found via elasticsearch) into new event\n\n**_Example:_**  \n``` ruby\n    filter {\n      elasticsearch {\n        docinfo_fields => {\n          "_id" => "document_id"\n          "_index" => "document_index"\n        }\n      }\n    }\n```'),
		createSnippet('enable_sort', 'option', 'enable_sort => ${1|true,false|}', '**[enable_sort](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elasticsearch.html#plugins-filters-elasticsearch-enable_sort) option**\n\n- Value type is boolean\n- Default value is true\n\nWhether results should be sorted or not'),
		createSnippet('fields', 'option', 'fields => {$1}', '**[fields](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elasticsearch.html#plugins-filters-elasticsearch-fields) option**\n\n- Value type is array\n- Default value is {}\n\nAn array of fields to copy from the old event (found via elasticsearch) into the new event, currently being processed.\n\n**_Example:_**  \n``` ruby\nfields => {\n  "@timestamp" => "started"\n  "event_id" => "start_id"\n}\n```'),
		createSnippet('hosts', 'option', 'hosts => ["${1:localhost:9200}"]', '**[hosts](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elasticsearch.html#plugins-filters-elasticsearch-hosts) option**\n\n- Value type is array\n- Default value is ["localhost:9200"]\n\nList of elasticsearch hosts to use for querying.'),
		createSnippet('index', 'option', 'index => "${1:index}"', '**[index](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elasticsearch.html#plugins-filters-elasticsearch-index) option**\n\n- Value type is string\n- Default value is ""\n\nComma-delimited list of index names to search; use _all or empty string to perform the operation on all indices. Field substitution (e.g. index-name-%{date_field}) is available'),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elasticsearch.html#plugins-filters-elasticsearch-password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nBasic Auth - password'),
		createSnippet('proxy', 'option', 'proxy => ["${1:http://localhost}"]', '**[proxy](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elasticsearch.html#plugins-filters-elasticsearch-proxy) option**\n\n- Value type is uri\n- There is no default value for this setting.\n\nSet the address of a forward HTTP proxy. An empty string is treated as if proxy was not set, and is useful when using environment variables e.g. proxy => \'${LS_PROXY:}\'.'),
		createSnippet('query', 'option', 'query => "${1:query}"', '**[query](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elasticsearch.html#plugins-filters-elasticsearch-query) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nElasticsearch query string. More information is available in the Elasticsearch query string documentation.'),
		createSnippet('query_template', 'option', 'query_template => "${1:query_template}"', '**[query_template](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elasticsearch.html#plugins-filters-elasticsearch-query_template) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nFile path to elasticsearch query in DSL format. More information is available in the Elasticsearch query documentation.'),
		createSnippet('result_size', 'option', 'result_size => ${1:1}', '**[result_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elasticsearch.html#plugins-filters-elasticsearch-result_size) option**\n\n- Value type is number\n- Default value is 1\n\nHow many results to return'),
		createSnippet('sort', 'option', 'sort => "${1:@timestamp:desc}"', '**[sort](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elasticsearch.html#plugins-filters-elasticsearch-sort) option**\n\n- Value type is string\n- Default value is "@timestamp:desc"\n\nComma-delimited list of <field>:<direction> pairs that define the sort order'),
		createSnippet('ssl', 'option', 'ssl => ${1|false,true|}', '**[ssl](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elasticsearch.html#plugins-filters-elasticsearch-ssl) option**\n\n- Value type is boolean\n- Default value is false\n\nSSL'),
		createSnippet('tag_on_failure', 'option', 'tag_on_failure => ["${1:_elasticsearch_lookup_failure}"]', '**[tag_on_failure](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elasticsearch.html#plugins-filters-elasticsearch-tag_on_failure) option**\n\n- Value type is array\n- Default value is ["_elasticsearch_lookup_failure"]\n\nTags the event on failure to look up previous log event information. This can be used in later analysis.'),
		createSnippet('user', 'option', 'user => "${1:user}"', '**[user](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-elasticsearch.html#plugins-filters-elasticsearch-user) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nBasic Auth - username')
	],
	'logstash-output-webhdfs': [
		createSnippet('compression', 'option', 'compression => "${1|none,snappy,gzip|}"$0', '**[compression](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-compression) option**\n\n- Value can be any of: none, snappy, gzip\n- Default value is "none"\n\nCompress output. One of [none, snappy, gzip]'),
		createSnippet('flush_size', 'option', 'flush_size => ${1:500}', '**[flush_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-flush_size) option**\n\n- Value type is number\n- Default value is 500\n\nSending data to webhdfs if event count is above, even if store_interval_in_secs is not reached.'),
		createSnippet('host', 'option', 'host => "${1:host}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-host) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe server name for webhdfs/httpfs connections.', true),
		createSnippet('idle_flush_time', 'option', 'idle_flush_time => ${1:1}', '**[idle_flush_time](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-idle_flush_time) option**\n\n- Value type is number\n- Default value is 1\n\nSending data to webhdfs in x seconds intervals.'),
		createSnippet('kerberos_keytab', 'option', 'kerberos_keytab => "${1:kerberos_keytab}"', '**[kerberos_keytab](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-kerberos_keytab) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nSet kerberos keytab file. Note that the gssapi library needs to be available to use this.'),
		createSnippet('open_timeout', 'option', 'open_timeout => ${1:30}', '**[open_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-open_timeout) option**\n\n- Value type is number\n- Default value is 30\n\nWebHdfs open timeout, default 30s.'),
		createSnippet('path', 'option', 'path => "${1:path}"', '**[path](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-path) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe path to the file to write to. Event fields can be used here, as well as date fields in the joda time format, e.g.: /user/logstash/dt=%{+YYYY-MM-dd}/%{@source_host}-%{+HH}.log', true),
		createSnippet('port', 'option', 'port => ${1:50070}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-port) option**\n\n- Value type is number\n- Default value is 50070\n\nThe server port for webhdfs/httpfs connections.'),
		createSnippet('read_timeout', 'option', 'read_timeout => ${1:30}', '**[read_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-read_timeout) option**\n\n- Value type is number\n- Default value is 30\n\nThe WebHdfs read timeout, default 30s.'),
		createSnippet('retry_interval', 'option', 'retry_interval => ${1:0.5}', '**[retry_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-retry_interval) option**\n\n- Value type is number\n- Default value is 0.5\n\nHow long should we wait between retries.'),
		createSnippet('retry_known_errors', 'option', 'retry_known_errors => ${1|true,false|}', '**[retry_known_errors](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-retry_known_errors) option**\n\n- Value type is boolean\n- Default value is true\n\nRetry some known webhdfs errors. These may be caused by race conditions when appending to same file, etc.'),
		createSnippet('retry_times', 'option', 'retry_times => ${1:5}', '**[retry_times](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-retry_times) option**\n\n- Value type is number\n- Default value is 5\n\nHow many times should we retry. If retry_times is exceeded, an error will be logged and the event will be discarded.'),
		createSnippet('single_file_per_thread', 'option', 'single_file_per_thread => ${1|false,true|}', '**[single_file_per_thread](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-single_file_per_thread) option**\n\n- Value type is boolean\n- Default value is false\n\nAvoid appending to same file in multiple threads. This solves some problems with multiple logstash output threads and locked file leases in webhdfs. If this option is set to true, %{[@metadata][thread_id]} needs to be used in path config settting.'),
		createSnippet('snappy_bufsize', 'option', 'snappy_bufsize => ${1:32768}', '**[snappy_bufsize](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-snappy_bufsize) option**\n\n- Value type is number\n- Default value is 32768\n\nSet snappy chunksize. Only neccessary for stream format. Defaults to 32k. Max is 65536 @see http://code.google.com/p/snappy/source/browse/trunk/framing_format.txt'),
		createSnippet('snappy_format', 'option', 'snappy_format => "${1|stream,file|}"$0', '**[snappy_format](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-snappy_format) option**\n\n- Value can be any of: stream, file\n- Default value is "stream"\n\nSet snappy format. One of "stream", "file". Set to stream to be hive compatible.'),
		createSnippet('ssl_cert', 'option', 'ssl_cert => "${1:ssl_cert}"', '**[ssl_cert](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-ssl_cert) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nSet ssl cert file.'),
		createSnippet('ssl_key', 'option', 'ssl_key => "${1:ssl_key}"', '**[ssl_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-ssl_key) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nSet ssl key file.'),
		createSnippet('standby_host', 'option', 'standby_host => "${1:false}"', '**[standby_host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-standby_host) option**\n\n- Value type is string\n- Default value is false\n\nStandby namenode for ha hdfs.'),
		createSnippet('standby_port', 'option', 'standby_port => ${1:50070}', '**[standby_port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-standby_port) option**\n\n- Value type is number\n- Default value is 50070\n\nStandby namenode port for ha hdfs.'),
		createSnippet('use_httpfs', 'option', 'use_httpfs => ${1|false,true|}', '**[use_httpfs](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-use_httpfs) option**\n\n- Value type is boolean\n- Default value is false\n\nUse httpfs mode if set to true, else webhdfs.'),
		createSnippet('use_kerberos_auth', 'option', 'use_kerberos_auth => ${1|false,true|}', '**[use_kerberos_auth](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-use_kerberos_auth) option**\n\n- Value type is boolean\n- Default value is false\n\nSet kerberos authentication.'),
		createSnippet('use_ssl_auth', 'option', 'use_ssl_auth => ${1|false,true|}', '**[use_ssl_auth](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-use_ssl_auth) option**\n\n- Value type is boolean\n- Default value is false\n\nSet ssl authentication. Note that the openssl library needs to be available to use this.'),
		createSnippet('user', 'option', 'user => "${1:user}"', '**[user](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html#plugins-outputs-webhdfs-user) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe Username for webhdfs.', true)
	],
	'logstash-input-kafka': [
		createSnippet('auto_commit_interval_ms', 'option', 'auto_commit_interval_ms => ${1:5000}', '**[auto_commit_interval_ms](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-auto_commit_interval_ms) option**\n\n- Value type is number\n- Default value is 5000.\n\nThe frequency in milliseconds that the consumer offsets are committed to Kafka.'),
		createSnippet('auto_offset_reset', 'option', 'auto_offset_reset => "${1:auto_offset_reset}"', '**[auto_offset_reset](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-auto_offset_reset) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nWhat to do when there is no initial offset in Kafka or if an offset is out of range:'),
		createSnippet('bootstrap_servers', 'option', 'bootstrap_servers => "${1:localhost:9092}"', '**[bootstrap_servers](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-bootstrap_servers) option**\n\n- Value type is string\n- Default value is "localhost:9092"\n\nA list of URLs of Kafka instances to use for establishing the initial connection to the cluster. This list should be in the form of host1:port1,host2:port2 These urls are just used for the initial connection to discover the full cluster membership (which may change dynamically) so this list need not contain the full set of servers (you may want more than one, though, in case a server is down).'),
		createSnippet('check_crcs', 'option', 'check_crcs => ${1|true,false|}', '**[check_crcs](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-check_crcs) option**\n\n- Value type is boolean\n- Default value is true\n\nAutomatically check the CRC32 of the records consumed. This ensures no on-the-wire or on-disk corruption to the messages occurred. This check adds some overhead, so it may be disabled in cases seeking extreme performance.'),
		createSnippet('client_dns_lookup', 'option', 'client_dns_lookup => "${1:default}"', '**[client_dns_lookup](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-client_dns_lookup) option**\n\n- Value type is string\n- Default value is "default"\n\nHow DNS lookups should be done. If set to use_all_dns_ips, when the lookup returns multiple IP addresses for a hostname, they will all be attempted to connect to before failing the connection. If the value is resolve_canonical_bootstrap_servers_only each entry will be resolved and expanded into a list of canonical names.'),
		createSnippet('client_id', 'option', 'client_id => "${1:logstash}"', '**[client_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-client_id) option**\n\n- Value type is string\n- Default value is "logstash"\n\nThe id string to pass to the server when making requests. The purpose of this is to be able to track the source of requests beyond just ip/port by allowing a logical application name to be included.'),
		createSnippet('client_rack', 'option', 'client_rack => "${1:client_rack}"', '**[client_rack](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-client_rack) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nA rack identifier for the Kafka consumer. Used to select the physically closest rack for the consumer to read from. The setting corresponds with Kafka’s broker.rack configuration.'),
		createSnippet('connections_max_idle_ms', 'option', 'connections_max_idle_ms => ${1:540000 milliseconds}', '**[connections_max_idle_ms](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-connections_max_idle_ms) option**\n\n- Value type is number\n- Default value is 540000 milliseconds (9 minutes).\n\nClose idle connections after the number of milliseconds specified by this config.'),
		createSnippet('consumer_threads', 'option', 'consumer_threads => ${1:1}', '**[consumer_threads](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-consumer_threads) option**\n\n- Value type is number\n- Default value is 1\n\nIdeally you should have as many threads as the number of partitions for a perfect balance — more threads than partitions means that some threads will be idle'),
		createSnippet('decorate_events', 'option', 'decorate_events => "${1:none}"', '**[decorate_events](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-decorate_events) option**\n\n- Value type is string\n- Accepted values are: none: no metadata is added basic: record’s attributes are added extended: record’s attributes, headers are added false: deprecated alias for none true: deprecated alias for basic\n- none: no metadata is added\n- basic: record’s attributes are added\n- extended: record’s attributes, headers are added\n- false: deprecated alias for none\n- true: deprecated alias for basic\n- Default value is none\n\nAccepted values are:'),
		createSnippet('enable_auto_commit', 'option', 'enable_auto_commit => ${1|true,false|}', '**[enable_auto_commit](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-enable_auto_commit) option**\n\n- Value type is boolean\n- Default value is true\n\nThis committed offset will be used when the process fails as the position from which the consumption will begin.'),
		createSnippet('exclude_internal_topics', 'option', 'exclude_internal_topics => "${1:exclude_internal_topics}"', '**[exclude_internal_topics](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-exclude_internal_topics) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nWhether records from internal topics (such as offsets) should be exposed to the consumer. If set to true the only way to receive records from an internal topic is subscribing to it.'),
		createSnippet('fetch_max_bytes', 'option', 'fetch_max_bytes => ${1:52428800}', '**[fetch_max_bytes](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-fetch_max_bytes) option**\n\n- Value type is number\n- Default value is 52428800 (50MB)\n\nThe maximum amount of data the server should return for a fetch request. This is not an absolute maximum, if the first message in the first non-empty partition of the fetch is larger than this value, the message will still be returned to ensure that the consumer can make progress.'),
		createSnippet('fetch_max_wait_ms', 'option', 'fetch_max_wait_ms => ${1:500 milliseconds}', '**[fetch_max_wait_ms](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-fetch_max_wait_ms) option**\n\n- Value type is number\n- Default value is 500 milliseconds.\n\nThe maximum amount of time the server will block before answering the fetch request if there isn’t sufficient data to immediately satisfy fetch_min_bytes. This should be less than or equal to the timeout used in poll_timeout_ms'),
		createSnippet('fetch_min_bytes', 'option', 'fetch_min_bytes => ${1:123}', '**[fetch_min_bytes](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-fetch_min_bytes) option**\n\n- Value type is number\n- There is no default value for this setting.\n\nThe minimum amount of data the server should return for a fetch request. If insufficient data is available the request will wait for that much data to accumulate before answering the request.'),
		createSnippet('group_id', 'option', 'group_id => "${1:logstash}"', '**[group_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-group_id) option**\n\n- Value type is string\n- Default value is "logstash"\n\nThe identifier of the group this consumer belongs to. Consumer group is a single logical subscriber that happens to be made up of multiple processors. Messages in a topic will be distributed to all Logstash instances with the same group_id.'),
		createSnippet('heartbeat_interval_ms', 'option', 'heartbeat_interval_ms => ${1:3000 milliseconds}', '**[heartbeat_interval_ms](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-heartbeat_interval_ms) option**\n\n- Value type is number\n- Default value is 3000 milliseconds (3 seconds).\n\nThe expected time between heartbeats to the consumer coordinator. Heartbeats are used to ensure that the consumer’s session stays active and to facilitate rebalancing when new consumers join or leave the group. The value must be set lower than session.timeout.ms, but typically should be set no higher than 1/3 of that value. It can be adjusted even lower to control the expected time for normal rebalances.'),
		createSnippet('isolation_level', 'option', 'isolation_level => "${1:read_uncommitted}"', '**[isolation_level](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-isolation_level) option**\n\n- Value type is string\n- Default value is "read_uncommitted"\n\nControls how to read messages written transactionally. If set to read_committed, polling messages will only return transactional messages which have been committed. If set to read_uncommitted (the default), polling messages will return all messages, even transactional messages which have been aborted. Non-transactional messages will be returned unconditionally in either mode.'),
		createSnippet('jaas_path', 'option', 'jaas_path => "${1:/path/to/file}"', '**[jaas_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-jaas_path) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nThe Java Authentication and Authorization Service (JAAS) API supplies user authentication and authorization services for Kafka. This setting provides the path to the JAAS file. Sample JAAS file for Kafka client:'),
		createSnippet('kerberos_config', 'option', 'kerberos_config => "${1:/path/to/file}"', '**[kerberos_config](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-kerberos_config) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nOptional path to kerberos config file. This is krb5.conf style as detailed in https://web.mit.edu/kerberos/krb5-1.12/doc/admin/conf_files/krb5_conf.html'),
		createSnippet('key_deserializer_class', 'option', 'key_deserializer_class => "${1:org.apache.kafka.common.serialization.StringDeserializer}"', '**[key_deserializer_class](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-key_deserializer_class) option**\n\n- Value type is string\n- Default value is "org.apache.kafka.common.serialization.StringDeserializer"\n\nJava Class used to deserialize the record’s key'),
		createSnippet('max_partition_fetch_bytes', 'option', 'max_partition_fetch_bytes => ${1:1048576}', '**[max_partition_fetch_bytes](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-max_partition_fetch_bytes) option**\n\n- Value type is number\n- Default value is 1048576 (1MB).\n\nThe maximum amount of data per-partition the server will return. The maximum total memory used for a request will be #partitions * max.partition.fetch.bytes. This size must be at least as large as the maximum message size the server allows or else it is possible for the producer to send messages larger than the consumer can fetch. If that happens, the consumer can get stuck trying to fetch a large message on a certain partition.'),
		createSnippet('max_poll_interval_ms', 'option', 'max_poll_interval_ms => ${1:300000 milliseconds}', '**[max_poll_interval_ms](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-max_poll_interval_ms) option**\n\n- Value type is number\n- Default value is 300000 milliseconds (5 minutes).\n\nThe maximum delay between invocations of poll() when using consumer group management. This places an upper bound on the amount of time that the consumer can be idle before fetching more records. If poll() is not called before expiration of this timeout, then the consumer is considered failed and the group will rebalance in order to reassign the partitions to another member.'),
		createSnippet('max_poll_records', 'option', 'max_poll_records => ${1:500}', '**[max_poll_records](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-max_poll_records) option**\n\n- Value type is number\n- Default value is 500.\n\nThe maximum number of records returned in a single call to poll().'),
		createSnippet('metadata_max_age_ms', 'option', 'metadata_max_age_ms => ${1:300000 milliseconds}', '**[metadata_max_age_ms](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-metadata_max_age_ms) option**\n\n- Value type is number\n- Default value is 300000 milliseconds (5 minutes).\n\nThe period of time in milliseconds after which we force a refresh of metadata even if we haven’t seen any partition leadership changes to proactively discover any new brokers or partitions'),
		createSnippet('partition_assignment_strategy', 'option', 'partition_assignment_strategy => "${1:partition_assignment_strategy}"', '**[partition_assignment_strategy](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-partition_assignment_strategy) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe name of the partition assignment strategy that the client uses to distribute partition ownership amongst consumer instances, supported options are:'),
		createSnippet('poll_timeout_ms', 'option', 'poll_timeout_ms => ${1:100 milliseconds}', '**[poll_timeout_ms](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-poll_timeout_ms) option**\n\n- Value type is number\n- Default value is 100 milliseconds.\n\nTime Kafka consumer will wait to receive new messages from topics.'),
		createSnippet('receive_buffer_bytes', 'option', 'receive_buffer_bytes => ${1:32768}', '**[receive_buffer_bytes](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-receive_buffer_bytes) option**\n\n- Value type is number\n- Default value is 32768 (32KB).\n\nThe size of the TCP receive buffer (SO_RCVBUF) to use when reading data.'),
		createSnippet('reconnect_backoff_ms', 'option', 'reconnect_backoff_ms => ${1:50 milliseconds}', '**[reconnect_backoff_ms](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-reconnect_backoff_ms) option**\n\n- Value type is number\n- Default value is 50 milliseconds.\n\nThe amount of time to wait before attempting to reconnect to a given host. This avoids repeatedly connecting to a host in a tight loop. This backoff applies to all requests sent by the consumer to the broker.'),
		createSnippet('request_timeout_ms', 'option', 'request_timeout_ms => ${1:40000 milliseconds}', '**[request_timeout_ms](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-request_timeout_ms) option**\n\n- Value type is number\n- Default value is 40000 milliseconds (40 seconds).\n\nThe configuration controls the maximum amount of time the client will wait for the response of a request. If the response is not received before the timeout elapses the client will resend the request if necessary or fail the request if retries are exhausted.'),
		createSnippet('retry_backoff_ms', 'option', 'retry_backoff_ms => ${1:100 milliseconds}', '**[retry_backoff_ms](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-retry_backoff_ms) option**\n\n- Value type is number\n- Default value is 100 milliseconds.\n\nThe amount of time to wait before attempting to retry a failed fetch request to a given topic partition. This avoids repeated fetching-and-failing in a tight loop.'),
		createSnippet('sasl_jaas_config', 'option', 'sasl_jaas_config => "${1:sasl_jaas_config}"', '**[sasl_jaas_config](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-sasl_jaas_config) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nJAAS configuration setting local to this plugin instance, as opposed to settings using config file configured using jaas_path, which are shared across the JVM. This allows each plugin instance to have its own configuration.\n\n**_Example:_**  \n``` ruby\n    input {\n      kafka {\n        sasl_jaas_config => "org.apache.kafka.common.security.plain.PlainLoginModule required username=\'auser\'  password=\'apassword\';"\n      }\n    }\n```'),
		createSnippet('sasl_kerberos_service_name', 'option', 'sasl_kerberos_service_name => "${1:sasl_kerberos_service_name}"', '**[sasl_kerberos_service_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-sasl_kerberos_service_name) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe Kerberos principal name that Kafka broker runs as. This can be defined either in Kafka’s JAAS config or in Kafka’s config.'),
		createSnippet('sasl_mechanism', 'option', 'sasl_mechanism => "${1:GSSAPI}"', '**[sasl_mechanism](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-sasl_mechanism) option**\n\n- Value type is string\n- Default value is "GSSAPI"\n\nSASL mechanism used for client connections. This may be any mechanism for which a security provider is available. GSSAPI is the default mechanism.'),
		createSnippet('schema_registry_key', 'option', 'schema_registry_key => "${1:schema_registry_key}"', '**[schema_registry_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-schema_registry_key) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nSet the username for basic authorization to access remote Schema Registry.'),
		createSnippet('schema_registry_proxy', 'option', 'schema_registry_proxy => ["${1:http://localhost}"]', '**[schema_registry_proxy](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-schema_registry_proxy) option**\n\n- Value type is uri\n- There is no default value for this setting.\n\nSet the address of a forward HTTP proxy. An empty string is treated as if proxy was not set.'),
		createSnippet('schema_registry_secret', 'option', 'schema_registry_secret => "${1:schema_registry_secret}"', '**[schema_registry_secret](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-schema_registry_secret) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nSet the password for basic authorization to access remote Schema Registry.'),
		createSnippet('schema_registry_url', 'option', 'schema_registry_url => ["${1:http://localhost}"]', '**[schema_registry_url](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-schema_registry_url) option**\n\n- Value type is uri\n\nThe URI that points to an instance of the Schema Registry service, used to manage Avro schemas. Be sure that the Avro schemas for deserializing the data from the specified topics have been uploaded to the Schema Registry service. The schemas must follow a naming convention with the pattern <topic name>-value.'),
		createSnippet('schema_registry_validation', 'option', 'schema_registry_validation => "${1:auto}"', '**[schema_registry_validation](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-schema_registry_validation) option**\n\n- Value can be either of: auto, skip\n- Default value is "auto"\n\nUnder most circumstances, the default setting of auto should not need to be changed.'),
		createSnippet('security_protocol', 'option', 'security_protocol => "${1|PLAINTEXT,SSL,SASL_PLAINTEXT,SASL_SSL|}"$0', '**[security_protocol](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-security_protocol) option**\n\n- Value can be any of: PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL\n- Default value is "PLAINTEXT"\n\nSecurity protocol to use, which can be either of PLAINTEXT,SSL,SASL_PLAINTEXT,SASL_SSL'),
		createSnippet('send_buffer_bytes', 'option', 'send_buffer_bytes => ${1:131072}', '**[send_buffer_bytes](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-send_buffer_bytes) option**\n\n- Value type is number\n- Default value is 131072 (128KB).\n\nThe size of the TCP send buffer (SO_SNDBUF) to use when sending data'),
		createSnippet('session_timeout_ms', 'option', 'session_timeout_ms => ${1:10000 milliseconds}', '**[session_timeout_ms](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-session_timeout_ms) option**\n\n- Value type is number\n- Default value is 10000 milliseconds (10 seconds).\n\nThe timeout after which, if the poll_timeout_ms is not invoked, the consumer is marked dead and a rebalance operation is triggered for the group identified by group_id'),
		createSnippet('ssl_endpoint_identification_algorithm', 'option', 'ssl_endpoint_identification_algorithm => "${1:https}"', '**[ssl_endpoint_identification_algorithm](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-ssl_endpoint_identification_algorithm) option**\n\n- Value type is string\n- Default value is "https"\n\nThe endpoint identification algorithm, defaults to "https". Set to empty string "" to disable endpoint verification'),
		createSnippet('ssl_key_password', 'option', 'ssl_key_password => "${1:ssl_key_password}"', '**[ssl_key_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-ssl_key_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nThe password of the private key in the key store file.'),
		createSnippet('ssl_keystore_location', 'option', 'ssl_keystore_location => "${1:/path/to/file}"', '**[ssl_keystore_location](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-ssl_keystore_location) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf client authentication is required, this setting stores the keystore path.'),
		createSnippet('ssl_keystore_password', 'option', 'ssl_keystore_password => "${1:ssl_keystore_password}"', '**[ssl_keystore_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-ssl_keystore_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nIf client authentication is required, this setting stores the keystore password'),
		createSnippet('ssl_keystore_type', 'option', 'ssl_keystore_type => "${1:ssl_keystore_type}"', '**[ssl_keystore_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-ssl_keystore_type) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe keystore type.'),
		createSnippet('ssl_truststore_location', 'option', 'ssl_truststore_location => "${1:/path/to/file}"', '**[ssl_truststore_location](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-ssl_truststore_location) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nThe JKS truststore path to validate the Kafka broker’s certificate.'),
		createSnippet('ssl_truststore_password', 'option', 'ssl_truststore_password => "${1:ssl_truststore_password}"', '**[ssl_truststore_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-ssl_truststore_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nThe truststore password.'),
		createSnippet('ssl_truststore_type', 'option', 'ssl_truststore_type => "${1:ssl_truststore_type}"', '**[ssl_truststore_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-ssl_truststore_type) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe truststore type.'),
		createSnippet('topics', 'option', 'topics => ["${1:logstash}"]', '**[topics](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-topics) option**\n\n- Value type is array\n- Default value is ["logstash"]\n\nA list of topics to subscribe to, defaults to ["logstash"].'),
		createSnippet('topics_pattern', 'option', 'topics_pattern => "${1:topics_pattern}"', '**[topics_pattern](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-topics_pattern) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nA topic regex pattern to subscribe to. The topics configuration will be ignored when using this configuration.'),
		createSnippet('value_deserializer_class', 'option', 'value_deserializer_class => "${1:org.apache.kafka.common.serialization.StringDeserializer}"', '**[value_deserializer_class](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html#plugins-inputs-kafka-value_deserializer_class) option**\n\n- Value type is string\n- Default value is "org.apache.kafka.common.serialization.StringDeserializer"\n\nJava Class used to deserialize the record’s value. A custom value deserializer can be used only if you are not using a Schema Registry. Use either the value_deserializer_class config option or the schema_registry_url config option, but not both.')
	],
	'logstash-input-dead_letter_queue': [
		createSnippet('commit_offsets', 'option', 'commit_offsets => ${1|true,false|}', '**[commit_offsets](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-dead_letter_queue.html#plugins-inputs-dead_letter_queue-commit_offsets) option**\n\n- Value type is boolean\n- Default value is true\n\nSpecifies whether this input should commit offsets as it processes the events. Typically you specify false when you want to iterate multiple times over the events in the dead letter queue, but don’t want to save state. This is when you are exploring the events in the dead letter queue.'),
		createSnippet('path', 'option', 'path => "${1:/path/to/file}"', '**[path](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-dead_letter_queue.html#plugins-inputs-dead_letter_queue-path) option**\n\n- This is a required setting.\n- Value type is path\n- There is no default value for this setting.\n\nPath to the dead letter queue directory that was created by a Logstash instance. This is the path from which "dead" events are read and is typically configured in the original Logstash instance with the setting path.dead_letter_queue.', true),
		createSnippet('pipeline_id', 'option', 'pipeline_id => "${1:main}"', '**[pipeline_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-dead_letter_queue.html#plugins-inputs-dead_letter_queue-pipeline_id) option**\n\n- Value type is string\n- Default value is "main"\n\nID of the pipeline whose events you want to read from.'),
		createSnippet('sincedb_path', 'option', 'sincedb_path => "${1:sincedb_path}"', '**[sincedb_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-dead_letter_queue.html#plugins-inputs-dead_letter_queue-sincedb_path) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nPath of the sincedb database file (keeps track of the current position of dead letter queue) that will be written to disk. The default will write sincedb files to <path.data>/plugins/inputs/dead_letter_queue.'),
		createSnippet('start_timestamp', 'option', 'start_timestamp => "${1:start_timestamp}"', '**[start_timestamp](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-dead_letter_queue.html#plugins-inputs-dead_letter_queue-start_timestamp) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nTimestamp in ISO8601 format from when you want to start processing the events from. For example, 2017-04-04T23:40:37.')
	],
	'logstash-input-elasticsearch': [
		createSnippet('api_key', 'option', 'api_key => "${1:api_key}"', '**[api_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-api_key) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nAuthenticate using Elasticsearch API key. Note that this option also requires enabling the ssl option.'),
		createSnippet('ca_file', 'option', 'ca_file => "${1:/path/to/file}"', '**[ca_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-ca_file) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nSSL Certificate Authority file in PEM encoded format, must also include any chain certificates as necessary.'),
		createSnippet('cloud_auth', 'option', 'cloud_auth => "${1:cloud_auth}"', '**[cloud_auth](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-cloud_auth) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nCloud authentication string ("<username>:<password>" format) is an alternative for the user/password pair.'),
		createSnippet('cloud_id', 'option', 'cloud_id => "${1:cloud_id}"', '**[cloud_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-cloud_id) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nCloud ID, from the Elastic Cloud web console. If set hosts should not be used.'),
		createSnippet('connect_timeout_seconds', 'option', 'connect_timeout_seconds => ${1:10}', '**[connect_timeout_seconds](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-connect_timeout_seconds) option**\n\n- Value type is number\n- Default value is 10\n\nThe maximum amount of time, in seconds, to wait while establishing a connection to Elasticsearch. Connect timeouts tend to occur when Elasticsearch or an intermediate proxy is overloaded with requests and has exhausted its connection pool.'),
		createSnippet('docinfo', 'option', 'docinfo => ${1|false,true|}', '**[docinfo](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-docinfo) option**\n\n- Value type is boolean\n- Default value is false\n\nIf set, include Elasticsearch document information such as index, type, and the id in the event.\n\n**_Example:_**  \n``` ruby\n    input {\n      elasticsearch {\n        hosts => "es.production.mysite.org"\n        index => "mydata-2018.09.*"\n        query => \'{ "query": { "query_string": { "query": "*" } } }\'\n        size => 500\n        scroll => "5m"\n        docinfo => true\n        docinfo_target => "[@metadata][doc]"\n      }\n    }\n    output {\n      elasticsearch {\n        index => "copy-of-production.%{[@metadata][doc][_index]}"\n        document_type => "%{[@metadata][doc][_type]}"\n        document_id => "%{[@metadata][doc][_id]}"\n      }\n    }\n```'),
		createSnippet('docinfo_fields', 'option', 'docinfo_fields => ["${1:_index}", "_type", "_id"]', '**[docinfo_fields](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-docinfo_fields) option**\n\n- Value type is array\n- Default value is ["_index", "_type", "_id"]\n\nIf document metadata storage is requested by enabling the docinfo option, this option lists the metadata fields to save in the current event. See Meta-Fields in the Elasticsearch documentation for more information.'),
		createSnippet('docinfo_target', 'option', 'docinfo_target => "${1:docinfo_target}"', '**[docinfo_target](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-docinfo_target) option**\n\n- Value type is string\n- Default value depends on whether ecs_compatibility is enabled: ECS Compatibility disabled: "@metadata" ECS Compatibility enabled: "[@metadata][input][elasticsearch]"\n- ECS Compatibility disabled: "@metadata"\n- ECS Compatibility enabled: "[@metadata][input][elasticsearch]"\n\nDefault value depends on whether ecs_compatibility is enabled:'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: CSV data added at root level v1,v8: Elastic Common Schema compliant behavior\n- disabled: CSV data added at root level\n- v1,v8: Elastic Common Schema compliant behavior\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled\n\nSupported values are:'),
		createSnippet('hosts', 'option', 'hosts => ["${1:host}"]', '**[hosts](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-hosts) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nList of one or more Elasticsearch hosts to use for querying. Each host can be either IP, HOST, IP:port, or HOST:port. The port defaults to 9200.'),
		createSnippet('index', 'option', 'index => "${1:logstash-*}"', '**[index](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-index) option**\n\n- Value type is string\n- Default value is "logstash-*"\n\nThe index or alias to search. See Multi Indices documentation in the Elasticsearch documentation for more information on how to reference multiple indices.'),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nThe password to use together with the username in the user option when authenticating to the Elasticsearch server. If set to an empty string authentication will be disabled.'),
		createSnippet('proxy', 'option', 'proxy => ["${1:http://localhost}"]', '**[proxy](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-proxy) option**\n\n- Value type is uri\n- There is no default value for this setting.\n\nSet the address of a forward HTTP proxy. An empty string is treated as if proxy was not set, this is useful when using environment variables e.g. proxy => \'${LS_PROXY:}\'.'),
		createSnippet('query', 'option', 'query => "${1:{ \\"sort\\": [ \\"_doc\\" ] \\}}"', '**[query](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-query) option**\n\n- Value type is string\n- Default value is \'{ "sort": [ "_doc" ] }\'\n\nThe query to be executed. Read the Elasticsearch query DSL documentation for more information.'),
		createSnippet('request_timeout_seconds', 'option', 'request_timeout_seconds => ${1:60}', '**[request_timeout_seconds](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-request_timeout_seconds) option**\n\n- Value type is number\n- Default value is 60\n\nThe maximum amount of time, in seconds, for a single request to Elasticsearch. Request timeouts tend to occur when an individual page of data is very large, such as when it contains large-payload documents and/or the size has been specified as a large value.'),
		createSnippet('schedule', 'option', 'schedule => "${1:schedule}"', '**[schedule](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-schedule) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nSchedule of when to periodically run statement, in Cron format for example: "* * * * *" (execute query every minute, on the minute)'),
		createSnippet('scroll', 'option', 'scroll => "${1:1m}"', '**[scroll](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-scroll) option**\n\n- Value type is string\n- Default value is "1m"\n\nThis parameter controls the keepalive time in seconds of the scrolling request and initiates the scrolling process. The timeout applies per round trip (i.e. between the previous scroll request, to the next).'),
		createSnippet('size', 'option', 'size => ${1:1000}', '**[size](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-size) option**\n\n- Value type is number\n- Default value is 1000\n\nThis allows you to set the maximum number of hits returned per scroll.'),
		createSnippet('slices', 'option', 'slices => ${1:123}', '**[slices](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-slices) option**\n\n- Value type is number\n- There is no default value.\n- Sensible values range from 2 to about 8.\n\nIn some cases, it is possible to improve overall throughput by consuming multiple distinct slices of a query simultaneously using sliced scrolls, especially if the pipeline is spending significant time waiting on Elasticsearch to provide results.'),
		createSnippet('ssl', 'option', 'ssl => ${1|false,true|}', '**[ssl](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-ssl) option**\n\n- Value type is boolean\n- Default value is false\n\nIf enabled, SSL will be used when communicating with the Elasticsearch server (i.e. HTTPS will be used instead of plain HTTP).'),
		createSnippet('socket_timeout_seconds', 'option', 'socket_timeout_seconds => ${1:60}', '**[socket_timeout_seconds](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-socket_timeout_seconds) option**\n\n- Value type is number\n- Default value is 60\n\nThe maximum amount of time, in seconds, to wait on an incomplete response from Elasticsearch while no additional data has been appended. Socket timeouts usually occur while waiting for the first byte of a response, such as when executing a particularly complex query.'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-target) option**\n\n- Value type is field reference\n- There is no default value for this setting.\n\nWithout a target, events are created from each hit’s _source at the root level. When the target is set to a field reference, the _source of the hit is placed in the target field instead.'),
		createSnippet('user', 'option', 'user => "${1:user}"', '**[user](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html#plugins-inputs-elasticsearch-user) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe username to use together with the password in the password option when authenticating to the Elasticsearch server. If set to an empty string authentication will be disabled.')
	],
	'logstash-input-meetup': [
		createSnippet('eventstatus', 'option', 'eventstatus => "${1:upcoming,past}"', '**[eventstatus](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-meetup.html#plugins-inputs-meetup-eventstatus) option**\n\n- Value type is string.\n- Default value is "upcoming,past".\n\nEvent Status can be one of "upcoming", "past", or "upcoming,past". Default is "upcoming,past".'),
		createSnippet('groupid', 'option', 'groupid => "${1:groupid}"', '**[groupid](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-meetup.html#plugins-inputs-meetup-groupid) option**\n\n- Value type is string.\n- There is no default value for this setting.\n\nThe Group ID, multiple may be specified seperated by commas. Must have one of urlname, venueid, groupid, text.'),
		createSnippet('interval', 'option', 'interval => ${1:123}', '**[interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-meetup.html#plugins-inputs-meetup-interval) option**\n\n- This is a required setting.\n- Value type is number.\n- There is no default value for this setting.\n\nInterval to run the command. Value is in minutes.', true),
		createSnippet('meetupkey', 'option', 'meetupkey => "${1:meetupkey}"', '**[meetupkey](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-meetup.html#plugins-inputs-meetup-meetupkey) option**\n\n- This is a required setting.\n- Value type is string.\n- There is no default value for this setting.\n\nMeetup Key, aka personal token.', true),
		createSnippet('urlname', 'option', 'urlname => "${1:urlname}"', '**[urlname](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-meetup.html#plugins-inputs-meetup-urlname) option**\n\n- Value type is string.\n- There is no default value for this setting.\n\nURLName - the URL name ie ElasticSearch-Oklahoma-City. Must have one of urlname, venue_id, group_id, text.'),
		createSnippet('venueid', 'option', 'venueid => "${1:venueid}"', '**[venueid](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-meetup.html#plugins-inputs-meetup-venueid) option**\n\n- Value type is string.\n- There is no default value for this setting.\n\nThe venue ID Must have one of urlname, venue_id, group_id, text.'),
		createSnippet('text', 'option', 'text => "${1:text}"', '**[text](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-meetup.html#plugins-inputs-meetup-text) option**\n\n- Value type is string.\n- There is no default value for this setting.\n\nA text string to search meetup events by. Must have one of urlname, venue_id, group_id, text.')
	],
	'logstash-output-juggernaut': [
		createSnippet('channels', 'option', 'channels => ["${1:channel}"]', '**[channels](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-juggernaut.html#plugins-outputs-juggernaut-channels) option**\n\n- This is a required setting.\n- Value type is array\n- There is no default value for this setting.\n\nList of channels to which to publish. Dynamic names are valid here, for example logstash-%{type}.', true),
		createSnippet('db', 'option', 'db => ${1:0}', '**[db](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-juggernaut.html#plugins-outputs-juggernaut-db) option**\n\n- Value type is number\n- Default value is 0\n\nThe redis database number.'),
		createSnippet('host', 'option', 'host => "${1:127.0.0.1}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-juggernaut.html#plugins-outputs-juggernaut-host) option**\n\n- Value type is string\n- Default value is "127.0.0.1"\n\nThe hostname of the redis server to which juggernaut is listening.'),
		createSnippet('message_format', 'option', 'message_format => "${1:message_format}"', '**[message_format](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-juggernaut.html#plugins-outputs-juggernaut-message_format) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nHow should the message be formatted before pushing to the websocket.'),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-juggernaut.html#plugins-outputs-juggernaut-password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nPassword to authenticate with. There is no authentication by default.'),
		createSnippet('port', 'option', 'port => ${1:6379}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-juggernaut.html#plugins-outputs-juggernaut-port) option**\n\n- Value type is number\n- Default value is 6379\n\nThe port to connect on.'),
		createSnippet('timeout', 'option', 'timeout => ${1:5}', '**[timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-juggernaut.html#plugins-outputs-juggernaut-timeout) option**\n\n- Value type is number\n- Default value is 5\n\nRedis initial connection timeout in seconds.')
	],
	'logstash-input-varnishlog': [
		createSnippet('threads', 'option', 'threads => ${1:1}', '**[threads](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-varnishlog.html#plugins-inputs-varnishlog-threads) option**\n\n- Value type is number\n- Default value is 1')
	],
	'logstash-filter-range': [
		createSnippet('negate', 'option', 'negate => ${1|false,true|}', '**[negate](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-range.html#plugins-filters-range-negate) option**\n\n- Value type is boolean\n- Default value is false\n\nNegate the range match logic, events should be outsize of the specified range to match.'),
		createSnippet('ranges', 'option', 'ranges => ["${1:range}"]', '**[ranges](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-range.html#plugins-filters-range-ranges) option**\n\n- Value type is array\n- Default value is []\n\nAn array of field, min, max, action tuples. Example:\n\n**_Example:_**  \n``` ruby\n    filter {\n      range {\n        ranges => [ "message", 0, 10, "tag:short",\n                    "message", 11, 100, "tag:medium",\n                    "message", 101, 1000, "tag:long",\n                    "message", 1001, 1e1000, "drop",\n                    "duration", 0, 100, "field:latency:fast",\n                    "duration", 101, 200, "field:latency:normal",\n                    "duration", 201, 1000, "field:latency:slow",\n                    "duration", 1001, 1e1000, "field:latency:outlier",\n                    "requests", 0, 10, "tag:too_few_%{host}_requests" ]\n      }\n    }\n```')
	],
	'logstash-output-redis': [
		createSnippet('batch', 'option', 'batch => ${1|false,true|}', '**[batch](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redis.html#plugins-outputs-redis-batch) option**\n\n- Value type is boolean\n- Default value is false\n\nSet to true if you want Redis to batch up values and send 1 RPUSH command instead of one command per value to push on the list. Note that this only works with data_type="list" mode right now.'),
		createSnippet('batch_events', 'option', 'batch_events => ${1:50}', '**[batch_events](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redis.html#plugins-outputs-redis-batch_events) option**\n\n- Value type is number\n- Default value is 50\n\nIf batch is set to true, the number of events we queue up for an RPUSH.'),
		createSnippet('batch_timeout', 'option', 'batch_timeout => ${1:5}', '**[batch_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redis.html#plugins-outputs-redis-batch_timeout) option**\n\n- Value type is number\n- Default value is 5\n\nIf batch is set to true, the maximum amount of time between RPUSH commands when there are pending events to flush.'),
		createSnippet('congestion_interval', 'option', 'congestion_interval => ${1:1}', '**[congestion_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redis.html#plugins-outputs-redis-congestion_interval) option**\n\n- Value type is number\n- Default value is 1\n\nHow often to check for congestion. Default is one second. Zero means to check on every event.'),
		createSnippet('congestion_threshold', 'option', 'congestion_threshold => ${1:0}', '**[congestion_threshold](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redis.html#plugins-outputs-redis-congestion_threshold) option**\n\n- Value type is number\n- Default value is 0\n\nIn case Redis data_type is list and has more than @congestion_threshold items, block until someone consumes them and reduces congestion, otherwise if there are no consumers Redis will run out of memory, unless it was configured with OOM protection. But even with OOM protection, a single Redis list can block all other users of Redis, until Redis CPU consumption reaches the max allowed RAM size. A default value of 0 means that this limit is disabled. Only supported for list Redis data_type.'),
		createSnippet('data_type', 'option', 'data_type => "${1|list,channel|}"$0', '**[data_type](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redis.html#plugins-outputs-redis-data_type) option**\n\n- Value can be any of: list, channel\n- There is no default value for this setting.\n\nEither list or channel. If data_type is list, then we will set RPUSH to key. If data_type is channel, then we will PUBLISH to key.'),
		createSnippet('db', 'option', 'db => ${1:0}', '**[db](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redis.html#plugins-outputs-redis-db) option**\n\n- Value type is number\n- Default value is 0\n\nThe Redis database number.'),
		createSnippet('host', 'option', 'host => ["${1:127.0.0.1}"]', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redis.html#plugins-outputs-redis-host) option**\n\n- Value type is array\n- Default value is ["127.0.0.1"]\n\nThe hostname(s) of your Redis server(s). Ports may be specified on any hostname, which will override the global port config. If the hosts list is an array, Logstash will pick one random host to connect to, if that host is disconnected it will then pick another.'),
		createSnippet('key', 'option', 'key => "${1:key}"', '**[key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redis.html#plugins-outputs-redis-key) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe name of a Redis list or channel. Dynamic names are valid here, for example logstash-%{type}.'),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redis.html#plugins-outputs-redis-password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nPassword to authenticate with. There is no authentication by default.'),
		createSnippet('port', 'option', 'port => ${1:6379}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redis.html#plugins-outputs-redis-port) option**\n\n- Value type is number\n- Default value is 6379\n\nThe default port to connect on. Can be overridden on any hostname.'),
		createSnippet('reconnect_interval', 'option', 'reconnect_interval => ${1:1}', '**[reconnect_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redis.html#plugins-outputs-redis-reconnect_interval) option**\n\n- Value type is number\n- Default value is 1\n\nInterval for reconnecting to failed Redis connections'),
		createSnippet('shuffle_hosts', 'option', 'shuffle_hosts => ${1|true,false|}', '**[shuffle_hosts](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redis.html#plugins-outputs-redis-shuffle_hosts) option**\n\n- Value type is boolean\n- Default value is true\n\nShuffle the host list during Logstash startup.'),
		createSnippet('timeout', 'option', 'timeout => ${1:5}', '**[timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redis.html#plugins-outputs-redis-timeout) option**\n\n- Value type is number\n- Default value is 5\n\nRedis initial connection timeout in seconds.')
	],
	'logstash-codec-rubydebug': [
		createSnippet('metadata', 'option', 'metadata => ${1|false,true|}', '**[metadata](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-rubydebug.html#plugins-codecs-rubydebug-metadata) option**\n\n- Value type is boolean\n- Default value is false\n\nShould the event’s metadata be included?')
	],
	'logstash-output-s3': [
		createSnippet('access_key_id', 'option', 'access_key_id => "${1:access_key_id}"', '**[access_key_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-access_key_id) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThis plugin uses the AWS SDK and supports several ways to get credentials, which will be tried in this order:'),
		createSnippet('additional_settings', 'option', 'additional_settings => {\n\t"${1:key}" => "${2:value}"\n}', '**[additional_settings](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-additional_settings) option**\n\n- Value type is hash\n- Default value is {}\n\nKey-value pairs of settings and corresponding values used to parametrize the connection to S3. See full list in the AWS SDK documentation. Example:\n\n**_Example:_**  \n``` ruby\n    output {\n      s3 {\n        access_key_id => "1234",\n        secret_access_key => "secret",\n        region => "eu-west-1",\n        bucket => "logstash-test",\n        additional_settings => {\n          "force_path_style" => true,\n          "follow_redirects" => false\n        }\n      }\n    }\n```'),
		createSnippet('aws_credentials_file', 'option', 'aws_credentials_file => "${1:aws_credentials_file}"', '**[aws_credentials_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-aws_credentials_file) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nPath to YAML file containing a hash of AWS credentials. This file will only be loaded if access_key_id and secret_access_key aren’t set. The contents of the file should look like this:'),
		createSnippet('bucket', 'option', 'bucket => "${1:bucket}"', '**[bucket](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-bucket) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nS3 bucket', true),
		createSnippet('canned_acl', 'option', 'canned_acl => "${1|private,public-read,public-read-write,authenticated-read,aws-exec-read,bucket-owner-read,bucket-owner-full-control,log-delivery-write|}"$0', '**[canned_acl](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-canned_acl) option**\n\n- Value can be any of: private, public-read, public-read-write, authenticated-read, aws-exec-read, bucket-owner-read, bucket-owner-full-control, log-delivery-write\n- Default value is "private"\n\nThe S3 canned ACL to use when putting the file. Defaults to "private".'),
		createSnippet('encoding', 'option', 'encoding => "${1|none,gzip|}"$0', '**[encoding](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-encoding) option**\n\n- Value can be any of: none, gzip\n- Default value is "none"\n\nSpecify the content encoding. Supports ("gzip"). Defaults to "none"'),
		createSnippet('endpoint', 'option', 'endpoint => "${1:endpoint}"', '**[endpoint](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-endpoint) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe endpoint to connect to. By default it is constructed using the value of region. This is useful when connecting to S3 compatible services, but beware that these aren’t guaranteed to work correctly with the AWS SDK. The endpoint should be an HTTP or HTTPS URL, e.g. https://example.com'),
		createSnippet('prefix', 'option', 'prefix => "${1:prefix}"', '**[prefix](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-prefix) option**\n\n- Value type is string\n- Default value is ""\n\nSpecify a prefix to the uploaded filename to simulate directories on S3. Prefix does not require leading slash. This option supports Logstash interpolation. For example, files can be prefixed with the event date using prefix = "%{+YYYY}/%{+MM}/%{+dd}".'),
		createSnippet('proxy_uri', 'option', 'proxy_uri => "${1:proxy_uri}"', '**[proxy_uri](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-proxy_uri) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nURI to proxy server if required'),
		createSnippet('region', 'option', 'region => "${1:us-east-1}"', '**[region](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-region) option**\n\n- Value type is string\n- Default value is "us-east-1"\n\nThe AWS Region'),
		createSnippet('restore', 'option', 'restore => ${1|true,false|}', '**[restore](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-restore) option**\n\n- Value type is boolean\n- Default value is true\n\nUsed to enable recovery after crash/abnormal termination. Temporary log files will be recovered and uploaded.'),
		createSnippet('retry_count', 'option', 'retry_count => ${1:Infinity}', '**[retry_count](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-retry_count) option**\n\n- Value type is number\n- Default value is Infinity\n\nAllows to limit number of retries when S3 uploading fails.'),
		createSnippet('retry_delay', 'option', 'retry_delay => ${1:1}', '**[retry_delay](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-retry_delay) option**\n\n- Value type is number\n- Default value is 1\n\nDelay (in seconds) to wait between consecutive retries on upload failures.'),
		createSnippet('role_arn', 'option', 'role_arn => "${1:role_arn}"', '**[role_arn](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-role_arn) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS IAM Role to assume, if any. This is used to generate temporary credentials, typically for cross-account access. See the AssumeRole API documentation for more information.'),
		createSnippet('role_session_name', 'option', 'role_session_name => "${1:logstash}"', '**[role_session_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-role_session_name) option**\n\n- Value type is string\n- Default value is "logstash"\n\nSession name to use when assuming an IAM role.'),
		createSnippet('rotation_strategy', 'option', 'rotation_strategy => "${1|size_and_time,size,time|}"$0', '**[rotation_strategy](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-rotation_strategy) option**\n\n- Value can be any of: size_and_time, size, time\n- Default value is "size_and_time"\n\nControls when to close the file and push it to S3.'),
		createSnippet('secret_access_key', 'option', 'secret_access_key => "${1:secret_access_key}"', '**[secret_access_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-secret_access_key) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS Secret Access Key'),
		createSnippet('server_side_encryption', 'option', 'server_side_encryption => ${1|false,true|}', '**[server_side_encryption](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-server_side_encryption) option**\n\n- Value type is boolean\n- Default value is false\n\nSpecifies whether or not to use S3’s server side encryption. Defaults to no encryption.'),
		createSnippet('server_side_encryption_algorithm', 'option', 'server_side_encryption_algorithm => "${1|AES256,aws:kms|}"$0', '**[server_side_encryption_algorithm](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-server_side_encryption_algorithm) option**\n\n- Value can be any of: AES256, aws:kms\n- Default value is "AES256"\n\nSpecifies what type of encryption to use when SSE is enabled.'),
		createSnippet('session_token', 'option', 'session_token => "${1:session_token}"', '**[session_token](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-session_token) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS Session token for temporary credential'),
		createSnippet('signature_version', 'option', 'signature_version => "${1|v2,v4|}"$0', '**[signature_version](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-signature_version) option**\n\n- Value can be any of: v2, v4\n- There is no default value for this setting.\n\nThe version of the S3 signature hash to use. Normally uses the internal client default, can be explicitly specified here'),
		createSnippet('size_file', 'option', 'size_file => ${1:5242880}', '**[size_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-size_file) option**\n\n- Value type is number\n- Default value is 5242880\n\nSet the file size in bytes. When the number of bytes exceeds the size_file value, a new file is created. If you use tags, Logstash generates a specific size file for every tag.'),
		createSnippet('ssekms_key_id', 'option', 'ssekms_key_id => "${1:ssekms_key_id}"', '**[ssekms_key_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-ssekms_key_id) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe key to use when specified along with server_side_encryption ⇒ aws:kms. If server_side_encryption ⇒ aws:kms is set but this is not default KMS key is used. http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html'),
		createSnippet('storage_class', 'option', 'storage_class => "${1|STANDARD,REDUCED_REDUNDANCY,STANDARD_IA,ONEZONE_IA|}"$0', '**[storage_class](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-storage_class) option**\n\n- Value can be any of: STANDARD, REDUCED_REDUNDANCY, STANDARD_IA, ONEZONE_IA\n- Default value is "STANDARD"\n\nSpecifies what S3 storage class to use when uploading the file. More information about the different storage classes can be found: http://docs.aws.amazon.com/AmazonS3/latest/dev/storage-class-intro.html Defaults to STANDARD.'),
		createSnippet('temporary_directory', 'option', 'temporary_directory => "${1:/tmp/logstash}"', '**[temporary_directory](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-temporary_directory) option**\n\n- Value type is string\n- Default value is "/tmp/logstash"\n\nSet the directory where logstash will store the tmp files before sending it to S3 default to the current OS temporary directory in linux /tmp/logstash'),
		createSnippet('time_file', 'option', 'time_file => ${1:15}', '**[time_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-time_file) option**\n\n- Value type is number\n- Default value is 15\n\nSet the time, in MINUTES, to close the current sub_time_section of bucket. If rotation_strategy is set to time or size_and_time, then time_file cannot be set to 0. Otherwise, the plugin raises a configuration error.'),
		createSnippet('upload_multipart_threshold', 'option', 'upload_multipart_threshold => ${1:15728640}', '**[upload_multipart_threshold](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-upload_multipart_threshold) option**\n\n- Value type is number\n- Default value is 15728640\n\nFiles larger than this number are uploaded using the S3 multipart APIs'),
		createSnippet('upload_queue_size', 'option', 'upload_queue_size => ${1:4}', '**[upload_queue_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-upload_queue_size) option**\n\n- Value type is number\n- Default value is 4\n\nNumber of items we can keep in the local queue before uploading them'),
		createSnippet('upload_workers_count', 'option', 'upload_workers_count => ${1:4}', '**[upload_workers_count](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-upload_workers_count) option**\n\n- Value type is number\n- Default value is 4\n\nSpecify how many workers to use to upload the files to S3'),
		createSnippet('validate_credentials_on_root_bucket', 'option', 'validate_credentials_on_root_bucket => ${1|true,false|}', '**[validate_credentials_on_root_bucket](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html#plugins-outputs-s3-validate_credentials_on_root_bucket) option**\n\n- Value type is boolean\n- Default value is true\n\nThe common use case is to define permissions on the root bucket and give Logstash full access to write logs. In some circumstances, you need more granular permissions on the subfolder. This allows you to disable the check at startup.')
	],
	'logstash-input-s3': [
		createSnippet('access_key_id', 'option', 'access_key_id => "${1:access_key_id}"', '**[access_key_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-access_key_id) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThis plugin uses the AWS SDK and supports several ways to get credentials, which will be tried in this order:'),
		createSnippet('additional_settings', 'option', 'additional_settings => {\n\t"${1:key}" => "${2:value}"\n}', '**[additional_settings](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-additional_settings) option**\n\n- Value type is hash\n- Default value is {}\n\nKey-value pairs of settings and corresponding values used to parametrize the connection to s3. See full list in the AWS SDK documentation. Example:\n\n**_Example:_**  \n``` ruby\n    input {\n      s3 {\n        access_key_id => "1234"\n        secret_access_key => "secret"\n        bucket => "logstash-test"\n        additional_settings => {\n          force_path_style => true\n          follow_redirects => false\n        }\n      }\n    }\n```'),
		createSnippet('aws_credentials_file', 'option', 'aws_credentials_file => "${1:aws_credentials_file}"', '**[aws_credentials_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-aws_credentials_file) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nPath to YAML file containing a hash of AWS credentials. This file will only be loaded if access_key_id and secret_access_key aren’t set. The contents of the file should look like this:'),
		createSnippet('backup_add_prefix', 'option', 'backup_add_prefix => "${1:backup_add_prefix}"', '**[backup_add_prefix](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-backup_add_prefix) option**\n\n- Value type is string\n- Default value is nil\n\nAppend a prefix to the key (full path including file name in s3) after processing. If backing up to another (or the same) bucket, this effectively lets you choose a new folder to place the files in'),
		createSnippet('backup_to_bucket', 'option', 'backup_to_bucket => "${1:backup_to_bucket}"', '**[backup_to_bucket](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-backup_to_bucket) option**\n\n- Value type is string\n- Default value is nil\n\nName of a S3 bucket to backup processed files to.'),
		createSnippet('backup_to_dir', 'option', 'backup_to_dir => "${1:backup_to_dir}"', '**[backup_to_dir](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-backup_to_dir) option**\n\n- Value type is string\n- Default value is nil\n\nPath of a local directory to backup processed files to.'),
		createSnippet('bucket', 'option', 'bucket => "${1:bucket}"', '**[bucket](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-bucket) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe name of the S3 bucket.', true),
		createSnippet('delete', 'option', 'delete => ${1|false,true|}', '**[delete](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-delete) option**\n\n- Value type is boolean\n- Default value is false\n\nWhether to delete processed files from the original bucket.'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: does not use ECS-compatible field names v1,v8: uses metadata fields that are compatible with Elastic Common Schema\n- disabled: does not use ECS-compatible field names\n- v1,v8: uses metadata fields that are compatible with Elastic Common Schema\n\nSupported values are:'),
		createSnippet('endpoint', 'option', 'endpoint => "${1:endpoint}"', '**[endpoint](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-endpoint) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe endpoint to connect to. By default it is constructed using the value of region. This is useful when connecting to S3 compatible services, but beware that these aren’t guaranteed to work correctly with the AWS SDK.'),
		createSnippet('exclude_pattern', 'option', 'exclude_pattern => "${1:exclude_pattern}"', '**[exclude_pattern](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-exclude_pattern) option**\n\n- Value type is string\n- Default value is nil\n\nRuby style regexp of keys to exclude from the bucket.'),
		createSnippet('gzip_pattern', 'option', 'gzip_pattern => "${1:\\.gz(ip)?\\$}"', '**[gzip_pattern](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-gzip_pattern) option**\n\n- Value type is string\n- Default value is "\\\\.gz(ip)?$"\n\nRegular expression used to determine whether an input file is in gzip format.'),
		createSnippet('include_object_properties', 'option', 'include_object_properties => ${1|false,true|}', '**[include_object_properties](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-include_object_properties) option**\n\n- Value type is boolean\n- Default value is false\n\nWhether or not to include the S3 object’s properties (last_modified, content_type, metadata) into each Event at [@metadata][s3]. Regardless of this setting, [@metadata][s3][key] will always be present.'),
		createSnippet('interval', 'option', 'interval => ${1:60}', '**[interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-interval) option**\n\n- Value type is number\n- Default value is 60\n\nInterval to wait between to check the file list again after a run is finished. Value is in seconds.'),
		createSnippet('prefix', 'option', 'prefix => "${1:prefix}"', '**[prefix](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-prefix) option**\n\n- Value type is string\n- Default value is nil\n\nIf specified, the prefix of filenames in the bucket must match (not a regexp)'),
		createSnippet('proxy_uri', 'option', 'proxy_uri => "${1:proxy_uri}"', '**[proxy_uri](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-proxy_uri) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nURI to proxy server if required'),
		createSnippet('region', 'option', 'region => "${1:us-east-1}"', '**[region](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-region) option**\n\n- Value type is string\n- Default value is "us-east-1"\n\nThe AWS Region'),
		createSnippet('role_arn', 'option', 'role_arn => "${1:role_arn}"', '**[role_arn](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-role_arn) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS IAM Role to assume, if any. This is used to generate temporary credentials, typically for cross-account access. See the AssumeRole API documentation for more information.'),
		createSnippet('role_session_name', 'option', 'role_session_name => "${1:logstash}"', '**[role_session_name](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-role_session_name) option**\n\n- Value type is string\n- Default value is "logstash"\n\nSession name to use when assuming an IAM role.'),
		createSnippet('secret_access_key', 'option', 'secret_access_key => "${1:secret_access_key}"', '**[secret_access_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-secret_access_key) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS Secret Access Key'),
		createSnippet('session_token', 'option', 'session_token => "${1:session_token}"', '**[session_token](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-session_token) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS Session token for temporary credential'),
		createSnippet('sincedb_path', 'option', 'sincedb_path => "${1:sincedb_path}"', '**[sincedb_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-sincedb_path) option**\n\n- Value type is string\n- Default value is nil\n\nWhere to write the since database (keeps track of the date the last handled file was added to S3). The default will write sincedb files to in the directory {path.data}/plugins/inputs/s3/'),
		createSnippet('temporary_directory', 'option', 'temporary_directory => "${1:/tmp/logstash}"', '**[temporary_directory](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-temporary_directory) option**\n\n- Value type is string\n- Default value is "/tmp/logstash"\n\nSet the directory where logstash will store the tmp files before processing them.'),
		createSnippet('watch_for_new_files', 'option', 'watch_for_new_files => ${1|true,false|}', '**[watch_for_new_files](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html#plugins-inputs-s3-watch_for_new_files) option**\n\n- Value type is boolean\n- Default value is true\n\nWhether or not to watch for new files. Disabling this option causes the input to close itself after processing the files from a single listing.')
	],
	'logstash-output-elastic_app_search': [
		createSnippet('api_key', 'option', 'api_key => "${1:api_key}"', '**[api_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elastic_app_search.html#plugins-outputs-elastic_app_search-api_key) option**\n\n- Value type is password\n- There is no default value\n\nThe private API Key with write permissions. Visit the Credentials in the App Search dashboard to find the key associated with your account.', true),
		createSnippet('document_id', 'option', 'document_id => "${1:document_id}"', '**[document_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elastic_app_search.html#plugins-outputs-elastic_app_search-document_id) option**\n\n- Value type is string\n- There is no default value\n\nThe id for app search documents. This can be an interpolated value like myapp-%{sequence_id}. Reusing ids will cause documents to be rewritten.'),
		createSnippet('engine', 'option', 'engine => "${1:engine}"', '**[engine](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elastic_app_search.html#plugins-outputs-elastic_app_search-engine) option**\n\n- Value type is string\n- There is no default value\n\nThe name of the search engine you created in App Search, an information repository that includes the indexed document records. The engine field supports sprintf format to allow the engine name to be derived from a field value from each event, for example engine-%{engine_name}.\n\n**_Example:_**  \n``` ruby\ninput {\n  stdin {\n    codec => json\n  }\n}\n\nfilter {\n  if ![engine_name] {\n    mutate {\n      add_field => {"engine_name" => "default"}\n    }\n  }\n}\n\noutput {\n  appsearch {\n    engine => "engine_%{[engine_name]}"\n  }\n}\n```', true),
		createSnippet('host', 'option', 'host => "${1:host}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elastic_app_search.html#plugins-outputs-elastic_app_search-host) option**\n\n- Value type is string\n- There is no default value\n\nThe hostname of the App Search API that is associated with your App Search account. Set this when using the Elastic App Search managed service.'),
		createSnippet('path', 'option', 'path => "${1:/api/as/v1/}"', '**[path](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elastic_app_search.html#plugins-outputs-elastic_app_search-path) option**\n\n- Value type is string\n- Default value is /api/as/v1/\n\nThe path that is appended to the url parameter when connecting to a self-managed Elastic App Search.'),
		createSnippet('timestamp_destination', 'option', 'timestamp_destination => "${1:timestamp_destination}"', '**[timestamp_destination](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elastic_app_search.html#plugins-outputs-elastic_app_search-timestamp_destination) option**\n\n- Value type is string\n- There is no default value\n\nWhere to move the value from the @timestamp field.'),
		createSnippet('url', 'option', 'url => "${1:url}"', '**[url](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elastic_app_search.html#plugins-outputs-elastic_app_search-url) option**\n\n- Value type is string\n- There is no default value\n\nThe value of the API endpoint in the form of a URL. Note: The value of the of the path setting will be will be appended to this URL. Set this when using the self-managed Elastic App Search.')
	],
	'logstash-filter-tld': [
		createSnippet('source', 'option', 'source => "${1:message}"', '**[source](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-tld.html#plugins-filters-tld-source) option**\n\n- Value type is string\n- Default value is "message"\n\nSetting the config_name here is required. This is how you configure this filter from your Logstash config.'),
		createSnippet('target', 'option', 'target => "${1:tld}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-tld.html#plugins-filters-tld-target) option**\n\n- Value type is string\n- Default value is "tld"\n\nThe target field to place all the data')
	],
	'logstash-input-exec': [
		createSnippet('command', 'option', 'command => "${1:command}"', '**[command](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-exec.html#plugins-inputs-exec-command) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nCommand to run. For example, uptime', true),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-exec.html#plugins-inputs-exec-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: uses backwards compatible field names, such as [host] v1, v8: uses fields that are compatible with ECS, such as [host][name]\n- disabled: uses backwards compatible field names, such as [host]\n- v1, v8: uses fields that are compatible with ECS, such as [host][name]\n\nSupported values are:'),
		createSnippet('interval', 'option', 'interval => ${1:123}', '**[interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-exec.html#plugins-inputs-exec-interval) option**\n\n- Value type is number\n- There is no default value for this setting.\n\nInterval to run the command. Value is in seconds.'),
		createSnippet('schedule', 'option', 'schedule => "${1:schedule}"', '**[schedule](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-exec.html#plugins-inputs-exec-schedule) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nSchedule of when to periodically run command.')
	],
	'logstash-codec-java_line': [
		createSnippet('charset', 'option', 'charset => "${1|UTF-8,ASCII-8BIT,US-ASCII,Big5,Big5-HKSCS,Big5-UAO,CP949,Emacs-Mule,EUC-JP,EUC-KR,EUC-TW,GB2312,GB18030,GBK,ISO-8859-1,ISO-8859-2,ISO-8859-3,ISO-8859-4,ISO-8859-5,ISO-8859-6,ISO-8859-7,ISO-8859-8,ISO-8859-9,ISO-8859-10,ISO-8859-11,ISO-8859-13,ISO-8859-14,ISO-8859-15,ISO-8859-16,KOI8-R,KOI8-U,Shift_JIS,UTF-16BE,UTF-16LE,UTF-32BE,UTF-32LE,Windows-31J,Windows-1250,Windows-1251,Windows-1252,IBM437,IBM737,IBM775,CP850,IBM852,CP852,IBM855,CP855,IBM857,IBM860,IBM861,IBM862,IBM863,IBM864,IBM865,IBM866,IBM869,Windows-1258,GB1988,macCentEuro,macCroatian,macCyrillic,macGreek,macIceland,macRoman,macRomania,macThai,macTurkish,macUkraine,CP950,CP951,IBM037,stateless-ISO-2022-JP,eucJP-ms,CP51932,EUC-JIS-2004,GB12345,ISO-2022-JP,ISO-2022-JP-2,CP50220,CP50221,Windows-1256,Windows-1253,Windows-1255,Windows-1254,TIS-620,Windows-874,Windows-1257,MacJapanese,UTF-7,UTF8-MAC,UTF-16,UTF-32,UTF8-DoCoMo,SJIS-DoCoMo,UTF8-KDDI,SJIS-KDDI,ISO-2022-JP-KDDI,stateless-ISO-2022-JP-KDDI,UTF8-SoftBank,SJIS-SoftBank,BINARY,CP437,CP737,CP775,IBM850,CP857,CP860,CP861,CP862,CP863,CP864,CP865,CP866,CP869,CP1258,Big5-HKSCS:2008,ebcdic-cp-us,eucJP,euc-jp-ms,EUC-JISX0213,eucKR,eucTW,EUC-CN,eucCN,CP936,ISO2022-JP,ISO2022-JP2,ISO8859-1,ISO8859-2,ISO8859-3,ISO8859-4,ISO8859-5,ISO8859-6,CP1256,ISO8859-7,CP1253,ISO8859-8,CP1255,ISO8859-9,CP1254,ISO8859-10,ISO8859-11,CP874,ISO8859-13,CP1257,ISO8859-14,ISO8859-15,ISO8859-16,CP878,MacJapan,ASCII,ANSI_X3.4-1968,646,CP65000,CP65001,UTF-8-MAC,UTF-8-HFS,UCS-2BE,UCS-4BE,UCS-4LE,CP932,csWindows31J,SJIS,PCK,CP1250,CP1251,CP1252,external,locale|}"$0', '**[charset](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-java_line.html#plugins-codecs-java_line-charset) option**\n\n- Value can be any of: ASCII-8BIT, UTF-8, US-ASCII, Big5, Big5-HKSCS, Big5-UAO, CP949, Emacs-Mule, EUC-JP, EUC-KR, EUC-TW, GB2312, GB18030, GBK, ISO-8859-1, ISO-8859-2, ISO-8859-3, ISO-8859-4, ISO-8859-5, ISO-8859-6, ISO-8859-7, ISO-8859-8, ISO-8859-9, ISO-8859-10, ISO-8859-11, ISO-8859-13, ISO-8859-14, ISO-8859-15, ISO-8859-16, KOI8-R, KOI8-U, Shift_JIS, UTF-16BE, UTF-16LE, UTF-32BE, UTF-32LE, Windows-31J, Windows-1250, Windows-1251, Windows-1252, IBM437, IBM737, IBM775, CP850, IBM852, CP852, IBM855, CP855, IBM857, IBM860, IBM861, IBM862, IBM863, IBM864, IBM865, IBM866, IBM869, Windows-1258, GB1988, macCentEuro, macCroatian, macCyrillic, macGreek, macIceland, macRoman, macRomania, macThai, macTurkish, macUkraine, CP950, CP951, IBM037, stateless-ISO-2022-JP, eucJP-ms, CP51932, EUC-JIS-2004, GB12345, ISO-2022-JP, ISO-2022-JP-2, CP50220, CP50221, Windows-1256, Windows-1253, Windows-1255, Windows-1254, TIS-620, Windows-874, Windows-1257, MacJapanese, UTF-7, UTF8-MAC, UTF-16, UTF-32, UTF8-DoCoMo, SJIS-DoCoMo, UTF8-KDDI, SJIS-KDDI, ISO-2022-JP-KDDI, stateless-ISO-2022-JP-KDDI, UTF8-SoftBank, SJIS-SoftBank, BINARY, CP437, CP737, CP775, IBM850, CP857, CP860, CP861, CP862, CP863, CP864, CP865, CP866, CP869, CP1258, Big5-HKSCS:2008, ebcdic-cp-us, eucJP, euc-jp-ms, EUC-JISX0213, eucKR, eucTW, EUC-CN, eucCN, CP936, ISO2022-JP, ISO2022-JP2, ISO8859-1, ISO8859-2, ISO8859-3, ISO8859-4, ISO8859-5, ISO8859-6, CP1256, ISO8859-7, CP1253, ISO8859-8, CP1255, ISO8859-9, CP1254, ISO8859-10, ISO8859-11, CP874, ISO8859-13, CP1257, ISO8859-14, ISO8859-15, ISO8859-16, CP878, MacJapan, ASCII, ANSI_X3.4-1968, 646, CP65000, CP65001, UTF-8-MAC, UTF-8-HFS, UCS-2BE, UCS-4BE, UCS-4LE, CP932, csWindows31J, SJIS, PCK, CP1250, CP1251, CP1252, external, locale\n- Default value is "UTF-8"\n\nThe character encoding used by this input. Examples include UTF-8 and cp1252. This setting is useful if your inputs are in Latin-1 (aka cp1252) or other character sets than UTF-8.'),
		createSnippet('delimiter', 'option', 'delimiter => "${1:delimiter}"', '**[delimiter](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-java_line.html#plugins-codecs-java_line-delimiter) option**\n\n- Value type is string\n- Default value is the system-dependent line separator ("\n" for UNIX systems; "\\\\r\n" for Microsoft Windows)\n\nSpecifies the delimiter that indicates end-of-line.'),
		createSnippet('format', 'option', 'format => "${1:format}"', '**[format](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-java_line.html#plugins-codecs-java_line-format) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nSet the desired text format for encoding in sprintf format.')
	],
	'logstash-filter-common_options': [
		createSnippet('add_field', 'common_option', 'add_field => {\n\t"${1:field}" => "${2:value}"\n}', '**[add_field](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-age.html#plugins-filters-age-add_field) option**\n\n- Value type is hash\n- Default value is {}\n\nIf this filter is successful, add any arbitrary fields to this event. Field names can be dynamic and include parts of the event using the %{field}.\n\n**_Example:_**  \n``` ruby\n    filter {\n      age {\n        add_field => { "foo_%{somefield}" => "Hello world, from %{host}" }\n      }\n    }\n```'),
		createSnippet('add_tag', 'common_option', 'add_tag => ["${1:tag}"]', '**[add_tag](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-age.html#plugins-filters-age-add_tag) option**\n\n- Value type is array\n- Default value is []\n\nIf this filter is successful, add arbitrary tags to the event. Tags can be dynamic and include parts of the event using the %{field} syntax.\n\n**_Example:_**  \n``` ruby\n    filter {\n      age {\n        add_tag => [ "foo_%{somefield}" ]\n      }\n    }\n```'),
		createSnippet('enable_metric', 'common_option', 'enable_metric => ${1|true,false|}', '**[enable_metric](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-age.html#plugins-filters-age-enable_metric) option**\n\n- Value type is boolean\n- Default value is true\n\nDisable or enable metric logging for this specific plugin instance. By default we record all the metrics we can, but you can disable metrics collection for a specific plugin.'),
		createSnippet('id', 'common_option', 'id => "${1:id}"', '**[id](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-age.html#plugins-filters-age-id) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nAdd a unique ID to the plugin configuration. If no ID is specified, Logstash will generate one. It is strongly recommended to set this ID in your configuration. This is particularly useful when you have two or more plugins of the same type, for example, if you have 2 age filters. Adding a named ID in this case will help in monitoring Logstash when using the monitoring APIs.\n\n**_Example:_**  \n``` ruby\n    filter {\n      age {\n        id => "ABC"\n      }\n    }\n```'),
		createSnippet('periodic_flush', 'common_option', 'periodic_flush => ${1|false,true|}', '**[periodic_flush](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-age.html#plugins-filters-age-periodic_flush) option**\n\n- Value type is boolean\n- Default value is false\n\nCall the filter flush method at regular interval. Optional.'),
		createSnippet('remove_field', 'common_option', 'remove_field => ["${1:field}"]', '**[remove_field](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-age.html#plugins-filters-age-remove_field) option**\n\n- Value type is array\n- Default value is []\n\nIf this filter is successful, remove arbitrary fields from this event. Fields names can be dynamic and include parts of the event using the %{field} Example:\n\n**_Example:_**  \n``` ruby\n    filter {\n      age {\n        remove_field => [ "foo_%{somefield}" ]\n      }\n    }\n```'),
		createSnippet('remove_tag', 'common_option', 'remove_tag => ["${1:tag}"]', '**[remove_tag](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-age.html#plugins-filters-age-remove_tag) option**\n\n- Value type is array\n- Default value is []\n\nIf this filter is successful, remove arbitrary tags from the event. Tags can be dynamic and include parts of the event using the %{field} syntax.\n\n**_Example:_**  \n``` ruby\n    filter {\n      age {\n        remove_tag => [ "foo_%{somefield}" ]\n      }\n    }\n```')
	],
	'logstash-filter-age': [
		createSnippet('target', 'option', 'target => "${1:[@metadata][age]}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-age.html#plugins-filters-age-target) option**\n\n- Value type is string\n- Default value is "[@metadata][age]"\n\nDefine the target field for the event age, in seconds.')
	],
	'logstash-filter-translate': [
		createSnippet('destination', 'option', 'destination => "${1:destination}"', '**[destination](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-translate.html#plugins-filters-translate-destination) option**\n\n- Value type is string\n- Deprecated alias for target setting.\n\nUse target instead. In 4.0 this setting will be removed.'),
		createSnippet('dictionary', 'option', 'dictionary => {\n\t"${1:key}" => "${2:value}"\n}', '**[dictionary](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-translate.html#plugins-filters-translate-dictionary) option**\n\n- Value type is hash\n- Default value is {}\n\nThe dictionary to use for translation, when specified in the logstash filter configuration item (i.e. do not use the dictionary_path file).\n\n**_Example:_**  \n``` ruby\n    filter {\n      translate {\n        dictionary => {\n          "100"         => "Continue"\n          "101"         => "Switching Protocols"\n          "merci"       => "thank you"\n          "old version" => "new version"\n        }\n      }\n    }\n```'),
		createSnippet('dictionary_path', 'option', 'dictionary_path => "${1:/path/to/file}"', '**[dictionary_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-translate.html#plugins-filters-translate-dictionary_path) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nThe full path of the external dictionary file. The format of the table should be a standard YAML, JSON, or CSV.'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-translate.html#plugins-filters-translate-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: disabled ECS-compatibility v1, v8: compatibility with the specified major version of the Elastic Common Schema\n- disabled: disabled ECS-compatibility\n- v1, v8: compatibility with the specified major version of the Elastic Common Schema\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:'),
		createSnippet('exact', 'option', 'exact => ${1|true,false|}', '**[exact](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-translate.html#plugins-filters-translate-exact) option**\n\n- Value type is boolean\n- Default value is true\n\nWhen exact => true, the translate filter will populate the destination field with the exact contents of the dictionary value. When exact => false, the filter will populate the destination field with the result of any existing destination field’s data, with the translated value substituted in-place.'),
		createSnippet('fallback', 'option', 'fallback => "${1:fallback}"', '**[fallback](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-translate.html#plugins-filters-translate-fallback) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nIn case no translation occurs in the event (no matches), this will add a default translation string, which will always populate field, if the match failed.'),
		createSnippet('field', 'option', 'field => "${1:field}"', '**[field](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-translate.html#plugins-filters-translate-field) option**\n\n- Value type is string\n- Deprecated alias for source setting.\n\nUse source instead. In 4.0 this setting will be removed.'),
		createSnippet('iterate_on', 'option', 'iterate_on => "${1:iterate_on}"', '**[iterate_on](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-translate.html#plugins-filters-translate-iterate_on) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nWhen the value that you need to perform enrichment on is a variable sized array then specify the field name in this setting. This setting introduces two modes, 1) when the value is an array of strings and 2) when the value is an array of objects (as in JSON object). In the first mode, you should have the same field name in both source and iterate_on, the result will be an array added to the field specified in the target setting. This array will have the looked up value (or the fallback value or nil) in same ordinal position as each sought value. In the second mode, specify the field that has the array of objects in iterate_on then specify the field in each object that provides the sought value with source and the field to write the looked up value (or the fallback value) to with target.\n\n**_Example:_**  \n``` ruby\n    filter {\n      translate {\n        iterate_on => "[collaborator_ids]"\n        source     => "[collaborator_ids]"\n        target     => "[collaborator_names]"\n        fallback => "Unknown"\n      }\n    }\n```'),
		createSnippet('override', 'option', 'override => ${1|true,false|}', '**[override](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-translate.html#plugins-filters-translate-override) option**\n\n- Value type is boolean\n- Default value depends on whether in-place translation is being used\n\nIf the destination (or target) field already exists, this configuration option controls whether the filter skips translation (default behavior) or overwrites the target field value with the new translation value.'),
		createSnippet('refresh_interval', 'option', 'refresh_interval => ${1:300}', '**[refresh_interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-translate.html#plugins-filters-translate-refresh_interval) option**\n\n- Value type is number\n- Default value is 300\n\nWhen using a dictionary file, this setting will indicate how frequently (in seconds) logstash will check the dictionary file for updates. A value of zero or less will disable refresh.'),
		createSnippet('regex', 'option', 'regex => ${1|false,true|}', '**[regex](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-translate.html#plugins-filters-translate-regex) option**\n\n- Value type is boolean\n- Default value is false\n\nTo treat dictionary keys as regular expressions, set regex => true.'),
		createSnippet('source', 'option', 'source => "${1:source}"', '**[source](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-translate.html#plugins-filters-translate-source) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe name of the logstash event field containing the value to be compared for a match by the translate filter (e.g. message, host, response_code).', true),
		createSnippet('refresh_behaviour', 'option', 'refresh_behaviour => "${1:merge}"', '**[refresh_behaviour](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-translate.html#plugins-filters-translate-refresh_behaviour) option**\n\n- Value type is string\n- Default value is merge\n\nWhen using a dictionary file, this setting indicates how the update will be executed. Setting this to merge causes the new dictionary to be merged into the old one. This means same entry will be updated but entries that existed before but not in the new dictionary will remain after the merge; replace causes the whole dictionary to be replaced with a new one (deleting all entries of the old one on update).'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-translate.html#plugins-filters-translate-target) option**\n\n- Value type is string\n- Default value depends on whether ecs_compatibility is enabled: ECS Compatibility disabled: "translation" ECS Compatibility enabled: defaults to the same value as source\n- ECS Compatibility disabled: "translation"\n- ECS Compatibility enabled: defaults to the same value as source\n\nDefault value depends on whether ecs_compatibility is enabled:')
	],
	'logstash-output-librato': [
		createSnippet('account_id', 'option', 'account_id => "${1:account_id}"', '**[account_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-librato.html#plugins-outputs-librato-account_id) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nYour Librato account usually an email address', true),
		createSnippet('annotation', 'option', 'annotation => {\n\t"${1:key}" => "${2:value}"\n}', '**[annotation](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-librato.html#plugins-outputs-librato-annotation) option**\n\n- Value type is hash\n- Default value is {}\n\nAnnotations Registers an annotation with Librato The only required field is title and name. start_time and end_time will be set to event.get("@timestamp").to_i You can add any other optional annotation values as well. All values will be passed through event.sprintf'),
		createSnippet('api_token', 'option', 'api_token => "${1:api_token}"', '**[api_token](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-librato.html#plugins-outputs-librato-api_token) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nYour Librato API Token', true),
		createSnippet('batch_size', 'option', 'batch_size => "${1:10}"', '**[batch_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-librato.html#plugins-outputs-librato-batch_size) option**\n\n- Value type is string\n- Default value is "10"\n\nBatch size Number of events to batch up before sending to Librato.'),
		createSnippet('counter', 'option', 'counter => {\n\t"${1:key}" => "${2:value}"\n}', '**[counter](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-librato.html#plugins-outputs-librato-counter) option**\n\n- Value type is hash\n- Default value is {}\n\nCounters Send data to Librato as a counter'),
		createSnippet('gauge', 'option', 'gauge => {\n\t"${1:key}" => "${2:value}"\n}', '**[gauge](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-librato.html#plugins-outputs-librato-gauge) option**\n\n- Value type is hash\n- Default value is {}\n\nGauges Send data to Librato as a gauge')
	],
	'logstash-input-elastic_agent': [
		createSnippet('add_hostname', 'option', 'add_hostname => ${1|false,true|}', '**[add_hostname](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elastic_agent.html#plugins-inputs-elastic_agent-add_hostname) option**\n\n- Value type is boolean\n- Default value is false\n\nThe default value has been changed to false. In 7.0.0 this setting will be removed'),
		createSnippet('cipher_suites', 'option', 'cipher_suites => ["${1:TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384}", "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384", "TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256", "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256", "TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384", "TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384", "TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256", "TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256"]', '**[cipher_suites](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elastic_agent.html#plugins-inputs-elastic_agent-cipher_suites) option**\n\n- Value type is array\n- Default value is java.lang.String[TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256, TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256]@459cfcca\n\nThe list of ciphers suite to use, listed by priorities.'),
		createSnippet('client_inactivity_timeout', 'option', 'client_inactivity_timeout => ${1:60}', '**[client_inactivity_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elastic_agent.html#plugins-inputs-elastic_agent-client_inactivity_timeout) option**\n\n- Value type is number\n- Default value is 60\n\nClose Idle clients after X seconds of inactivity.'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elastic_agent.html#plugins-inputs-elastic_agent-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: unstructured connection metadata added at root level v1: structured connection metadata added under ECS v1 compliant namespaces v8: structured connection metadata added under ECS v8 compliant namespaces\n- disabled: unstructured connection metadata added at root level\n- v1: structured connection metadata added under ECS v1 compliant namespaces\n- v8: structured connection metadata added under ECS v8 compliant namespaces\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:'),
		createSnippet('executor_threads', 'option', 'executor_threads => ${1:1 executor thread per CPU core}', '**[executor_threads](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elastic_agent.html#plugins-inputs-elastic_agent-executor_threads) option**\n\n- Value type is number\n- Default value is 1 executor thread per CPU core\n\nThe number of threads to be used to process incoming beats requests. By default the Beats input creates a number of threads equal to 2*CPU cores. These threads handle incoming connections, reading from established sockets, and executing most of the tasks related to network connection management. Parsing the Lumberjack protocol is offloaded to a dedicated thread pool.'),
		createSnippet('host', 'option', 'host => "${1:0.0.0.0}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elastic_agent.html#plugins-inputs-elastic_agent-host) option**\n\n- Value type is string\n- Default value is "0.0.0.0"\n\nThe IP address to listen on.'),
		createSnippet('include_codec_tag', 'option', 'include_codec_tag => ${1|true,false|}', '**[include_codec_tag](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elastic_agent.html#plugins-inputs-elastic_agent-include_codec_tag) option**\n\n- Value type is boolean\n- Default value is true'),
		createSnippet('port', 'option', 'port => ${1:123}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elastic_agent.html#plugins-inputs-elastic_agent-port) option**\n\n- This is a required setting.\n- Value type is number\n- There is no default value for this setting.\n\nThe port to listen on.', true),
		createSnippet('ssl', 'option', 'ssl => ${1|false,true|}', '**[ssl](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elastic_agent.html#plugins-inputs-elastic_agent-ssl) option**\n\n- Value type is boolean\n- Default value is false\n\nEvents are by default sent in plain text. You can enable encryption by setting ssl to true and configuring the ssl_certificate and ssl_key options.'),
		createSnippet('ssl_certificate', 'option', 'ssl_certificate => "${1:/path/to/file}"', '**[ssl_certificate](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elastic_agent.html#plugins-inputs-elastic_agent-ssl_certificate) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nSSL certificate to use.'),
		createSnippet('ssl_certificate_authorities', 'option', 'ssl_certificate_authorities => ["${1:ssl_certificate_authoritie}"]', '**[ssl_certificate_authorities](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elastic_agent.html#plugins-inputs-elastic_agent-ssl_certificate_authorities) option**\n\n- Value type is array\n- Default value is []\n\nValidate client certificates against these authorities. You can define multiple files or paths. All the certificates will be read and added to the trust store. You need to configure the ssl_verify_mode to peer or force_peer to enable the verification.'),
		createSnippet('ssl_handshake_timeout', 'option', 'ssl_handshake_timeout => ${1:10000}', '**[ssl_handshake_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elastic_agent.html#plugins-inputs-elastic_agent-ssl_handshake_timeout) option**\n\n- Value type is number\n- Default value is 10000\n\nTime in milliseconds for an incomplete ssl handshake to timeout'),
		createSnippet('ssl_key', 'option', 'ssl_key => "${1:/path/to/file}"', '**[ssl_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elastic_agent.html#plugins-inputs-elastic_agent-ssl_key) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nSSL key to use. This key must be in the PKCS8 format and PEM encoded. You can use the openssl pkcs8 command to complete the conversion. For example, the command to convert a PEM encoded PKCS1 private key to a PEM encoded, non-encrypted PKCS8 key is:'),
		createSnippet('ssl_key_passphrase', 'option', 'ssl_key_passphrase => "${1:ssl_key_passphrase}"', '**[ssl_key_passphrase](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elastic_agent.html#plugins-inputs-elastic_agent-ssl_key_passphrase) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nSSL key passphrase to use.'),
		createSnippet('ssl_verify_mode', 'option', 'ssl_verify_mode => "${1|none,peer,force_peer|}"$0', '**[ssl_verify_mode](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elastic_agent.html#plugins-inputs-elastic_agent-ssl_verify_mode) option**\n\n- Value can be any of: none, peer, force_peer\n- Default value is "none"\n\nBy default the server doesn’t do any client verification.'),
		createSnippet('ssl_peer_metadata', 'option', 'ssl_peer_metadata => ${1|false,true|}', '**[ssl_peer_metadata](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elastic_agent.html#plugins-inputs-elastic_agent-ssl_peer_metadata) option**\n\n- Value type is boolean\n- Default value is false\n\nEnables storing client certificate information in event’s metadata.'),
		createSnippet('tls_max_version', 'option', 'tls_max_version => ${1:1.2}', '**[tls_max_version](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elastic_agent.html#plugins-inputs-elastic_agent-tls_max_version) option**\n\n- Value type is number\n- Default value is 1.2\n\nThe maximum TLS version allowed for the encrypted connections. The value must be the one of the following: 1.0 for TLS 1.0, 1.1 for TLS 1.1, 1.2 for TLS 1.2'),
		createSnippet('tls_min_version', 'option', 'tls_min_version => ${1:1}', '**[tls_min_version](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elastic_agent.html#plugins-inputs-elastic_agent-tls_min_version) option**\n\n- Value type is number\n- Default value is 1\n\nThe minimum TLS version allowed for the encrypted connections. The value must be one of the following: 1.0 for TLS 1.0, 1.1 for TLS 1.1, 1.2 for TLS 1.2')
	],
	'logstash-input-http': [
		createSnippet('additional_codecs', 'option', 'additional_codecs => {\n\t"${1:key}" => "${2:value}"\n}', '**[additional_codecs](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-additional_codecs) option**\n\n- Value type is hash\n- Default value is {"application/json"=>"json"}\n\nApply specific codecs for specific content types. The default codec will be applied only after this list is checked and no codec for the request’s content-type is found'),
		createSnippet('cipher_suites', 'option', 'cipher_suites => ["${1:TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384}", "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384", "TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256", "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256", "TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384", "TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384", "TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256", "TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256"]', '**[cipher_suites](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-cipher_suites) option**\n\n- Value type is array\n- Default value is java.lang.String[TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256, TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256]@459cfcca\n\nThe list of ciphers suite to use, listed by priorities.'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: unstructured connection metadata added at root level v1,v8: headers added under [@metadata][http][header]. Some are copied to structured ECS fields http, url, user_agent and host\n- disabled: unstructured connection metadata added at root level\n- v1,v8: headers added under [@metadata][http][header]. Some are copied to structured ECS fields http, url, user_agent and host\n\nSupported values are:'),
		createSnippet('host', 'option', 'host => "${1:0.0.0.0}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-host) option**\n\n- Value type is string\n- Default value is "0.0.0.0"\n\nThe host or ip to bind'),
		createSnippet('keystore', 'option', 'keystore => "${1:/path/to/file}"', '**[keystore](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-keystore) option**\n\n- Value type is path\n- There is no default value for this setting.\n- This option is deprecated\n\nThe JKS keystore to validate the client’s certificates'),
		createSnippet('keystore_password', 'option', 'keystore_password => "${1:keystore_password}"', '**[keystore_password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-keystore_password) option**\n\n- Value type is password\n- There is no default value for this setting.\n- This option is deprecated\n\nSet the truststore password'),
		createSnippet('password', 'option', 'password => "${1:password}"', '**[password](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-password) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nPassword for basic authorization'),
		createSnippet('port', 'option', 'port => ${1:8080}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-port) option**\n\n- Value type is number\n- Default value is 8080\n\nThe TCP port to bind to'),
		createSnippet('max_pending_requests', 'option', 'max_pending_requests => ${1:200}', '**[max_pending_requests](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-max_pending_requests) option**\n\n- Value type is number\n- Default value is 200\n\nMaximum number of incoming requests to store in a temporary queue before being processed by worker threads. If a request arrives and the queue is full a 429 response will be returned immediately. This queue exists to deal with micro bursts of events and to improve overall throughput, so it should be changed very carefully as it can lead to memory pressure and impact performance. If you need to deal both periodic or unforeseen spikes in incoming requests consider enabling the Persistent Queue for the logstash pipeline.'),
		createSnippet('response_headers', 'option', 'response_headers => {\n\t"${1:key}" => "${2:value}"\n}', '**[response_headers](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-response_headers) option**\n\n- Value type is hash\n- Default value is {"Content-Type"=>"text/plain"}\n\nspecify a custom set of response headers'),
		createSnippet('response_code', 'option', 'response_code => "${1|200,201,202,204|}"$0', '**[response_code](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-response_code) option**\n\n- Value can be any of: 200, 201, 202, 204\n- Default value is 200\n\nThe HTTP return code if the request is processed successfully.'),
		createSnippet('ssl', 'option', 'ssl => ${1|false,true|}', '**[ssl](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-ssl) option**\n\n- Value type is boolean\n- Default value is false\n\nEvents are by default sent in plain text. You can enable encryption by setting ssl to true and configuring the ssl_certificate and ssl_key options.'),
		createSnippet('ssl_certificate', 'option', 'ssl_certificate => "${1:/path/to/file}"', '**[ssl_certificate](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-ssl_certificate) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nSSL certificate to use.'),
		createSnippet('ssl_certificate_authorities', 'option', 'ssl_certificate_authorities => ["${1:ssl_certificate_authoritie}"]', '**[ssl_certificate_authorities](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-ssl_certificate_authorities) option**\n\n- Value type is array\n- Default value is []\n\nValidate client certificates against these authorities. You can define multiple files or paths. All the certificates will be read and added to the trust store. You need to configure the ssl_verify_mode to peer or force_peer to enable the verification.'),
		createSnippet('ssl_handshake_timeout', 'option', 'ssl_handshake_timeout => ${1:10000}', '**[ssl_handshake_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-ssl_handshake_timeout) option**\n\n- Value type is number\n- Default value is 10000\n\nTime in milliseconds for an incomplete ssl handshake to timeout'),
		createSnippet('ssl_key', 'option', 'ssl_key => "${1:/path/to/file}"', '**[ssl_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-ssl_key) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nSSL key to use. NOTE: This key need to be in the PKCS8 format, you can convert it with OpenSSL for more information.'),
		createSnippet('ssl_key_passphrase', 'option', 'ssl_key_passphrase => "${1:ssl_key_passphrase}"', '**[ssl_key_passphrase](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-ssl_key_passphrase) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nSSL key passphrase to use.'),
		createSnippet('ssl_verify_mode', 'option', 'ssl_verify_mode => "${1|none,peer,force_peer|}"$0', '**[ssl_verify_mode](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-ssl_verify_mode) option**\n\n- Value can be any of: none, peer, force_peer\n- Default value is "none"\n\nBy default the server doesn’t do any client verification.'),
		createSnippet('threads', 'option', 'threads => ${1:123}', '**[threads](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-threads) option**\n\n- Value type is number\n- Default value is number of processors\n\nNumber of threads to use for both accepting connections and handling requests'),
		createSnippet('tls_max_version', 'option', 'tls_max_version => ${1:1.2}', '**[tls_max_version](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-tls_max_version) option**\n\n- Value type is number\n- Default value is 1.2\n\nThe maximum TLS version allowed for the encrypted connections. The value must be the one of the following: 1.0 for TLS 1.0, 1.1 for TLS 1.1, 1.2 for TLS 1.2'),
		createSnippet('tls_min_version', 'option', 'tls_min_version => ${1:1}', '**[tls_min_version](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-tls_min_version) option**\n\n- Value type is number\n- Default value is 1\n\nThe minimum TLS version allowed for the encrypted connections. The value must be one of the following: 1.0 for TLS 1.0, 1.1 for TLS 1.1, 1.2 for TLS 1.2'),
		createSnippet('user', 'option', 'user => "${1:user}"', '**[user](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-user) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nUsername for basic authorization'),
		createSnippet('verify_mode', 'option', 'verify_mode => "${1|none,peer,force_peer|}"$0', '**[verify_mode](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html#plugins-inputs-http-verify_mode) option**\n\n- Value can be any of: none, peer, force_peer\n- Default value is "none"\n- This option is deprecated\n\nSet the client certificate verification method. Valid methods: none, peer, force_peer')
	],
	'logstash-filter-split': [
		createSnippet('field', 'option', 'field => "${1:message}"', '**[field](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-split.html#plugins-filters-split-field) option**\n\n- Value type is string\n- Default value is "message"\n\nThe field which value is split by the terminator. Can be a multiline message or the ID of an array. Nested arrays are referenced like: "[object_id][array_id]"'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-split.html#plugins-filters-split-target) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe field within the new event which the value is split into. If not set, the target field defaults to split field name.'),
		createSnippet('terminator', 'option', 'terminator => "${1:\n}"', '**[terminator](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-split.html#plugins-filters-split-terminator) option**\n\n- Value type is string\n- Default value is "\n"\n\nThe string to split on. This is usually a line terminator, but can be any string. If you are splitting a JSON array into multiple events, you can ignore this field.')
	],
	'logstash-output-nagios': [
		createSnippet('commandfile', 'option', 'commandfile => "${1:/var/lib/nagios3/rw/nagios.cmd}"', '**[commandfile](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-nagios.html#plugins-outputs-nagios-commandfile) option**\n\n- Value type is string\n- Default value is "/var/lib/nagios3/rw/nagios.cmd"\n\nThe full path to your Nagios command file.'),
		createSnippet('nagios_level', 'option', 'nagios_level => "${1|2,1,0,3|}"$0', '**[nagios_level](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-nagios.html#plugins-outputs-nagios-nagios_level) option**\n\n- Value can be any of: 0, 1, 2, 3\n- Default value is "2"\n\nThe Nagios check level. Should be one of 0=OK, 1=WARNING, 2=CRITICAL, 3=UNKNOWN. Defaults to 2 - CRITICAL.')
	],
	'logstash-filter-alter': [
		createSnippet('coalesce', 'option', 'coalesce => ["${1:coalesce}"]', '**[coalesce](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-alter.html#plugins-filters-alter-coalesce) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nSets the value of field_name to the first nonnull expression among its arguments.\n\n**_Example:_**  \n``` ruby\n    filter {\n      alter {\n        coalesce => [\n             "field_name", "value1", "value2", "value3", ...\n        ]\n      }\n    }\n```'),
		createSnippet('condrewrite', 'option', 'condrewrite => ["${1:condrewrite}"]', '**[condrewrite](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-alter.html#plugins-filters-alter-condrewrite) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nChange the content of the field to the specified value if the actual content is equal to the expected one.\n\n**_Example:_**  \n``` ruby\n    filter {\n      alter {\n        condrewrite => [\n             "field_name", "expected_value", "new_value",\n             "field_name2", "expected_value2", "new_value2",\n             ....\n           ]\n      }\n    }\n```'),
		createSnippet('condrewriteother', 'option', 'condrewriteother => ["${1:condrewriteother}"]', '**[condrewriteother](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-alter.html#plugins-filters-alter-condrewriteother) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nChange the content of the field to the specified value if the content of another field is equal to the expected one.\n\n**_Example:_**  \n``` ruby\n    filter {\n      alter {\n        condrewriteother => [\n             "field_name", "expected_value", "field_name_to_change", "value",\n             "field_name2", "expected_value2", "field_name_to_change2", "value2",\n             ....\n        ]\n      }\n    }\n```')
	],
	'logstash-input-google_pubsub': [
		createSnippet('json_key_file', 'option', 'json_key_file => "${1:/path/to/file}"', '**[json_key_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-google_pubsub.html#plugins-inputs-google_pubsub-json_key_file) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nIf logstash is running within Google Compute Engine, the plugin will use GCE’s Application Default Credentials. Outside of GCE, you will need to specify a Service Account JSON key file.'),
		createSnippet('max_messages', 'option', 'max_messages => ${1:5}', '**[max_messages](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-google_pubsub.html#plugins-inputs-google_pubsub-max_messages) option**\n\n- This is a required setting.\n- Value type is number\n- Default value is 5\n\nThe maximum number of messages returned per request. The Pub/Sub system may return fewer than the number specified.', true),
		createSnippet('project_id', 'option', 'project_id => "${1:project_id}"', '**[project_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-google_pubsub.html#plugins-inputs-google_pubsub-project_id) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nGoogle Cloud Project ID (name, not number).', true),
		createSnippet('subscription', 'option', 'subscription => "${1:subscription}"', '**[subscription](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-google_pubsub.html#plugins-inputs-google_pubsub-subscription) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.', true),
		createSnippet('topic', 'option', 'topic => "${1:topic}"', '**[topic](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-google_pubsub.html#plugins-inputs-google_pubsub-topic) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nGoogle Cloud Pub/Sub Topic and Subscription. Note that the topic must be created manually with Cloud Logging pre-configured export to PubSub configured to use the defined topic. The subscription will be created automatically by the plugin.', true),
		createSnippet('include_metadata', 'option', 'include_metadata => ${1|false,true|}', '**[include_metadata](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-google_pubsub.html#plugins-inputs-google_pubsub-include_metadata) option**\n\n- Value type is boolean\n- Default value is false.\n\nIf set true, will include the full message data in the [@metadata][pubsub_message] field.'),
		createSnippet('create_subscription', 'option', 'create_subscription => ${1|false,true|}', '**[create_subscription](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-google_pubsub.html#plugins-inputs-google_pubsub-create_subscription) option**\n\n- Value type is boolean\n- Default value is false.\n\nAdded in 1.2.0.')
	],
	'logstash-filter-cipher': [
		createSnippet('algorithm', 'option', 'algorithm => "${1:algorithm}"', '**[algorithm](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-cipher.html#plugins-filters-cipher-algorithm) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe cipher algorithm to use for encryption and decryption operations.', true),
		createSnippet('base64', 'option', 'base64 => ${1|true,false|}', '**[base64](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-cipher.html#plugins-filters-cipher-base64) option**\n\n- Value type is boolean\n- Default value is true\n- Unless this option is disabled: When mode => encrypt, the source ciphertext will be base64-decoded before it is deciphered. When mode => decrypt, the result ciphertext will be base64-encoded before it is stored.\n- When mode => encrypt, the source ciphertext will be base64-decoded before it is deciphered.\n- When mode => decrypt, the result ciphertext will be base64-encoded before it is stored.\n\nUnless this option is disabled:'),
		createSnippet('cipher_padding', 'option', 'cipher_padding => "${1:cipher_padding}"', '**[cipher_padding](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-cipher.html#plugins-filters-cipher-cipher_padding) option**\n\n- Value type is string 0: means false 1: means true\n- 0: means false\n- 1: means true\n- There is no default value for this setting.\n\nValue type is string\n\n**_Example:_**  \n``` ruby\n    filter { cipher { cipher_padding => 0 }}\n```'),
		createSnippet('iv_random_length', 'option', 'iv_random_length => ${1:123}', '**[iv_random_length](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-cipher.html#plugins-filters-cipher-iv_random_length) option**\n\n- Value type is number\n- There is no default value for this setting.\n\nIn encryption operations, this plugin generates a random Initialization Vector (IV) per encryption operation. This is a standard best-practice to ensure that the resulting ciphertexts cannot be compared to infer equivalence of the source plaintext. This unique IV is then prepended to the resulting ciphertext before it is stored, ensuring it is available to any process that needs to decrypt it.\n\n**_Example:_**  \n``` ruby\n    filter { cipher { iv_random_length => 16 }}\n```'),
		createSnippet('key', 'option', 'key => "${1:key}"', '**[key](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-cipher.html#plugins-filters-cipher-key) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe key to use for encryption and decryption operations.'),
		createSnippet('key_pad', 'option', 'key_pad => "${1:\\u0000}"', '**[key_pad](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-cipher.html#plugins-filters-cipher-key_pad) option**\n\n- Value type is string\n- Default value is "\\\\u0000"\n\nThe character used to pad the key to the required key_size.'),
		createSnippet('key_size', 'option', 'key_size => ${1:16}', '**[key_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-cipher.html#plugins-filters-cipher-key_size) option**\n\n- Value type is number\n- Default value is 16\n\nThe cipher’s required key size, which depends on which algorithm you are using. If a key is specified with a shorter value, it will be padded with key_pad.\n\n**_Example:_**  \n``` ruby\n    filter { cipher { key_size => 16 }\n```'),
		createSnippet('max_cipher_reuse', 'option', 'max_cipher_reuse => ${1:1}', '**[max_cipher_reuse](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-cipher.html#plugins-filters-cipher-max_cipher_reuse) option**\n\n- Value type is number\n- Default value is 1\n\nIf this value is set, the internal Cipher instance will be re-used up to max_cipher_reuse times before it is re-created from scratch. This is an option for efficiency where lots of data is being encrypted and decrypted using this filter. This lets the filter avoid creating new Cipher instances over and over for each encrypt/decrypt operation.\n\n**_Example:_**  \n``` ruby\n    filter { cipher { max_cipher_reuse => 1000 }}\n```'),
		createSnippet('mode', 'option', 'mode => "${1:mode}"', '**[mode](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-cipher.html#plugins-filters-cipher-mode) option**\n\n- This is a required setting.\n- Value type is string encrypt: encrypts a plaintext value into IV + ciphertext decrypt: decrypts an IV + ciphertext value into plaintext\n- encrypt: encrypts a plaintext value into IV + ciphertext\n- decrypt: decrypts an IV + ciphertext value into plaintext\n- There is no default value for this setting.\n\nValue type is string', true),
		createSnippet('source', 'option', 'source => "${1:message}"', '**[source](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-cipher.html#plugins-filters-cipher-source) option**\n\n- Value type is string\n- Default value is "message"\n\nThe name of the source field.\n\n**_Example:_**  \n``` ruby\n    filter { cipher { source => "message" } }\n```'),
		createSnippet('target', 'option', 'target => "${1:message}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-cipher.html#plugins-filters-cipher-target) option**\n\n- Value type is string\n- Default value is "message"\n\nThe name of the target field to put the result:\n\n**_Example:_**  \n``` ruby\n    filter { cipher { target => "crypt" } }\n```')
	],
	'logstash-input-log4j': [
		createSnippet('host', 'option', 'host => "${1:0.0.0.0}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-log4j.html#plugins-inputs-log4j-host) option**\n\n- Value type is string\n- Default value is "0.0.0.0"\n\nWhen mode is server, the address to listen on. When mode is client, the address to connect to.'),
		createSnippet('mode', 'option', 'mode => "${1|server,client|}"$0', '**[mode](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-log4j.html#plugins-inputs-log4j-mode) option**\n\n- Value can be any of: server, client\n- Default value is "server"\n\nMode to operate in. server listens for client connections, client connects to a server.'),
		createSnippet('port', 'option', 'port => ${1:4560}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-log4j.html#plugins-inputs-log4j-port) option**\n\n- Value type is number\n- Default value is 4560\n\nWhen mode is server, the port to listen on. When mode is client, the port to connect to.'),
		createSnippet('proxy_protocol', 'option', 'proxy_protocol => ${1|false,true|}', '**[proxy_protocol](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-log4j.html#plugins-inputs-log4j-proxy_protocol) option**\n\n- Value type is boolean\n- Default value is false\n\nProxy protocol support, only v1 is supported at this time http://www.haproxy.org/download/1.5/doc/proxy-protocol.txt')
	],
	'logstash-output': [
		createSnippet('if', 'keyword', 'if ${1|[field],"value",123,true|} ${2|==,!=,<,>,<=,>=,=~,!~,in,not in|} ${3|[field],"value",123,true,["value1"\\, "value2"],/regex/|} {\n\t$0\n}', '**[if](https://www.elastic.co/guide/en/logstash/7.17/event-dependent-configuration.html#conditionals) keyword**\n\nConditionnal block'),
		createSnippet('pipeline', 'plugin', 'pipeline {\n\tsend_to => ["${1:target_pipeline_address}"]\n}', '**[pipeline](https://www.elastic.co/guide/en/logstash/7.17/pipeline-to-pipeline.html) output**\n\nSends events to one or several other pipelines.'),
		createSnippet('boundary', 'plugin', 'boundary {\n\tapi_key => "${1:api_key}"\n\torg_id => "${2:org_id}"\n}', '**[boundary](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-boundary.html) output**\n\nSends annotations to Boundary based on Logstash events\n\n**_Example:_**  \n``` ruby\noutput {\n  boundary {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('circonus', 'plugin', 'circonus {\n\tannotation => {\n\t\t"${1:key}" => "${2:value}"\n\t}\n\tapi_token => "${3:api_token}"\n\tapp_name => "${4:app_name}"\n}', '**[circonus](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-circonus.html) output**\n\nSends annotations to Circonus based on Logstash events\n\n**_Example:_**  \n``` ruby\noutput {\n  circonus {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('cloudwatch', 'plugin', 'cloudwatch {\n\t$0\n}', '**[cloudwatch](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-cloudwatch.html) output**\n\nAggregates and sends metric data to AWS CloudWatch\n\n**_Example:_**  \n``` ruby\noutput {\n  cloudwatch {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('csv', 'plugin', 'csv {\n\tfields => ["${1:field}"]\n\tpath => "${2:path}"\n}', '**[csv](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-csv.html) output**\n\nWrites events to disk in a delimited format\n\n**_Example:_**  \n``` ruby\noutput {\n  csv {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('datadog', 'plugin', 'datadog {\n\tapi_key => "${1:api_key}"\n}', '**[datadog](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-datadog.html) output**\n\nSends events to DataDogHQ based on Logstash events\n\n**_Example:_**  \n``` ruby\noutput {\n  datadog {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('datadog_metrics', 'plugin', 'datadog_metrics {\n\tapi_key => "${1:api_key}"\n}', '**[datadog_metrics](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-datadog_metrics.html) output**\n\nSends metrics to DataDogHQ based on Logstash events\n\n**_Example:_**  \n``` ruby\noutput {\n  datadog_metrics {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('dynatrace', 'plugin', 'dynatrace {\n\t$0\n}', '**[dynatrace](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-dynatrace.html) output**\n\nSends events to Dynatrace based on Logstash events'),
		createSnippet('elastic_app_search', 'plugin', 'elastic_app_search {\n\tapi_key => "${1:api_key}"\n\tengine => "${2:engine}"\n}', '**[elastic_app_search](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elastic_app_search.html) output**\n\nSends events to the Elastic App Search solution\n\n**_Example:_**  \n``` ruby\noutput {\n  elastic_app_search {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('elastic_workplace_search', 'plugin', 'elastic_workplace_search {\n\taccess_token => "${1:access_token}"\n\tsource => "${2:source}"\n\turl => "${3:url}"\n}', '**[elastic_workplace_search](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elastic_workplace_search.html) output**\n\nSends events to the Elastic Workplace Search solution\n\n**_Example:_**  \n``` ruby\ninput {\n  stdin {\n    codec => json\n  }\n}\n\nfilter {\n  if ![source_id] {\n    mutate {\n      add_field => {"source_id" => "default"}\n    }\n  }\n}\n\noutput {\n  elastic_workplace_search {\n    source => "%{[source_id]}"\n  }\n}\n```'),
		createSnippet('elasticsearch', 'plugin', 'elasticsearch {\n\t$0\n}', '**[elasticsearch](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html) output**\n\nStores logs in Elasticsearch\n\n**_Example:_**  \n``` ruby\noutput {\n    elasticsearch {\n        hosts => "hostname"\n        data_stream => "true"\n    }\n}\n```'),
		createSnippet('email', 'plugin', 'email {\n\tto => "${1:to}"\n}', '**[email](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-email.html) output**\n\nSends email to a specified address when output is received\n\n**_Example:_**  \n``` ruby\noutput {\n  if "shouldmail" in [tags] {\n    email {\n      to => \'technical@example.com\'\n      from => \'monitor@example.com\'\n      subject => \'Alert - %{title}\'\n      body => "Tags: %{tags}\\\\n\\\\Content:\\\\n%{message}"\n      template_file => "/tmp/email_template.mustache"\n      domain => \'mail.example.com\'\n      port => 25\n    }\n  }\n}\n```'),
		createSnippet('exec', 'plugin', 'exec {\n\tcommand => "${1:command}"\n}', '**[exec](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-exec.html) output**\n\nRuns a command for a matching event\n\n**_Example:_**  \n``` ruby\n    output {\n      if [type] == "abuse" {\n        exec {\n          command => "iptables -A INPUT -s %{clientip} -j DROP"\n        }\n      }\n    }\n```'),
		createSnippet('file', 'plugin', 'file {\n\tpath => "${1:path}"\n}', '**[file](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-file.html) output**\n\nWrites events to files on disk\n\n**_Example:_**  \n``` ruby\noutput {\n file {\n   path => ...\n   codec => line { format => "custom format: %{message}"}\n }\n}\n```'),
		createSnippet('ganglia', 'plugin', 'ganglia {\n\tmetric => "${1:metric}"\n\tvalue => "${2:value}"\n}', '**[ganglia](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-ganglia.html) output**\n\nWrites metrics to Ganglia’s gmond\n\n**_Example:_**  \n``` ruby\noutput {\n  ganglia {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('gelf', 'plugin', 'gelf {\n\thost => "${1:host}"\n}', '**[gelf](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-gelf.html) output**\n\nGenerates GELF formatted output for Graylog2\n\n**_Example:_**  \n``` ruby\noutput {\n  gelf {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('google_bigquery', 'plugin', 'google_bigquery {\n\tdataset => "${1:dataset}"\n\terror_directory => "${2:/tmp/bigquery}"\n\tproject_id => "${3:project_id}"\n}', '**[google_bigquery](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_bigquery.html) output**\n\nWrites events to Google BigQuery\n\n**_Example:_**  \n``` ruby\noutput {\n   google_bigquery {\n     project_id => "folkloric-guru-278"                        (required)\n     dataset => "logs"                                         (required)\n     csv_schema => "path:STRING,status:INTEGER,score:FLOAT"    (required) \n     json_key_file => "/path/to/key.json"                      (optional) \n     error_directory => "/tmp/bigquery-errors"                 (required)\n     date_pattern => "%Y-%m-%dT%H:00"                          (optional)\n     flush_interval_secs => 30                                 (optional)\n   }\n}\n```'),
		createSnippet('google_cloud_storage', 'plugin', 'google_cloud_storage {\n\tbucket => "${1:bucket}"\n}', '**[google_cloud_storage](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_cloud_storage.html) output**\n\nUploads log events to Google Cloud Storage\n\n**_Example:_**  \n``` ruby\noutput {\n   google_cloud_storage {\n     bucket => "my_bucket"                                     (required)\n     json_key_file => "/path/to/privatekey.json"               (optional)\n     temp_directory => "/tmp/logstash-gcs"                     (optional)\n     log_file_prefix => "logstash_gcs"                         (optional)\n     max_file_size_kbytes => 1024                              (optional)\n     output_format => "plain"                                  (optional)\n     date_pattern => "%Y-%m-%dT%H:00"                          (optional)\n     flush_interval_secs => 2                                  (optional)\n     gzip => false                                             (optional)\n     gzip_content_encoding => false                            (optional)\n     uploader_interval_secs => 60                              (optional)\n     include_uuid => true                                      (optional)\n     include_hostname => true                                  (optional)\n   }\n}\n```'),
		createSnippet('google_pubsub', 'plugin', 'google_pubsub {\n\tproject_id => "${1:project_id}"\n\ttopic => "${2:topic}"\n}', '**[google_pubsub](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-google_pubsub.html) output**\n\nUploads log events to Google Cloud Pubsub\n\n**_Example:_**  \n``` ruby\noutput {\n  google_pubsub {\n    # Required attributes\n    project_id => "my_project"\n    topic => "my_topic"\n\n    # Optional if you\'re using app default credentials\n    json_key_file => "service_account_key.json"\n  }\n}\n```'),
		createSnippet('graphite', 'plugin', 'graphite {\n\t$0\n}', '**[graphite](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphite.html) output**\n\nWrites metrics to Graphite\n\n**_Example:_**  \n``` ruby\noutput {\n  graphite {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('graphtastic', 'plugin', 'graphtastic {\n\t$0\n}', '**[graphtastic](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphtastic.html) output**\n\nSends metric data on Windows\n\n**_Example:_**  \n``` ruby\noutput {\n  graphtastic {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('http', 'plugin', 'http {\n\thttp_method => "${1|put,post,patch,delete,get,head|}"$2\n\turl => "${3:url}"\n}', '**[http](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-http.html) output**\n\nSends events to a generic HTTP or HTTPS endpoint\n\n**_Example:_**  \n``` ruby\noutput {\n  http {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('influxdb', 'plugin', 'influxdb {\n\tdata_points => {\n\t\t"${1:key}" => "${2:value}"\n\t}\n\thost => "${3:host}"\n}', '**[influxdb](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-influxdb.html) output**\n\nWrites metrics to InfluxDB\n\n**_Example:_**  \n``` ruby\noutput {\n  influxdb {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('irc', 'plugin', 'irc {\n\tchannels => ["${1:channel}"]\n\thost => "${2:host}"\n}', '**[irc](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-irc.html) output**\n\nWrites events to IRC\n\n**_Example:_**  \n``` ruby\noutput {\n  irc {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('java_stdout', 'plugin', 'java_stdout {\n\t$0\n}', '**[java_stdout](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-java_stdout.html) output**\n\nPrints events to the STDOUT of the shell\n\n**_Example:_**  \n``` ruby\n    output {\n      java_stdout {}\n    }\n```'),
		createSnippet('juggernaut', 'plugin', 'juggernaut {\n\tchannels => ["${1:channel}"]\n}', '**[juggernaut](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-juggernaut.html) output**\n\nPushes messages to the Juggernaut websockets server\n\n**_Example:_**  \n``` ruby\noutput {\n  juggernaut {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('kafka', 'plugin', 'kafka {\n\ttopic_id => "${1:topic_id}"\n}', '**[kafka](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-kafka.html) output**\n\nWrites events to a Kafka topic\n\n**_Example:_**  \n``` ruby\n    output {\n      kafka {\n        codec => json\n        topic_id => "mytopic"\n      }\n    }\n```'),
		createSnippet('librato', 'plugin', 'librato {\n\taccount_id => "${1:account_id}"\n\tapi_token => "${2:api_token}"\n}', '**[librato](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-librato.html) output**\n\nSends metrics, annotations, and alerts to Librato based on Logstash events\n\n**_Example:_**  \n``` ruby\noutput {\n  librato {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('loggly', 'plugin', 'loggly {\n\tkey => "${1:key}"\n\tmax_event_size => "${2:1 Mib}"\n\tmax_payload_size => "${3:5 Mib}"\n}', '**[loggly](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-loggly.html) output**\n\nShips logs to Loggly\n\n**_Example:_**  \n``` ruby\noutput {\n  loggly {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('lumberjack', 'plugin', 'lumberjack {\n\thosts => ["${1:host}"]\n\tport => ${2:123}\n\tssl_certificate => "${3:/path/to/file}"\n}', '**[lumberjack](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-lumberjack.html) output**\n\nSends events using the lumberjack protocol\n\n**_Example:_**  \n``` ruby\noutput {\n  lumberjack {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('metriccatcher', 'plugin', 'metriccatcher {\n\t$0\n}', '**[metriccatcher](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-metriccatcher.html) output**\n\nWrites metrics to MetricCatcher\n\n**_Example:_**  \n``` ruby\n    metriccatcher {\n        host => "localhost"\n        port => "1420"\n        type => "apache-access"\n        fields => [ "response" ]\n        meter => {\n            "%{host}.apache.response.%{response}" => "1"\n            }\n    }\n```'),
		createSnippet('mongodb', 'plugin', 'mongodb {\n\tcollection => "${1:collection}"\n\tdatabase => "${2:database}"\n\turi => "${3:uri}"\n}', '**[mongodb](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-mongodb.html) output**\n\nWrites events to MongoDB\n\n**_Example:_**  \n``` ruby\noutput {\n  mongodb {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('nagios', 'plugin', 'nagios {\n\t$0\n}', '**[nagios](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-nagios.html) output**\n\nSends passive check results to Nagios\n\n**_Example:_**  \n``` ruby\n    output{\n      if [message] =~ /(error|ERROR|CRITICAL)/ {\n        nagios {\n          # your config here\n        }\n      }\n    }\n```'),
		createSnippet('nagios_nsca', 'plugin', 'nagios_nsca {\n\tnagios_status => "${1:nagios_status}"\n}', '**[nagios_nsca](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-nagios_nsca.html) output**\n\nSends passive check results to Nagios using the NSCA protocol\n\n**_Example:_**  \n``` ruby\n    output {\n      nagios_nsca {\n        # specify the hostname or ip of your nagios server\n        host => "nagios.example.com"\n```'),
		createSnippet('opentsdb', 'plugin', 'opentsdb {\n\tmetrics => ["${1:metric}"]\n}', '**[opentsdb](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-opentsdb.html) output**\n\nWrites metrics to OpenTSDB\n\n**_Example:_**  \n``` ruby\noutput {\n  opentsdb {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('pagerduty', 'plugin', 'pagerduty {\n\tservice_key => "${1:service_key}"\n}', '**[pagerduty](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-pagerduty.html) output**\n\nSends notifications based on preconfigured services and escalation policies\n\n**_Example:_**  \n``` ruby\noutput {\n  pagerduty {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('pipe', 'plugin', 'pipe {\n\tcommand => "${1:command}"\n}', '**[pipe](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-pipe.html) output**\n\nPipes events to another program’s standard input\n\n**_Example:_**  \n``` ruby\noutput {\n  pipe {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('rabbitmq', 'plugin', 'rabbitmq {\n\texchange => "${1:exchange}"\n\texchange_type => "${2|fanout,direct,topic,x-consistent-hash,x-modulus-hash|}"$3\n\thost => "${4:host}"\n}', '**[rabbitmq](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-rabbitmq.html) output**\n\nPushes events to a RabbitMQ exchange\n\n**_Example:_**  \n``` ruby\noutput {\n  rabbitmq {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('redis', 'plugin', 'redis {\n\t$0\n}', '**[redis](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redis.html) output**\n\nSends events to a Redis queue using the RPUSH command\n\n**_Example:_**  \n``` ruby\noutput {\n  redis {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('redmine', 'plugin', 'redmine {\n\tpriority_id => ${1:123}\n\tproject_id => ${2:123}\n\tstatus_id => ${3:123}\n\ttoken => "${4:token}"\n\ttracker_id => ${5:123}\n\turl => "${6:url}"\n}', '**[redmine](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-redmine.html) output**\n\nCreates tickets using the Redmine API\n\n**_Example:_**  \n``` ruby\n output {\n   redmine {\n     url => "http://redmineserver.tld"\n     token => \'token\'\n     project_id => 200\n     tracker_id => 1\n     status_id => 3\n     priority_id => 2\n     subject => "Error ... detected"\n   }\n }\n```'),
		createSnippet('riak', 'plugin', 'riak {\n\t$0\n}', '**[riak](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-riak.html) output**\n\nWrites events to the Riak distributed key/value store\n\n**_Example:_**  \n``` ruby\noutput {\n  riak {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('riemann', 'plugin', 'riemann {\n\t$0\n}', '**[riemann](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-riemann.html) output**\n\nSends metrics to Riemann\n\n**_Example:_**  \n``` ruby\n    riemann {\n        riemann_event => {\n            "metric"  => "%{metric}"\n            "service" => "%{service}"\n        }\n    }\n```'),
		createSnippet('s3', 'plugin', 's3 {\n\tbucket => "${1:bucket}"\n}', '**[s3](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-s3.html) output**\n\nSends Logstash events to the Amazon Simple Storage Service\n\n**_Example:_**  \n``` ruby\n    output {\n      s3 {\n        access_key_id => "1234",\n        secret_access_key => "secret",\n        region => "eu-west-1",\n        bucket => "logstash-test",\n        additional_settings => {\n          "force_path_style" => true,\n          "follow_redirects" => false\n        }\n      }\n    }\n```'),
		createSnippet('sink', 'plugin', 'sink {\n\t$0\n}', '**[sink](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sink.html) output**\n\nDiscards any events received\n\n**_Example:_**  \n``` ruby\noutput {\n  sink {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('sns', 'plugin', 'sns {\n\t$0\n}', '**[sns](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sns.html) output**\n\nSends events to Amazon’s Simple Notification Service\n\n**_Example:_**  \n``` ruby\noutput {\n  sns {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('solr_http', 'plugin', 'solr_http {\n\t$0\n}', '**[solr_http](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-solr_http.html) output**\n\nStores and indexes logs in Solr\n\n**_Example:_**  \n``` ruby\noutput {\n  solr_http {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('sqs', 'plugin', 'sqs {\n\tqueue => "${1:queue}"\n}', '**[sqs](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sqs.html) output**\n\nPushes events to an Amazon Web Services Simple Queue Service queue\n\n**_Example:_**  \n``` ruby\noutput {\n  sqs {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('statsd', 'plugin', 'statsd {\n\t$0\n}', '**[statsd](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-statsd.html) output**\n\nSends metrics using the statsd network daemon\n\n**_Example:_**  \n``` ruby\noutput {\n  statsd {\n    host => "statsd.example.org"\n    count => {\n      "http.bytes" => "%{bytes}"\n    }\n  }\n}\n```'),
		createSnippet('stdout', 'plugin', 'stdout {\n\t$0\n}', '**[stdout](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-stdout.html) output**\n\nPrints events to the standard output\n\n**_Example:_**  \n``` ruby\n    output {\n      stdout {}\n    }\n```'),
		createSnippet('stomp', 'plugin', 'stomp {\n\tdestination => "${1:destination}"\n\thost => "${2:host}"\n}', '**[stomp](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-stomp.html) output**\n\nWrites events using the STOMP protocol\n\n**_Example:_**  \n``` ruby\noutput {\n  stomp {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('syslog', 'plugin', 'syslog {\n\thost => "${1:host}"\n\tport => ${2:123}\n}', '**[syslog](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-syslog.html) output**\n\nSends events to a syslog server\n\n**_Example:_**  \n``` ruby\noutput {\n  syslog {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('tcp', 'plugin', 'tcp {\n\thost => "${1:host}"\n\tport => ${2:123}\n}', '**[tcp](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-tcp.html) output**\n\nWrites events over a TCP socket\n\n**_Example:_**  \n``` ruby\noutput {\n  tcp {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('timber', 'plugin', 'timber {\n\t$0\n}', '**[timber](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-timber.html) output**\n\nSends events to the Timber.io logging service\n\n**_Example:_**  \n``` ruby\noutput {\n  timber {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('udp', 'plugin', 'udp {\n\thost => "${1:host}"\n\tport => "${2:port}"\n}', '**[udp](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-udp.html) output**\n\nSends events over UDP\n\n**_Example:_**  \n``` ruby\noutput {\n  udp {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('webhdfs', 'plugin', 'webhdfs {\n\thost => "${1:host}"\n\tpath => "${2:path}"\n\tuser => "${3:user}"\n}', '**[webhdfs](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-webhdfs.html) output**\n\nSends Logstash events to HDFS using the webhdfs REST API\n\n**_Example:_**  \n``` ruby\ninput {\n  ...\n}\nfilter {\n  ...\n}\noutput {\n  webhdfs {\n    host => "127.0.0.1"                 # (required)\n    port => 50070                       # (optional, default: 50070)\n    path => "/user/logstash/dt=%{+YYYY-MM-dd}/logstash-%{+HH}.log"  # (required)\n    user => "hue"                       # (required)\n  }\n}\n```'),
		createSnippet('websocket', 'plugin', 'websocket {\n\t$0\n}', '**[websocket](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-websocket.html) output**\n\nPublishes messages to a websocket\n\n**_Example:_**  \n``` ruby\noutput {\n  websocket {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('xmpp', 'plugin', 'xmpp {\n\tmessage => "${1:message}"\n\tpassword => "${2:password}"\n\tuser => "${3:user}"\n}', '**[xmpp](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-xmpp.html) output**\n\nPosts events over XMPP\n\n**_Example:_**  \n``` ruby\noutput {\n  xmpp {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('zabbix', 'plugin', 'zabbix {\n\tzabbix_host => "${1:zabbix_host}"\n}', '**[zabbix](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-zabbix.html) output**\n\nSends events to a Zabbix server\n\n**_Example:_**  \n``` ruby\noutput {\n  zabbix {\n    id => "my_plugin_id"\n  }\n}\n```')
	],
	'logstash-input': [
		createSnippet('pipeline', 'plugin', 'pipeline {\n\taddress => "${1:pipeline_address}"\n}', '**[pipeline](https://www.elastic.co/guide/en/logstash/7.17/pipeline-to-pipeline.html) input**\n\nReceives events from another pipeline.'),
		createSnippet('azure_event_hubs', 'plugin', 'azure_event_hubs {\n\t$0\n}', '**[azure_event_hubs](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-azure_event_hubs.html) input**\n\nReceives events from Azure Event Hubs\n\n**_Example:_**  \n``` ruby\ninput {\n   azure_event_hubs {\n      event_hub_connections => ["Endpoint=sb://example1...EntityPath=insights-logs-errors", "Endpoint=sb://example2...EntityPath=insights-metrics-pt1m"]\n      threads => 8\n      decorate_events => true\n      consumer_group => "logstash"\n      storage_connection => "DefaultEndpointsProtocol=https;AccountName=example...."\n   }\n}\n```'),
		createSnippet('beats', 'plugin', 'beats {\n\tport => ${1:123}\n}', '**[beats](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-beats.html) input**\n\nReceives events from the Elastic Beats framework\n\n**_Example:_**  \n``` ruby\ninput {\n  beats {\n    port => 5044\n  }\n}\n\noutput {\n  elasticsearch {\n    hosts => ["http://localhost:9200"]\n    index => "%{[@metadata][beat]}-%{[@metadata][version]}" \n  }\n}\n```'),
		createSnippet('cloudwatch', 'plugin', 'cloudwatch {\n\t$0\n}', '**[cloudwatch](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-cloudwatch.html) input**\n\nPulls events from the Amazon Web Services CloudWatch API\n\n**_Example:_**  \n``` ruby\n    input {\n      cloudwatch {\n        namespace => "AWS/EC2"\n        metrics => [ "CPUUtilization" ]\n        filters => { "tag:Group" => "API-Production" }\n        region => "us-east-1"\n      }\n    }\n```'),
		createSnippet('couchdb_changes', 'plugin', 'couchdb_changes {\n\tdb => "${1:db}"\n}', '**[couchdb_changes](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-couchdb_changes.html) input**\n\nStreams events from CouchDB’s _changes URI\n\n**_Example:_**  \n``` ruby\ninput {\n  couchdb_changes {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('dead_letter_queue', 'plugin', 'dead_letter_queue {\n\tpath => "${1:/path/to/file}"\n}', '**[dead_letter_queue](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-dead_letter_queue.html) input**\n\nread events from Logstash’s dead letter queue\n\n**_Example:_**  \n``` ruby\ninput {\n  dead_letter_queue {\n    path => "/var/logstash/data/dead_letter_queue"\n    start_timestamp => "2017-04-04T23:40:37"\n  }\n}\n```'),
		createSnippet('elastic_agent', 'plugin', 'elastic_agent {\n\tport => ${1:123}\n}', '**[elastic_agent](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elastic_agent.html) input**\n\nReceives events from the Elastic Agent framework\n\n**_Example:_**  \n``` ruby\ninput {\n  elastic_agent {\n    port => 5044\n  }\n}\n\noutput {\n  elasticsearch {\n    hosts => ["http://localhost:9200"]\n    data_stream => "true"\n  }\n}\n```'),
		createSnippet('elasticsearch', 'plugin', 'elasticsearch {\n\t$0\n}', '**[elasticsearch](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-elasticsearch.html) input**\n\nReads query results from an Elasticsearch cluster\n\n**_Example:_**  \n``` ruby\n    input {\n      # Read all documents from Elasticsearch matching the given query\n      elasticsearch {\n        hosts => "localhost"\n        query => \'{ "query": { "match": { "statuscode": 200 } }, "sort": [ "_doc" ] }\'\n      }\n    }\n```'),
		createSnippet('exec', 'plugin', 'exec {\n\tcommand => "${1:command}"\n}', '**[exec](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-exec.html) input**\n\nCaptures the output of a shell command as an event\n\n**_Example:_**  \n``` ruby\ninput {\n  exec {\n    command => "echo \'hi!\'"\n    interval => 30\n  }\n}\n```'),
		createSnippet('file', 'plugin', 'file {\n\tpath => ["${1:path}"]\n}', '**[file](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-file.html) input**\n\nStreams events from files\n\n**_Example:_**  \n``` ruby\ninput {\n  file {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('ganglia', 'plugin', 'ganglia {\n\t$0\n}', '**[ganglia](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-ganglia.html) input**\n\nReads Ganglia packets over UDP\n\n**_Example:_**  \n``` ruby\ninput {\n  ganglia {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('gelf', 'plugin', 'gelf {\n\t$0\n}', '**[gelf](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-gelf.html) input**\n\nReads GELF-format messages from Graylog2 as events\n\n**_Example:_**  \n``` ruby\ninput {\n  gelf {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('generator', 'plugin', 'generator {\n\t$0\n}', '**[generator](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-generator.html) input**\n\nGenerates random log events for test purposes\n\n**_Example:_**  \n``` ruby\n    input {\n      generator {\n        lines => [\n          "line 1",\n          "line 2",\n          "line 3"\n        ]\n        # Emit all lines 3 times.\n        count => 3\n      }\n    }\n```'),
		createSnippet('github', 'plugin', 'github {\n\tport => ${1:123}\n}', '**[github](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-github.html) input**\n\nReads events from a GitHub webhook\n\n**_Example:_**  \n``` ruby\ninput {\n  github {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('google_cloud_storage', 'plugin', 'google_cloud_storage {\n\tbucket_id => "${1:bucket_id}"\n}', '**[google_cloud_storage](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-google_cloud_storage.html) input**\n\nExtract events from files in a Google Cloud Storage bucket\n\n**_Example:_**  \n``` ruby\ninput {\n  google_cloud_storage {\n    interval => 60\n    bucket_id => "my-logs-bucket"\n    json_key_file => "/home/user/key.json"\n    file_matches => ".*json"\n    codec => "json_lines"\n  }\n}\noutput { stdout { codec => rubydebug } }\n```'),
		createSnippet('google_pubsub', 'plugin', 'google_pubsub {\n\tmax_messages => ${1:5}\n\tproject_id => "${2:project_id}"\n\tsubscription => "${3:subscription}"\n\ttopic => "${4:topic}"\n}', '**[google_pubsub](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-google_pubsub.html) input**\n\nConsume events from a Google Cloud PubSub service\n\n**_Example:_**  \n``` ruby\ninput {\n    google_pubsub {\n        # Your GCP project id (name)\n        project_id => "my-project-1234"\n\n        # The topic name below is currently hard-coded in the plugin. You\n        # must first create this topic by hand and ensure you are exporting\n        # logging to this pubsub topic.\n        topic => "logstash-input-dev"\n\n        # The subscription name is customizeable. The plugin will attempt to\n        # create the subscription (but use the hard-coded topic name above).\n        subscription => "logstash-sub"\n\n        # If you are running logstash within GCE, it will use\n        # Application Default Credentials and use GCE\'s metadata\n        # service to fetch tokens.  However, if you are running logstash\n        # outside of GCE, you will need to specify the service account\'s\n        # JSON key file below.\n        #json_key_file => "/home/erjohnso/pkey.json"\n\n        # Should the plugin attempt to create the subscription on startup?\n        # This is not recommended for security reasons but may be useful in\n        # some cases.\n        #create_subscription => false\n    }\n}\noutput { stdout { codec => rubydebug } }\n```'),
		createSnippet('graphite', 'plugin', 'graphite {\n\tport => ${1:123}\n}', '**[graphite](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-graphite.html) input**\n\nReads metrics from the graphite tool\n\n**_Example:_**  \n``` ruby\ninput {\n  graphite {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('heartbeat', 'plugin', 'heartbeat {\n\t$0\n}', '**[heartbeat](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-heartbeat.html) input**\n\nGenerates heartbeat events for testing\n\n**_Example:_**  \n``` ruby\ninput {\n  heartbeat {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('http', 'plugin', 'http {\n\t$0\n}', '**[http](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http.html) input**\n\nReceives events over HTTP or HTTPS\n\n**_Example:_**  \n``` ruby\ninput {\n  http {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('http_poller', 'plugin', 'http_poller {\n\tschedule => {\n\t\t"${1:key}" => "${2:value}"\n\t}\n\turls => {\n\t\t"${3:key}" => "${4:value}"\n\t}\n}', '**[http_poller](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-http_poller.html) input**\n\nDecodes the output of an HTTP API into events\n\n**_Example:_**  \n``` ruby\ninput {\n  http_poller {\n    urls => {\n      test1 => "http://localhost:9200"\n      test2 => {\n        # Supports all options supported by ruby\'s Manticore HTTP client\n        method => get\n        user => "AzureDiamond"\n        password => "hunter2"\n        url => "http://localhost:9200/_cluster/health"\n        headers => {\n          Accept => "application/json"\n        }\n     }\n    }\n    request_timeout => 60\n    # Supports "cron", "every", "at" and "in" schedules by rufus scheduler\n    schedule => { cron => "* * * * * UTC"}\n    codec => "json"\n    # A hash of request metadata info (timing, response headers, etc.) will be sent here\n    metadata_target => "http_poller_metadata"\n  }\n}\n\noutput {\n  stdout {\n    codec => rubydebug\n  }\n}\n```'),
		createSnippet('imap', 'plugin', 'imap {\n\thost => "${1:host}"\n\tpassword => "${2:password}"\n\tuser => "${3:user}"\n}', '**[imap](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-imap.html) input**\n\nReads mail from an IMAP server\n\n**_Example:_**  \n``` ruby\ninput {\n  imap {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('irc', 'plugin', 'irc {\n\tchannels => ["${1:channel}"]\n\thost => "${2:host}"\n}', '**[irc](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-irc.html) input**\n\nReads events from an IRC server\n\n**_Example:_**  \n``` ruby\ninput {\n  irc {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('java_generator', 'plugin', 'java_generator {\n\t$0\n}', '**[java_generator](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-java_generator.html) input**\n\nGenerates synthetic log events\n\n**_Example:_**  \n``` ruby\n    input {\n      java_generator {\n        lines => [\n          "line 1",\n          "line 2",\n          "line 3"\n        ]\n        # Emit all lines 2 times.\n        count => 2\n      }\n    }\n```'),
		createSnippet('java_stdin', 'plugin', 'java_stdin {\n\t$0\n}', '**[java_stdin](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-java_stdin.html) input**\n\nReads events from standard input\n\n**_Example:_**  \n``` ruby\ninput {\n  java_stdin {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('jdbc', 'plugin', 'jdbc {\n\tjdbc_connection_string => "${1:jdbc_connection_string}"\n\tjdbc_driver_class => "${2:jdbc_driver_class}"\n\tjdbc_user => "${3:jdbc_user}"\n}', '**[jdbc](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jdbc.html) input**\n\nCreates events from JDBC data\n\n**_Example:_**  \n``` ruby\ninput {\n  jdbc {\n    jdbc_driver_library => "mysql-connector-java-5.1.36-bin.jar"\n    jdbc_driver_class => "com.mysql.jdbc.Driver"\n    jdbc_connection_string => "jdbc:mysql://localhost:3306/mydb"\n    jdbc_user => "mysql"\n    parameters => { "favorite_artist" => "Beethoven" }\n    schedule => "* * * * *"\n    statement => "SELECT * from songs where artist = :favorite_artist"\n  }\n}\n```'),
		createSnippet('jms', 'plugin', 'jms {\n\tdestination => "${1:destination}"\n}', '**[jms](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jms.html) input**\n\nReads events from a Jms Broker\n\n**_Example:_**  \n``` ruby\n input\n {\n    jms {\n        broker_url => \'failover:(tcp://host1:61616,tcp://host2:61616)?initialReconnectDelay=100\' \n        destination => \'myqueue\' \n        factory => \'org.apache.activemq.ActiveMQConnectionFactory\' \n        pub_sub => false \n        use_jms_timestamp => false \n        # JMS provider credentials if needed \n        username => \'username\'\n        password => \'secret\'\n        # JMS provider keystore and truststore details \n        keystore => \'/Users/logstash-user/security/keystore.jks\'\n        keystore_password => \'another_secret\'\n        truststore => \'/Users/logstash-user/security/truststore.jks\'\n        truststore_password => \'yet_another_secret\'\n        # Parts of the JMS message to be included \n        include_headers => false\n        include_properties => false\n        include_body => true\n        # Message selector\n        selector => "string_property = \'this\' OR int_property < 3" \n        # Connection factory specific settings\n        factory_settings => { \n                              exclusive_consumer => true\n        }\n        # Jar Files to include\n        require_jars => [\'/usr/share/jms/activemq-all-5.15.9.jar\'] \n    }\n  }\n```'),
		createSnippet('jmx', 'plugin', 'jmx {\n\tpath => "${1:path}"\n}', '**[jmx](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-jmx.html) input**\n\nRetrieves metrics from remote Java applications over JMX\n\n**_Example:_**  \n``` ruby\n    jmx {\n      //Required\n      path => "/apps/logstash_conf/jmxconf"\n      //Optional, default 60s\n      polling_frequency => 15\n      type => "jmx"\n      //Optional, default 4\n      nb_thread => 4\n    }\n```'),
		createSnippet('kafka', 'plugin', 'kafka {\n\t$0\n}', '**[kafka](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kafka.html) input**\n\nReads events from a Kafka topic\n\n**_Example:_**  \n``` ruby\n    input {\n      kafka {\n        sasl_jaas_config => "org.apache.kafka.common.security.plain.PlainLoginModule required username=\'auser\'  password=\'apassword\';"\n      }\n    }\n```'),
		createSnippet('kinesis', 'plugin', 'kinesis {\n\tkinesis_stream_name => "${1:kinesis_stream_name}"\n}', '**[kinesis](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-kinesis.html) input**\n\nReceives events through an AWS Kinesis stream\n\n**_Example:_**  \n``` ruby\ninput {\n  kinesis {\n    kinesis_stream_name => "my-logging-stream"\n    codec => json { }\n  }\n}\n```'),
		createSnippet('log4j', 'plugin', 'log4j {\n\t$0\n}', '**[log4j](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-log4j.html) input**\n\nReads events over a TCP socket from a Log4j SocketAppender object\n\n**_Example:_**  \n``` ruby\ninput {\n  log4j {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('lumberjack', 'plugin', 'lumberjack {\n\tport => ${1:123}\n\tssl_certificate => "${2:/path/to/file}"\n\tssl_key => "${3:/path/to/file}"\n}', '**[lumberjack](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-lumberjack.html) input**\n\nReceives events using the Lumberjack protocl\n\n**_Example:_**  \n``` ruby\ninput {\n  lumberjack {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('meetup', 'plugin', 'meetup {\n\tinterval => ${1:123}\n\tmeetupkey => "${2:meetupkey}"\n}', '**[meetup](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-meetup.html) input**\n\nCaptures the output of command line tools as an event\n\n**_Example:_**  \n``` ruby\ninput {\n  meetup {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('pipe', 'plugin', 'pipe {\n\tcommand => "${1:command}"\n}', '**[pipe](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-pipe.html) input**\n\nStreams events from a long-running command pipe\n\n**_Example:_**  \n``` ruby\ninput {\n  pipe {\n    command => "echo ¡Hola!"\n  }\n}\n```'),
		createSnippet('puppet_facter', 'plugin', 'puppet_facter {\n\t$0\n}', '**[puppet_facter](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-puppet_facter.html) input**\n\nReceives facts from a Puppet server\n\n**_Example:_**  \n``` ruby\ninput {\n  puppet_facter {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('rabbitmq', 'plugin', 'rabbitmq {\n\thost => "${1:host}"\n\tsubscription_retry_interval_seconds => ${2:5}\n}', '**[rabbitmq](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rabbitmq.html) input**\n\nPulls events from a RabbitMQ exchange\n\n**_Example:_**  \n``` ruby\ninput {\n  rabbitmq {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('redis', 'plugin', 'redis {\n\tdata_type => "${1|list,channel,pattern_channel|}"$2\n\tkey => "${3:key}"\n}', '**[redis](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-redis.html) input**\n\nReads events from a Redis instance\n\n**_Example:_**  \n``` ruby\ninput {\n  redis {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('relp', 'plugin', 'relp {\n\tport => ${1:123}\n}', '**[relp](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-relp.html) input**\n\nReceives RELP events over a TCP socket\n\n**_Example:_**  \n``` ruby\ninput {\n  relp {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('rss', 'plugin', 'rss {\n\tinterval => ${1:123}\n\turl => "${2:url}"\n}', '**[rss](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-rss.html) input**\n\nCaptures the output of command line tools as an event\n\n**_Example:_**  \n``` ruby\ninput {\n  rss {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('s3', 'plugin', 's3 {\n\tbucket => "${1:bucket}"\n}', '**[s3](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3.html) input**\n\nStreams events from files in a S3 bucket\n\n**_Example:_**  \n``` ruby\n    input {\n      s3 {\n        access_key_id => "1234"\n        secret_access_key => "secret"\n        bucket => "logstash-test"\n        additional_settings => {\n          force_path_style => true\n          follow_redirects => false\n        }\n      }\n    }\n```'),
		createSnippet('s3-sns-sqs', 'plugin', 's3-sns-sqs {\n\t$0\n}', '**[s3-sns-sqs](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-s3-sns-sqs.html) input**\n\nReads logs from AWS S3 buckets using sqs'),
		createSnippet('salesforce', 'plugin', 'salesforce {\n\tclient_id => "${1:client_id}"\n\tclient_secret => "${2:client_secret}"\n\tpassword => "${3:password}"\n\tsecurity_token => "${4:security_token}"\n\tsfdc_object_name => "${5:sfdc_object_name}"\n\tusername => "${6:username}"\n}', '**[salesforce](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-salesforce.html) input**\n\nCreates events based on a Salesforce SOQL query\n\n**_Example:_**  \n``` ruby\ninput {\n  salesforce {\n    client_id => \'OAUTH CLIENT ID FROM YOUR SFDC APP\'\n    client_secret => \'OAUTH CLIENT SECRET FROM YOUR SFDC APP\'\n    username => \'email@example.com\'\n    password => \'super-secret\'\n    security_token => \'SECURITY TOKEN FOR THIS USER\'\n    sfdc_object_name => \'Opportunity\'\n  }\n}\n\noutput {\n  stdout {\n    codec => rubydebug\n  }\n}\n```'),
		createSnippet('snmp', 'plugin', 'snmp {\n\t$0\n}', '**[snmp](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-snmp.html) input**\n\nPolls network devices using Simple Network Management Protocol (SNMP)\n\n**_Example:_**  \n``` ruby\ninput {\n  snmp {\n    get => ["1.3.6.1.2.1.1.1.0", "1.3.6.1.2.1.1.3.0", "1.3.6.1.2.1.1.5.0"]\n    hosts => [{host => "udp:127.0.0.1/161" community => "public"}]\n  }\n}\n```'),
		createSnippet('snmptrap', 'plugin', 'snmptrap {\n\t$0\n}', '**[snmptrap](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-snmptrap.html) input**\n\nCreates events based on SNMP trap messages\n\n**_Example:_**  \n``` ruby\ninput {\n  snmptrap {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('sqlite', 'plugin', 'sqlite {\n\tpath => "${1:path}"\n}', '**[sqlite](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-sqlite.html) input**\n\nCreates events based on rows in an SQLite database\n\n**_Example:_**  \n``` ruby\n    input {\n      sqlite {\n        path => "/tmp/example.db"\n        type => weblogs\n      }\n    }\n    output {\n      stdout {\n        debug => true\n      }\n    }\n```'),
		createSnippet('sqs', 'plugin', 'sqs {\n\tqueue => "${1:queue}"\n}', '**[sqs](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-sqs.html) input**\n\nPulls events from an Amazon Web Services Simple Queue Service queue\n\n**_Example:_**  \n``` ruby\ninput {\n  sqs {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('stdin', 'plugin', 'stdin {\n\t$0\n}', '**[stdin](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-stdin.html) input**\n\nReads events from standard input\n\n**_Example:_**  \n``` ruby\ninput {\n  stdin {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('stomp', 'plugin', 'stomp {\n\tdestination => "${1:destination}"\n\thost => "${2:localhost}"\n}', '**[stomp](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-stomp.html) input**\n\nCreates events received with the STOMP protocol\n\n**_Example:_**  \n``` ruby\ninput {\n  stomp {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('syslog', 'plugin', 'syslog {\n\t$0\n}', '**[syslog](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-syslog.html) input**\n\nReads syslog messages as events\n\n**_Example:_**  \n``` ruby\ninput {\n  syslog {\n    port => 12345\n    codec => cef\n    syslog_field => "syslog"\n    grok_pattern => "<%{POSINT:priority}>%{SYSLOGTIMESTAMP:timestamp} CUSTOM GROK HERE"\n  }\n}\n```'),
		createSnippet('tcp', 'plugin', 'tcp {\n\tport => ${1:123}\n}', '**[tcp](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-tcp.html) input**\n\nReads events from a TCP socket\n\n**_Example:_**  \n``` ruby\ninput {\n  tcp {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('twitter', 'plugin', 'twitter {\n\tconsumer_key => "${1:consumer_key}"\n\tconsumer_secret => "${2:consumer_secret}"\n\toauth_token => "${3:oauth_token}"\n\toauth_token_secret => "${4:oauth_token_secret}"\n}', '**[twitter](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-twitter.html) input**\n\nReads events from the Twitter Streaming API\n\n**_Example:_**  \n``` ruby\n    input {\n      twitter {\n        consumer_key => \'...\'\n        consumer_secret => \'...\'\n        oauth_token => \'...\'\n        oauth_token_secret => \'...\'\n        keywords => [ \'logstash\' ]\n      }\n    }\n```'),
		createSnippet('udp', 'plugin', 'udp {\n\tport => ${1:123}\n}', '**[udp](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-udp.html) input**\n\nReads events over UDP\n\n**_Example:_**  \n``` ruby\n    input {\n      udp {\n        source_ip_fieldname => "[appliance][monitoring][ip]"\n      }\n    }\n```'),
		createSnippet('unix', 'plugin', 'unix {\n\tpath => "${1:path}"\n\tsocket_not_present_retry_interval_seconds => ${2:5}\n}', '**[unix](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-unix.html) input**\n\nReads events over a UNIX socket\n\n**_Example:_**  \n``` ruby\ninput {\n  unix {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('varnishlog', 'plugin', 'varnishlog {\n\t$0\n}', '**[varnishlog](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-varnishlog.html) input**\n\nReads from the varnish cache shared memory log\n\n**_Example:_**  \n``` ruby\ninput {\n  varnishlog {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('websocket', 'plugin', 'websocket {\n\turl => "${1:url}"\n}', '**[websocket](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-websocket.html) input**\n\nReads events from a websocket\n\n**_Example:_**  \n``` ruby\ninput {\n  websocket {\n    id => "my_plugin_id"\n  }\n}\n```'),
		createSnippet('wmi', 'plugin', 'wmi {\n\tquery => "${1:query}"\n}', '**[wmi](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-wmi.html) input**\n\nCreates events based on the results of a WMI query\n\n**_Example:_**  \n``` ruby\n    input {\n      wmi {\n        query => "select * from Win32_Process"\n        interval => 10\n      }\n      wmi {\n        query => "select PercentProcessorTime from Win32_PerfFormattedData_PerfOS_Processor where name = \'_Total\'"\n      }\n      wmi { # Connect to a remote host\n        query => "select * from Win32_Process"\n        host => "MyRemoteHost"\n        user => "mydomain\\\\myuser"\n        password => "Password"\n      }\n    }\n```'),
		createSnippet('xmpp', 'plugin', 'xmpp {\n\tpassword => "${1:password}"\n\tuser => "${2:user}"\n}', '**[xmpp](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-xmpp.html) input**\n\nReceives events over the XMPP/Jabber protocol\n\n**_Example:_**  \n``` ruby\ninput {\n  xmpp {\n    id => "my_plugin_id"\n  }\n}\n```')
	],
	'logstash-codec-json': [
		createSnippet('charset', 'option', 'charset => "${1|UTF-8,ASCII-8BIT,US-ASCII,Big5,Big5-HKSCS,Big5-UAO,CP949,Emacs-Mule,EUC-JP,EUC-KR,EUC-TW,GB2312,GB18030,GBK,ISO-8859-1,ISO-8859-2,ISO-8859-3,ISO-8859-4,ISO-8859-5,ISO-8859-6,ISO-8859-7,ISO-8859-8,ISO-8859-9,ISO-8859-10,ISO-8859-11,ISO-8859-13,ISO-8859-14,ISO-8859-15,ISO-8859-16,KOI8-R,KOI8-U,Shift_JIS,UTF-16BE,UTF-16LE,UTF-32BE,UTF-32LE,Windows-31J,Windows-1250,Windows-1251,Windows-1252,IBM437,IBM737,IBM775,CP850,IBM852,CP852,IBM855,CP855,IBM857,IBM860,IBM861,IBM862,IBM863,IBM864,IBM865,IBM866,IBM869,Windows-1258,GB1988,macCentEuro,macCroatian,macCyrillic,macGreek,macIceland,macRoman,macRomania,macThai,macTurkish,macUkraine,CP950,CP951,IBM037,stateless-ISO-2022-JP,eucJP-ms,CP51932,EUC-JIS-2004,GB12345,ISO-2022-JP,ISO-2022-JP-2,CP50220,CP50221,Windows-1256,Windows-1253,Windows-1255,Windows-1254,TIS-620,Windows-874,Windows-1257,MacJapanese,UTF-7,UTF8-MAC,UTF-16,UTF-32,UTF8-DoCoMo,SJIS-DoCoMo,UTF8-KDDI,SJIS-KDDI,ISO-2022-JP-KDDI,stateless-ISO-2022-JP-KDDI,UTF8-SoftBank,SJIS-SoftBank,BINARY,CP437,CP737,CP775,IBM850,CP857,CP860,CP861,CP862,CP863,CP864,CP865,CP866,CP869,CP1258,Big5-HKSCS:2008,ebcdic-cp-us,eucJP,euc-jp-ms,EUC-JISX0213,eucKR,eucTW,EUC-CN,eucCN,CP936,ISO2022-JP,ISO2022-JP2,ISO8859-1,ISO8859-2,ISO8859-3,ISO8859-4,ISO8859-5,ISO8859-6,CP1256,ISO8859-7,CP1253,ISO8859-8,CP1255,ISO8859-9,CP1254,ISO8859-10,ISO8859-11,CP874,ISO8859-13,CP1257,ISO8859-14,ISO8859-15,ISO8859-16,CP878,MacJapan,ASCII,ANSI_X3.4-1968,646,CP65000,CP65001,UTF-8-MAC,UTF-8-HFS,UCS-2BE,UCS-4BE,UCS-4LE,CP932,csWindows31J,SJIS,PCK,CP1250,CP1251,CP1252,external,locale|}"$0', '**[charset](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-json.html#plugins-codecs-json-charset) option**\n\n- Value can be any of: ASCII-8BIT, UTF-8, US-ASCII, Big5, Big5-HKSCS, Big5-UAO, CP949, Emacs-Mule, EUC-JP, EUC-KR, EUC-TW, GB2312, GB18030, GBK, ISO-8859-1, ISO-8859-2, ISO-8859-3, ISO-8859-4, ISO-8859-5, ISO-8859-6, ISO-8859-7, ISO-8859-8, ISO-8859-9, ISO-8859-10, ISO-8859-11, ISO-8859-13, ISO-8859-14, ISO-8859-15, ISO-8859-16, KOI8-R, KOI8-U, Shift_JIS, UTF-16BE, UTF-16LE, UTF-32BE, UTF-32LE, Windows-31J, Windows-1250, Windows-1251, Windows-1252, IBM437, IBM737, IBM775, CP850, IBM852, CP852, IBM855, CP855, IBM857, IBM860, IBM861, IBM862, IBM863, IBM864, IBM865, IBM866, IBM869, Windows-1258, GB1988, macCentEuro, macCroatian, macCyrillic, macGreek, macIceland, macRoman, macRomania, macThai, macTurkish, macUkraine, CP950, CP951, IBM037, stateless-ISO-2022-JP, eucJP-ms, CP51932, EUC-JIS-2004, GB12345, ISO-2022-JP, ISO-2022-JP-2, CP50220, CP50221, Windows-1256, Windows-1253, Windows-1255, Windows-1254, TIS-620, Windows-874, Windows-1257, MacJapanese, UTF-7, UTF8-MAC, UTF-16, UTF-32, UTF8-DoCoMo, SJIS-DoCoMo, UTF8-KDDI, SJIS-KDDI, ISO-2022-JP-KDDI, stateless-ISO-2022-JP-KDDI, UTF8-SoftBank, SJIS-SoftBank, BINARY, CP437, CP737, CP775, IBM850, CP857, CP860, CP861, CP862, CP863, CP864, CP865, CP866, CP869, CP1258, Big5-HKSCS:2008, ebcdic-cp-us, eucJP, euc-jp-ms, EUC-JISX0213, eucKR, eucTW, EUC-CN, eucCN, CP936, ISO2022-JP, ISO2022-JP2, ISO8859-1, ISO8859-2, ISO8859-3, ISO8859-4, ISO8859-5, ISO8859-6, CP1256, ISO8859-7, CP1253, ISO8859-8, CP1255, ISO8859-9, CP1254, ISO8859-10, ISO8859-11, CP874, ISO8859-13, CP1257, ISO8859-14, ISO8859-15, ISO8859-16, CP878, MacJapan, ASCII, ANSI_X3.4-1968, 646, CP65000, CP65001, UTF-8-MAC, UTF-8-HFS, UCS-2BE, UCS-4BE, UCS-4LE, CP932, csWindows31J, SJIS, PCK, CP1250, CP1251, CP1252, external, locale\n- Default value is "UTF-8"\n\nThe character encoding used in this codec. Examples include "UTF-8" and "CP1252".'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-json.html#plugins-codecs-json-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: JSON document data added at root level v1,v8: Elastic Common Schema compliant behavior (warns when target isn’t set)\n- disabled: JSON document data added at root level\n- v1,v8: Elastic Common Schema compliant behavior (warns when target isn’t set)\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled\n\nSupported values are:'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-json.html#plugins-codecs-json-target) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nDefine the target field for placing the parsed data. If this setting is not set, the JSON data will be stored at the root (top level) of the event.\n\n**_Example:_**  \n``` ruby\n    input {\n      http {\n        codec => json {\n          target => "[document]"\n        }\n      }\n    }\n```')
	],
	'logstash-filter-aggregate': [
		createSnippet('aggregate_maps_path', 'option', 'aggregate_maps_path => "${1:/path/to/file}"', '**[aggregate_maps_path](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-aggregate.html#plugins-filters-aggregate-aggregate_maps_path) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe path to file where aggregate maps are stored when Logstash stops and are loaded from when Logstash starts.\n\n**_Example:_**  \n``` ruby\n    filter {\n      aggregate {\n        aggregate_maps_path => "/path/to/.aggregate_maps"\n      }\n    }\n```'),
		createSnippet('code', 'option', 'code => "${1:code}"', '**[code](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-aggregate.html#plugins-filters-aggregate-code) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe code to execute to update aggregated map, using current event.\n\n**_Example:_**  \n``` ruby\n    filter {\n      aggregate {\n        code => "map[\'sql_duration\'] += event.get(\'duration\')"\n      }\n    }\n```', true),
		createSnippet('end_of_task', 'option', 'end_of_task => ${1|false,true|}', '**[end_of_task](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-aggregate.html#plugins-filters-aggregate-end_of_task) option**\n\n- Value type is boolean\n- Default value is false\n\nTell the filter that task is ended, and therefore, to delete aggregate map after code execution.'),
		createSnippet('inactivity_timeout', 'option', 'inactivity_timeout => ${1:123}', '**[inactivity_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-aggregate.html#plugins-filters-aggregate-inactivity_timeout) option**\n\n- Value type is number\n- There is no default value for this setting.\n\nThe amount of seconds (since the last event) after which a task is considered as expired.'),
		createSnippet('map_action', 'option', 'map_action => "${1|create_or_update,update,create|}"$0', '**[map_action](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-aggregate.html#plugins-filters-aggregate-map_action) option**\n\n- Value type is string\n- Default value is "create_or_update"\n\nTell the filter what to do with aggregate map.'),
		createSnippet('push_map_as_event_on_timeout', 'option', 'push_map_as_event_on_timeout => ${1|false,true|}', '**[push_map_as_event_on_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-aggregate.html#plugins-filters-aggregate-push_map_as_event_on_timeout) option**\n\n- Value type is boolean\n- Default value is false\n\nWhen this option is enabled, each time a task timeout is detected, it pushes task aggregation map as a new Logstash event. This enables to detect and process task timeouts in Logstash, but also to manage tasks that have no explicit end event.'),
		createSnippet('push_previous_map_as_event', 'option', 'push_previous_map_as_event => ${1|false,true|}', '**[push_previous_map_as_event](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-aggregate.html#plugins-filters-aggregate-push_previous_map_as_event) option**\n\n- Value type is boolean\n- Default value is false\n\nWhen this option is enabled, each time aggregate plugin detects a new task id, it pushes previous aggregate map as a new Logstash event, and then creates a new empty map for the next task.'),
		createSnippet('task_id', 'option', 'task_id => "${1:task_id}"', '**[task_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-aggregate.html#plugins-filters-aggregate-task_id) option**\n\n- This is a required setting.\n- Value type is string\n- There is no default value for this setting.\n\nThe expression defining task ID to correlate logs.\n\n**_Example:_**  \n``` ruby\n    filter {\n      aggregate {\n        task_id => "%{type}%{my_task_id}"\n      }\n    }\n```', true),
		createSnippet('timeout', 'option', 'timeout => ${1:1800}', '**[timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-aggregate.html#plugins-filters-aggregate-timeout) option**\n\n- Value type is number\n- Default value is 1800\n\nThe amount of seconds (since the first event) after which a task is considered as expired.'),
		createSnippet('timeout_code', 'option', 'timeout_code => "${1:timeout_code}"', '**[timeout_code](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-aggregate.html#plugins-filters-aggregate-timeout_code) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe code to execute to complete timeout generated event, when \'push_map_as_event_on_timeout\' or \'push_previous_map_as_event\' is set to true. The code block will have access to the newly generated timeout event that is pre-populated with the aggregation map.\n\n**_Example:_**  \n``` ruby\n    filter {\n      aggregate {\n        timeout_code => "event.set(\'state\', \'timeout\')"\n      }\n    }\n```'),
		createSnippet('timeout_tags', 'option', 'timeout_tags => ["${1:timeout_tag}"]', '**[timeout_tags](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-aggregate.html#plugins-filters-aggregate-timeout_tags) option**\n\n- Value type is array\n- Default value is []\n\nDefines tags to add when a timeout event is generated and yield\n\n**_Example:_**  \n``` ruby\n    filter {\n      aggregate {\n        timeout_tags => ["aggregate_timeout"]\n      }\n    }\n```'),
		createSnippet('timeout_task_id_field', 'option', 'timeout_task_id_field => "${1:timeout_task_id_field}"', '**[timeout_task_id_field](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-aggregate.html#plugins-filters-aggregate-timeout_task_id_field) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThis option indicates the timeout generated event’s field where the current "task_id" value will be set. This can help to correlate which tasks have been timed out.\n\n**_Example:_**  \n``` ruby\n    filter {\n      aggregate {\n        timeout_task_id_field => "task_id"\n      }\n    }\n```'),
		createSnippet('timeout_timestamp_field', 'option', 'timeout_timestamp_field => "${1:timeout_timestamp_field}"', '**[timeout_timestamp_field](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-aggregate.html#plugins-filters-aggregate-timeout_timestamp_field) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nBy default, timeout is computed using system time, where Logstash is running.\n\n**_Example:_**  \n``` ruby\n    filter {\n      aggregate {\n        timeout_timestamp_field => "@timestamp"\n      }\n    }\n```')
	],
	'logstash-input-puppet_facter': [
		createSnippet('environment', 'option', 'environment => "${1:production}"', '**[environment](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-puppet_facter.html#plugins-inputs-puppet_facter-environment) option**\n\n- Value type is string\n- Default value is "production"'),
		createSnippet('host', 'option', 'host => "${1:0.0.0.0}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-puppet_facter.html#plugins-inputs-puppet_facter-host) option**\n\n- Value type is string\n- Default value is "0.0.0.0"'),
		createSnippet('interval', 'option', 'interval => ${1:600}', '**[interval](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-puppet_facter.html#plugins-inputs-puppet_facter-interval) option**\n\n- Value type is number\n- Default value is 600'),
		createSnippet('port', 'option', 'port => ${1:8140}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-puppet_facter.html#plugins-inputs-puppet_facter-port) option**\n\n- Value type is number\n- Default value is 8140'),
		createSnippet('private_key', 'option', 'private_key => "${1:/path/to/file}"', '**[private_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-puppet_facter.html#plugins-inputs-puppet_facter-private_key) option**\n\n- Value type is path\n- There is no default value for this setting.'),
		createSnippet('public_key', 'option', 'public_key => "${1:/path/to/file}"', '**[public_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-puppet_facter.html#plugins-inputs-puppet_facter-public_key) option**\n\n- Value type is path\n- There is no default value for this setting.'),
		createSnippet('ssl', 'option', 'ssl => ${1|true,false|}', '**[ssl](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-puppet_facter.html#plugins-inputs-puppet_facter-ssl) option**\n\n- Value type is boolean\n- Default value is true')
	],
	'logstash-codec-msgpack': [
		createSnippet('format', 'option', 'format => "${1:format}"', '**[format](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-msgpack.html#plugins-codecs-msgpack-format) option**\n\n- Value type is string\n- There is no default value for this setting.'),
		createSnippet('target', 'option', 'target => "${1:target}"', '**[target](https://www.elastic.co/guide/en/logstash/7.17/plugins-codecs-msgpack.html#plugins-codecs-msgpack-target) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nDefine the target field for placing the decoded values. If this setting is not set, data will be stored at the root (top level) of the event.\n\n**_Example:_**  \n``` ruby\n    input {\n      tcp {\n        port => 4242\n        codec => msgpack {\n          target => "[document]"\n        }\n      }\n    }\n```')
	],
	'logstash-output-graphtastic': [
		createSnippet('batch_number', 'option', 'batch_number => ${1:60}', '**[batch_number](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphtastic.html#plugins-outputs-graphtastic-batch_number) option**\n\n- Value type is number\n- Default value is 60\n\nthe number of metrics to send to GraphTastic at one time. 60 seems to be the perfect amount for UDP, with default packet size.'),
		createSnippet('context', 'option', 'context => "${1:graphtastic}"', '**[context](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphtastic.html#plugins-outputs-graphtastic-context) option**\n\n- Value type is string\n- Default value is "graphtastic"\n\nif using rest as your end point you need to also provide the application url it defaults to localhost/graphtastic. You can customize the application url by changing the name of the .war file. There are other ways to change the application context, but they vary depending on the Application Server in use. Please consult your application server documentation for more on application contexts.'),
		createSnippet('error_file', 'option', 'error_file => "${1:error_file}"', '**[error_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphtastic.html#plugins-outputs-graphtastic-error_file) option**\n\n- Value type is string\n- Default value is ""\n\nsetting allows you to specify where we save errored transactions this makes the most sense at this point - will need to decide on how we reintegrate these error metrics NOT IMPLEMENTED!'),
		createSnippet('host', 'option', 'host => "${1:127.0.0.1}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphtastic.html#plugins-outputs-graphtastic-host) option**\n\n- Value type is string\n- Default value is "127.0.0.1"\n\nhost for the graphtastic server - defaults to 127.0.0.1'),
		createSnippet('integration', 'option', 'integration => "${1|udp,tcp,rmi,rest|}"$0', '**[integration](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphtastic.html#plugins-outputs-graphtastic-integration) option**\n\n- Value can be any of: udp, tcp, rmi, rest\n- Default value is "udp"\n\noptions are udp(fastest - default) - rmi(faster) - rest(fast) - tcp(don’t use TCP yet - some problems - errors out on linux)'),
		createSnippet('metrics', 'option', 'metrics => {\n\t"${1:key}" => "${2:value}"\n}', '**[metrics](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphtastic.html#plugins-outputs-graphtastic-metrics) option**\n\n- Value type is hash\n- Default value is {}\n\nmetrics hash - you will provide a name for your metric and the metric data as key value pairs. so for example:\n\n**_Example:_**  \n``` ruby\nmetrics => { "Response" => "%{response}" }\n```'),
		createSnippet('port', 'option', 'port => ${1:123}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphtastic.html#plugins-outputs-graphtastic-port) option**\n\n- Value type is number\n- There is no default value for this setting.\n\nport for the graphtastic instance - defaults to 1199 for RMI, 1299 for TCP, 1399 for UDP, and 8080 for REST'),
		createSnippet('retries', 'option', 'retries => ${1:1}', '**[retries](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-graphtastic.html#plugins-outputs-graphtastic-retries) option**\n\n- Value type is number\n- Default value is 1\n\nnumber of attempted retry after send error - currently only way to integrate errored transactions - should try and save to a file or later consumption either by graphtastic utility or by this program after connectivity is ensured to be established.')
	],
	'logstash-output-sns': [
		createSnippet('access_key_id', 'option', 'access_key_id => "${1:access_key_id}"', '**[access_key_id](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sns.html#plugins-outputs-sns-access_key_id) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThis plugin uses the AWS SDK and supports several ways to get credentials, which will be tried in this order:'),
		createSnippet('arn', 'option', 'arn => "${1:arn}"', '**[arn](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sns.html#plugins-outputs-sns-arn) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nOptional ARN to send messages to. If you do not set this you must include the sns field in your events to set the ARN on a per-message basis!'),
		createSnippet('aws_credentials_file', 'option', 'aws_credentials_file => "${1:aws_credentials_file}"', '**[aws_credentials_file](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sns.html#plugins-outputs-sns-aws_credentials_file) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nPath to YAML file containing a hash of AWS credentials. This file will only be loaded if access_key_id and secret_access_key aren’t set. The contents of the file should look like this:'),
		createSnippet('proxy_uri', 'option', 'proxy_uri => "${1:proxy_uri}"', '**[proxy_uri](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sns.html#plugins-outputs-sns-proxy_uri) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nURI to proxy server if required'),
		createSnippet('publish_boot_message_arn', 'option', 'publish_boot_message_arn => "${1:publish_boot_message_arn}"', '**[publish_boot_message_arn](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sns.html#plugins-outputs-sns-publish_boot_message_arn) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nWhen an ARN for an SNS topic is specified here, the message "Logstash successfully booted" will be sent to it when this plugin is registered.'),
		createSnippet('region', 'option', 'region => "${1|us-east-1,us-east-2,us-west-1,us-west-2,eu-central-1,eu-west-1,eu-west-2,ap-southeast-1,ap-southeast-2,ap-northeast-1,ap-northeast-2,sa-east-1,us-gov-west-1,cn-north-1,ap-south-1,ca-central-1|}"$0', '**[region](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sns.html#plugins-outputs-sns-region) option**\n\n- Value can be any of: us-east-1, us-east-2, us-west-1, us-west-2, eu-central-1, eu-west-1, eu-west-2, ap-southeast-1, ap-southeast-2, ap-northeast-1, ap-northeast-2, sa-east-1, us-gov-west-1, cn-north-1, ap-south-1, ca-central-1\n- Default value is "us-east-1"\n\nThe AWS Region'),
		createSnippet('secret_access_key', 'option', 'secret_access_key => "${1:secret_access_key}"', '**[secret_access_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sns.html#plugins-outputs-sns-secret_access_key) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS Secret Access Key'),
		createSnippet('session_token', 'option', 'session_token => "${1:session_token}"', '**[session_token](https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-sns.html#plugins-outputs-sns-session_token) option**\n\n- Value type is string\n- There is no default value for this setting.\n\nThe AWS Session token for temporary credential')
	],
	'logstash-filter-dns': [
		createSnippet('action', 'option', 'action => "${1|append,replace|}"$0', '**[action](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-dns.html#plugins-filters-dns-action) option**\n\n- Value can be any of: append, replace\n- Default value is "append"\n\nDetermine what action to do: append or replace the values in the fields specified under reverse and resolve.'),
		createSnippet('failed_cache_size', 'option', 'failed_cache_size => ${1:0}', '**[failed_cache_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-dns.html#plugins-filters-dns-failed_cache_size) option**\n\n- Value type is number\n- Default value is 0\n\ncache size for failed requests'),
		createSnippet('failed_cache_ttl', 'option', 'failed_cache_ttl => ${1:5}', '**[failed_cache_ttl](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-dns.html#plugins-filters-dns-failed_cache_ttl) option**\n\n- Value type is number\n- Default value is 5\n\nhow long to cache failed requests (in seconds)'),
		createSnippet('hit_cache_size', 'option', 'hit_cache_size => ${1:0}', '**[hit_cache_size](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-dns.html#plugins-filters-dns-hit_cache_size) option**\n\n- Value type is number\n- Default value is 0\n\nset the size of cache for successful requests'),
		createSnippet('hit_cache_ttl', 'option', 'hit_cache_ttl => ${1:60}', '**[hit_cache_ttl](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-dns.html#plugins-filters-dns-hit_cache_ttl) option**\n\n- Value type is number\n- Default value is 60\n\nhow long to cache successful requests (in seconds)'),
		createSnippet('hostsfile', 'option', 'hostsfile => ["${1:hostsfile}"]', '**[hostsfile](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-dns.html#plugins-filters-dns-hostsfile) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nUse custom hosts file(s). For example: ["/var/db/my_custom_hosts"]'),
		createSnippet('max_retries', 'option', 'max_retries => ${1:2}', '**[max_retries](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-dns.html#plugins-filters-dns-max_retries) option**\n\n- Value type is number\n- Default value is 2\n\nnumber of times to retry a failed resolve/reverse'),
		createSnippet('nameserver', 'option', 'nameserver => {\n\t"${1:key}" => "${2:value}"\n}', '**[nameserver](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-dns.html#plugins-filters-dns-nameserver) option**\n\n- Value type is hash, and is composed of: a required address key, whose value is either a string or an array, representing one or more nameserver ip addresses an optional search key, whose value is either a string or an array, representing between one and six search domains (e.g., with search domain com, a query for example will match DNS entries for example.com) an optional ndots key, used in conjunction with search, whose value is a number, representing the minimum number of dots in a domain name being resolved that will prevent the search domains from being used (default 1; this option is rarely needed)\n- a required address key, whose value is either a string or an array, representing one or more nameserver ip addresses\n- an optional search key, whose value is either a string or an array, representing between one and six search domains (e.g., with search domain com, a query for example will match DNS entries for example.com)\n- an optional ndots key, used in conjunction with search, whose value is a number, representing the minimum number of dots in a domain name being resolved that will prevent the search domains from being used (default 1; this option is rarely needed)\n- For backward-compatibility, values of string and array are also accepted, representing one or more nameserver ip addresses without search domains.\n- There is no default value for this setting.\n\nValue type is hash, and is composed of:\n\n**_Example:_**  \n``` ruby\n    filter {\n      dns {\n        nameserver => {\n          address => ["8.8.8.8", "8.8.4.4"]\n          search  => ["internal.net"]\n        }\n      }\n    }\n```'),
		createSnippet('resolve', 'option', 'resolve => ["${1:resolve}"]', '**[resolve](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-dns.html#plugins-filters-dns-resolve) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nForward resolve one or more fields.'),
		createSnippet('reverse', 'option', 'reverse => ["${1:reverse}"]', '**[reverse](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-dns.html#plugins-filters-dns-reverse) option**\n\n- Value type is array\n- There is no default value for this setting.\n\nReverse resolve one or more fields.'),
		createSnippet('timeout', 'option', 'timeout => ${1:0.5}', '**[timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-dns.html#plugins-filters-dns-timeout) option**\n\n- Value type is number\n- Default value is 0.5\n\nresolv calls will be wrapped in a timeout instance')
	],
	'logstash-input-beats': [
		createSnippet('add_hostname', 'option', 'add_hostname => ${1|false,true|}', '**[add_hostname](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-beats.html#plugins-inputs-beats-add_hostname) option**\n\n- Value type is boolean\n- Default value is false\n\nThe default value has been changed to false. In 7.0.0 this setting will be removed'),
		createSnippet('cipher_suites', 'option', 'cipher_suites => ["${1:TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384}", "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384", "TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256", "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256", "TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384", "TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384", "TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256", "TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256"]', '**[cipher_suites](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-beats.html#plugins-inputs-beats-cipher_suites) option**\n\n- Value type is array\n- Default value is java.lang.String[TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256, TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256]@459cfcca\n\nThe list of ciphers suite to use, listed by priorities.'),
		createSnippet('client_inactivity_timeout', 'option', 'client_inactivity_timeout => ${1:60}', '**[client_inactivity_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-beats.html#plugins-inputs-beats-client_inactivity_timeout) option**\n\n- Value type is number\n- Default value is 60\n\nClose Idle clients after X seconds of inactivity.'),
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-beats.html#plugins-inputs-beats-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: unstructured connection metadata added at root level v1: structured connection metadata added under ECS v1 compliant namespaces v8: structured connection metadata added under ECS v8 compliant namespaces\n- disabled: unstructured connection metadata added at root level\n- v1: structured connection metadata added under ECS v1 compliant namespaces\n- v8: structured connection metadata added under ECS v8 compliant namespaces\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:'),
		createSnippet('executor_threads', 'option', 'executor_threads => ${1:1 executor thread per CPU core}', '**[executor_threads](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-beats.html#plugins-inputs-beats-executor_threads) option**\n\n- Value type is number\n- Default value is 1 executor thread per CPU core\n\nThe number of threads to be used to process incoming beats requests. By default the Beats input creates a number of threads equal to 2*CPU cores. These threads handle incoming connections, reading from established sockets, and executing most of the tasks related to network connection management. Parsing the Lumberjack protocol is offloaded to a dedicated thread pool.'),
		createSnippet('host', 'option', 'host => "${1:0.0.0.0}"', '**[host](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-beats.html#plugins-inputs-beats-host) option**\n\n- Value type is string\n- Default value is "0.0.0.0"\n\nThe IP address to listen on.'),
		createSnippet('include_codec_tag', 'option', 'include_codec_tag => ${1|true,false|}', '**[include_codec_tag](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-beats.html#plugins-inputs-beats-include_codec_tag) option**\n\n- Value type is boolean\n- Default value is true'),
		createSnippet('port', 'option', 'port => ${1:123}', '**[port](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-beats.html#plugins-inputs-beats-port) option**\n\n- This is a required setting.\n- Value type is number\n- There is no default value for this setting.\n\nThe port to listen on.', true),
		createSnippet('ssl', 'option', 'ssl => ${1|false,true|}', '**[ssl](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-beats.html#plugins-inputs-beats-ssl) option**\n\n- Value type is boolean\n- Default value is false\n\nEvents are by default sent in plain text. You can enable encryption by setting ssl to true and configuring the ssl_certificate and ssl_key options.'),
		createSnippet('ssl_certificate', 'option', 'ssl_certificate => "${1:/path/to/file}"', '**[ssl_certificate](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-beats.html#plugins-inputs-beats-ssl_certificate) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nSSL certificate to use.'),
		createSnippet('ssl_certificate_authorities', 'option', 'ssl_certificate_authorities => ["${1:ssl_certificate_authoritie}"]', '**[ssl_certificate_authorities](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-beats.html#plugins-inputs-beats-ssl_certificate_authorities) option**\n\n- Value type is array\n- Default value is []\n\nValidate client certificates against these authorities. You can define multiple files or paths. All the certificates will be read and added to the trust store. You need to configure the ssl_verify_mode to peer or force_peer to enable the verification.'),
		createSnippet('ssl_handshake_timeout', 'option', 'ssl_handshake_timeout => ${1:10000}', '**[ssl_handshake_timeout](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-beats.html#plugins-inputs-beats-ssl_handshake_timeout) option**\n\n- Value type is number\n- Default value is 10000\n\nTime in milliseconds for an incomplete ssl handshake to timeout'),
		createSnippet('ssl_key', 'option', 'ssl_key => "${1:/path/to/file}"', '**[ssl_key](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-beats.html#plugins-inputs-beats-ssl_key) option**\n\n- Value type is path\n- There is no default value for this setting.\n\nSSL key to use. This key must be in the PKCS8 format and PEM encoded. You can use the openssl pkcs8 command to complete the conversion. For example, the command to convert a PEM encoded PKCS1 private key to a PEM encoded, non-encrypted PKCS8 key is:'),
		createSnippet('ssl_key_passphrase', 'option', 'ssl_key_passphrase => "${1:ssl_key_passphrase}"', '**[ssl_key_passphrase](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-beats.html#plugins-inputs-beats-ssl_key_passphrase) option**\n\n- Value type is password\n- There is no default value for this setting.\n\nSSL key passphrase to use.'),
		createSnippet('ssl_verify_mode', 'option', 'ssl_verify_mode => "${1|none,peer,force_peer|}"$0', '**[ssl_verify_mode](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-beats.html#plugins-inputs-beats-ssl_verify_mode) option**\n\n- Value can be any of: none, peer, force_peer\n- Default value is "none"\n\nBy default the server doesn’t do any client verification.'),
		createSnippet('ssl_peer_metadata', 'option', 'ssl_peer_metadata => ${1|false,true|}', '**[ssl_peer_metadata](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-beats.html#plugins-inputs-beats-ssl_peer_metadata) option**\n\n- Value type is boolean\n- Default value is false\n\nEnables storing client certificate information in event’s metadata.'),
		createSnippet('tls_max_version', 'option', 'tls_max_version => ${1:1.2}', '**[tls_max_version](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-beats.html#plugins-inputs-beats-tls_max_version) option**\n\n- Value type is number\n- Default value is 1.2\n\nThe maximum TLS version allowed for the encrypted connections. The value must be the one of the following: 1.0 for TLS 1.0, 1.1 for TLS 1.1, 1.2 for TLS 1.2'),
		createSnippet('tls_min_version', 'option', 'tls_min_version => ${1:1}', '**[tls_min_version](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-beats.html#plugins-inputs-beats-tls_min_version) option**\n\n- Value type is number\n- Default value is 1\n\nThe minimum TLS version allowed for the encrypted connections. The value must be one of the following: 1.0 for TLS 1.0, 1.1 for TLS 1.1, 1.2 for TLS 1.2')
	],
	'logstash-input-stdin': [
		createSnippet('ecs_compatibility', 'option', 'ecs_compatibility => "${1:ecs_compatibility}"', '**[ecs_compatibility](https://www.elastic.co/guide/en/logstash/7.17/plugins-inputs-stdin.html#plugins-inputs-stdin-ecs_compatibility) option**\n\n- Value type is string\n- Supported values are: disabled: does not use ECS-compatible field names (using host field to store host name) v1,v8: uses fields that are compatible with Elastic Common Schema (using [host][hostname])\n- disabled: does not use ECS-compatible field names (using host field to store host name)\n- v1,v8: uses fields that are compatible with Elastic Common Schema (using [host][hostname])\n- Default value depends on which version of Logstash is running: When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default Otherwise, the default value is disabled.\n- When Logstash provides a pipeline.ecs_compatibility setting, its value is used as the default\n- Otherwise, the default value is disabled.\n\nSupported values are:')
	]
};